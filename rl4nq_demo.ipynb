{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tender-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-unknown",
   "metadata": {},
   "source": [
    "# OR Suite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "##  Ambulance Routing Environment\n",
    "\n",
    "One potential application of reinforcement learning involves positioning a server or servers (in this case an ambulance) in an optimal way geographically to respond to incoming calls while minimizing the distance traveled by the servers. \n",
    "\n",
    "This is closely related to the [k-server problem](https://en.wikipedia.org/wiki/K-server_problem), where there are $k$ servers stationed in a space that must respond to requests arriving in that space in such a way as to minimize the total distance traveled. \n",
    "\n",
    "The ambulance routing problem addresses the problem by modeling an environment where there are ambulances stationed at locations, and calls come in that one of the ambulances must be sent to respond to. The goal of the agent is to minimize both the distance traveled by the ambulances between calls and the distance traveled to respond to a call by optimally choosing the locations to station the ambulances. The ambulance environment has been implemented in two different ways; as a 1-dimensional number line $[0,1]$ along which ambulances will be stationed and calls will arrive, and a graph with nodes where ambulances can be stationed and calls can arrive, and edges between the nodes that ambulances travel along.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8a622",
   "metadata": {},
   "source": [
    "## Line\n",
    "\n",
    "ambulance_metric.py is a 1-dimensional reinforcement learning environment in the space $X = [0, 1]$. Each ambulance in the problem can be located anywhere in $X$, so the state space is $S = X^k$, where $k$ is the number of ambulances. The distance function is chosen by the user, who specifies what kind of norm to use. Calls for an ambulance can also arrive anywhere in $X$, and the nearest ambulance will respond to the call, leaving the locations of the other ambulances unchanged. Between calls the agent must choose a location to station each ambulance, with the goal of minimizing both the distance traveled between calls and to respond to a call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-carry",
   "metadata": {},
   "source": [
    "### Environment Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-chester",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did not get a better reward than the RL algorithm.\n",
      "\n",
      "Your total reward over all iterations was  -0.864\n",
      "The RL algorithm's total reward over all iterations was  -0.807 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFDCAYAAAB/UdRdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVKUlEQVR4nO3de9BlVX3m8e9jt7EVgoByaUBsTBGQRKL4ZopcJChgKSZpUjFGByNaNaGsUUOokAyWU5HU1DCkMiZq4iVtIukocRgwCS0hKrS2SCJIc5FLAEECcmmhoUYSA16Q3/yx16snb857ac7r6vfA91N16uyz9jp7rXPOXufZe+3Tb6eqkCRJP3hP2dkdkCTpycLQlSSpE0NXkqRODF1JkjoxdCVJ6sTQlSSpk2UJ3SSvSHJLktuSnD5mfZK8t62/LskRy9GuJEnTZOLQTbIKeB/wSuAw4HVJDptT7ZXAwe12MvCBSduVJGnaLMeZ7n8Cbquq26vq28D/AdbPqbMe+MsaXA7snmTtMrQtSdLUWI7Q3R+4a+Tx3a1sR+tIkvSEtnoZtpExZXP/tuRS6gwVk5MZpqDZZZddXnzooYdO1rvm+nseWpbtSL29YP9n7uwuLJnjTNNqucfZVVdd9UBV7TW3fDlC927gOSOPDwDufRx1AKiqDcAGgJmZmdq6desydBHWnf53y7IdqbetZ71qZ3dhyRxnmlbLPc6S3DmufDmml68EDk5yUJIfAl4LbJpTZxPwhvYr5iOBh6pq2zK0LUnS1Jj4TLeqHk3yVuBTwCrgw1V1Y5I3t/UfBC4CjgduAx4G3jRpu5IkTZvlmF6mqi5iCNbRsg+OLBfwluVoS5KkaeVfpJIkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6MXQlSerE0JUkqRNDV5KkTgxdSZI6mSh0k+yZ5OIkt7b7PcbUeU6Szya5KcmNSU6ZpE1JkqbVpGe6pwObq+pgYHN7PNejwG9V1fOBI4G3JDlswnYlSZo6k4buemBjW94InDC3QlVtq6qr2/K/AjcB+0/YriRJU2fS0N2nqrbBEK7A3gtVTrIOeBFwxQJ1Tk6yNcnW7du3T9g9SZJWjtWLVUhyCbDvmFXv2JGGkuwKfBz4zar6l/nqVdUGYAPAzMxM7UgbkiStZIuGblUdO9+6JPclWVtV25KsBe6fp95TGQL3nKr668fdW0mSptik08ubgJPa8knABXMrJAnw58BNVfWHE7YnSdLUmjR0zwKOS3IrcFx7TJL9klzU6vwM8GvAy5Jc227HT9iuJElTZ9Hp5YVU1YPAMWPK7wWOb8uXAZmkHUmSngj8i1SSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1ImhK0lSJ4auJEmdGLqSJHVi6EqS1MlEoZtkzyQXJ7m13e+xQN1VSa5JcuEkbUqSNK0mPdM9HdhcVQcDm9vj+ZwC3DRhe5IkTa1JQ3c9sLEtbwROGFcpyQHAq4A/m7A9SZKm1qShu09VbQNo93vPU+/dwO8Aj03YniRJU2v1YhWSXALsO2bVO5bSQJKfB+6vqquSHL2E+icDJwMceOCBS2lCkqSpsGjoVtWx861Lcl+StVW1Lcla4P4x1X4G+MUkxwNrgN2SfLSqXj9PexuADQAzMzO1lBchSdI0mHR6eRNwUls+CbhgboWqentVHVBV64DXAp+ZL3AlSXoimzR0zwKOS3IrcFx7TJL9klw0aeckSXoiWXR6eSFV9SBwzJjye4Hjx5RvAbZM0qYkSdPKv0glSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdWLoSpLUiaErSVInhq4kSZ0YupIkdTJR6CbZM8nFSW5t93vMU2/3JOcnuTnJTUl+apJ2JUmaRpOe6Z4ObK6qg4HN7fE47wE+WVWHAj8B3DRhu5IkTZ1JQ3c9sLEtbwROmFshyW7AUcCfA1TVt6vq6xO2K0nS1Jk0dPepqm0A7X7vMXWeB2wHzk5yTZI/S7LLfBtMcnKSrUm2bt++fcLuSZK0ciwaukkuSXLDmNv6JbaxGjgC+EBVvQj4N+afhqaqNlTVTFXN7LXXXktsQpKklW/1YhWq6tj51iW5L8naqtqWZC1w/5hqdwN3V9UV7fH5LBC6kiQ9UU06vbwJOKktnwRcMLdCVX0NuCvJIa3oGOCfJmxXkqSpM2nongUcl+RW4Lj2mCT7JblopN7bgHOSXAe8EDhzwnYlSZo6i04vL6SqHmQ4c51bfi9w/Mjja4GZSdqSJGna+RepJEnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKkTQ1eSpE4MXUmSOjF0JUnqxNCVJKmTiUI3yZ5JLk5ya7vfY556pya5MckNST6WZM0k7UqSNI0mPdM9HdhcVQcDm9vjfyfJ/sBvADNV9ePAKuC1E7YrSdLUmTR01wMb2/JG4IR56q0Gnp5kNfAM4N4J25UkaepMGrr7VNU2gHa/99wKVXUP8L+BrwLbgIeq6tMTtitJ0tRZNHSTXNKuxc69rV9KA+0673rgIGA/YJckr1+g/slJtibZun379qW+DkmSVrzVi1WoqmPnW5fkviRrq2pbkrXA/WOqHQv8c1Vtb8/5a+CngY/O094GYAPAzMxMLf4SJEmaDouG7iI2AScBZ7X7C8bU+SpwZJJnAI8AxwBbJ2xX0gp0x1mv2tldkFa0Sa/pngUcl+RW4Lj2mCT7JbkIoKquAM4Hrgaub21umLBdSZKmzkRnulX1IMOZ69zye4HjRx6/E3jnJG1JkjTt/ItUkiR1YuhKktSJoStJUieGriRJnRi6kiR1YuhKktSJoStJUieGriRJnRi6kiR1YuhKktSJoStJUieGriRJnRi6kiR1YuhKktSJoStJUicT/X+60+SOs161s7sgSXqS80xXkqRODF1JkjoxdCVJ6sTQlSSpE0NXkqRODF1JkjoxdCVJ6sTQlSSpE0NXkqRODF1JkjoxdCVJ6sTQlSSpE0NXkqROUlU7uw/zSrIduHNn90OLejbwwM7uhPQk4FibHs+tqr3mFq7o0NV0SLK1qmZ2dj+kJzrH2vRzelmSpE4MXUmSOjF0tRw27OwOSE8SjrUp5zVdSZI68UxXkqRODN0VIoPLkrxypOw1ST65jG1sSXJLki8luTLJC5dr2zvYjzOSnDam/JDWx2uT3JRkyVNpSdYleaQ9d/b2Q8vbc/WU5Lvtc7whySeS7N7K1yW5YYnb+FKSj80p+4skr16mPs4keW9bPjrJT/+A2nljku3t/bg5yanLsd3H0Y+x732SpyR5b/usrm/fLwftwHZnv5tmx+6yvG8r0eqd3QENqqqSvBk4L8lngVXA/wRe8Xi2lyQMlw8em7PqxKramuRNwB8Ax03S7wn6Mc57gT+qqgvac1+wg819papeuIP9W1VV393BdtTHI7OfZ5KNwFsYxsSSJHk+w4nFUUl2qap/W87OJVldVVuBra3oaOAbwD8uZzsjzq2qtyZ5FnBLkvOr6q4fUFvA917jo0uo+qvAfsDhVfVYkgOAHX2/T2zv5470b+rGr2e6K0hV3QB8AvhvwDuBjwLvSnJdksuTHA7/8UyxHV2ua7ebkrwfuBp4zgLNfQHYvz1/lyQfbken1yRZ38ovGmnzmiS/25b/R5L/kmTXJJuTXN2Obmef9x/6keQd7Uj2EuCQefq0Frh75P24vm1vTZKzWxvXJHnpUt7P1o/Pt/5dPXsW0s5IPpvkr4Drl7It7XTf2193wH8GPgJ8GvjFcRWSHN/OHC9rZ2oXtvI9k/ztPGNvQ5JPA3/Z9qULk6wD3gyc2s7UXtKaOCrJPya5ffbsrT3nc0n+b5IvJzkryYlJvtj28R9Z6EVV1YPAbQzjhSSvb8+9NsmfJlmVYZbsD9v6U5Lc3pZ/JMllbfl325i/ob2mtPItSc5M8jnglCQvzjBj8AWGA59x1gLbZg+uq+ruqvp/bXuva6/rhiS/v9Brm/PZfCDJ1iQ3Jvm9kfI7Wt8vA35lqdtbMarK2wq6AbsAtzCEwQeAd7bylwHXtuUzgNNGnnMDsK7dHgOOnGfbW4CZtvybwJlt+Uzg9W15d+DLrR+nMwyy3YArgU+1Op9lCM7VwG6t7NkMXwSZ2w/gxe31PKNt67bR/o/0703AQ8DfA6cCu7fy3wLObsuHAl8F1sx57jrgEeDadntfa29NW38wsLUtH81wFH7Qzv68vS04Fr7R7lcB5wGvGPmsb1jC878MPBd4ObBppPwvgFcDa4C7ZvcD4GPAhW35jxcYe1cBTx/Zly4cWXfanHbOYzi5OQy4beQ5X2cIqqcB9wC/19adArx7zGt5I/AnbfnAto+vAZ7PcKD+1Lbu/cAbgH2BK1vZ+Qzjd3/gJOB/tfI9R7b/EeAX2vIW4P0j664Dfq4t/8G49x44ALij9etdwIta+X4M43Uvhu+LzwAnjHn+FobvvWvb7Vmz/Wuf/xaGs2haO7+zs/fPx3vzTHeFqWEK7FyGQXBku6eqPgM8K8kzF9nEnVV1+QLrz0lyN8PZ9B+3spcDpye5lmHnXsMwsD8PHAX8LPB3wK5JngGsq6pbGAL2zCTXAZcwDOp9xvTjJcDfVNXDVfUvwKZ5XvvZDF8i5zF8MV2e5Gmt/dn34WaGPw36o2M28ZWqemG7vQV4KvChJNe3bR42UveLVfXPC7xP2vme3vbJB4E9gYuX+sQkPwlsr6o7gc3AEUn2mFPtUOD2kf1g9Nrv6D43d+xtqqpHltiVv62qx6rqn/j+2IAhELdV1beArzCcjcNwcLpunm39apIbgduB91TVN4FjGA5qr2zv1THA86rqawzj9YcZZrz+imEsv4RhXAO8NMkVbXy8DPixkbbOBWivefeq+lwr/8i4jlXV3QwH4m9nOODenOQY4CeBLVW1vYZp6nNaP8Y5cWT8Pgi8JsnVwDWtb6Pj99x5trHiGbor02PtljHrCniUf//ZrRlZXuw6yonAQQyD8H2tLMAvj+zwB1bVTQxHxzMMA/VShp3/1xmO9Ge3tRfw4hquvd030pe5/VjSv02rqnur6sNVtb69zh9n/PuwFKe2Pv1Eex2jP6xa1ut7+oGYvab7XIbPbr6pzXFeBxya5A6GUNsN+OU5dRbar+Ybe7Bj+8635tnmaPljI48fY/7f2pxbVT/GMB7flWTfts2NI2P3kKo6o9X/AsPs0S0MQfsS4KeAf0iyhuGs+NVV9QLgQ4z/HglLH7vfqqq/r6rfZpg9O4HHOXYz/AjrNOCYqjqc4aB/R77nVixDd2W7lCHYSHI08EA7U7wDOKKVH8EQoktWVd8B/jtwZIYfm3wKeNvINZ0XtXrfZph+ew1wOcPAPY3vHyk/E7i/qr7TrrM+d4HX8UtJnt6OvH9hXKUkr0jy1La8L8MU0z1z3ocfZTgLv2UJL/WZfP86068xTFNpylTVQ8BvAKfN7h8LSfIUhmt9h1fVuqpaB6xnCOJRNwPPa9djYfgx0Kz5xt5C/hX44cX6N6mq+gLDGecpDGfxr06yN3zvWvTsOLyUYbzOHjC/FPhWez9nA+yBJLsyTLePa+vrwENJfrYVnTiuXpIjkuzXlp8CHM4wI3UF8HNJnp1kFcNn8Llx25hjN4ZgfSjJPsArF6k/Nfz18sp2BnB2m759mOF6DMDHgTe06aQrGa5d7ZCqeiTJuxgG5VuBdwPXteC9A/j5VvXzDEebDyf5PMO1m9nQPQf4RJKtDNdhbp6nrauTnNvq3Dny/LleDrwnyTfb49+uqq9l+EHWB9s02KPAG9u03GLeD3w8ya8wXIee2qPjJ7uquibJl4DXMuw/h7TLJLNOrarz2vJRwD1Vdc/I+kuBw5KsHdnmI0n+K/DJJA8AXxypfwbjx95CPgGcn+EHhW/bsVe4w36f4UeKZzIcQH+6hd13GGYEZsfZc4BLq+q7Se6ijdGq+nqSDzFMZ9/B8D0ynzcBH07yMMMB+jh7M1zKeVp7/EWGa9DfTPJ2hvEX4KJq/zphIVX1pSTXALPT6f+w2HOmhX+RStKTVpJdq+ob7WDzfcCtVfVHO7tfeuJyelnSk9mvtxmjGxkuR/zpzu2Onug805UkqRPPdCVJ6sTQlSSpE0NXkqRODF1JkjoxdCVJ6sTQlSSpk/8PWmDWY9DqhNQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from pyvirtualdisplay import Display\n",
    "#display = Display(visible=0, size=(500, 800))\n",
    "#display.start()\n",
    "\n",
    "import or_suite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "import rendering\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "a = 5\n",
    "b = 2\n",
    "CONFIG = {'epLen': 5,\n",
    "    'arrival_dist': lambda x : np.random.beta(a,b), \n",
    "    'alpha': 0.25, \n",
    "    'starting_state': np.array([0.0, 0.0]), \n",
    "    'num_ambulance': 2,\n",
    "    'norm': 1\n",
    "}\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "epLen = CONFIG['epLen']\n",
    "state = CONFIG['starting_state']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "agent = or_suite.agents.ambulance.command_line_metric.commandLineAgent(epLen)\n",
    "env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "env.reset()\n",
    "\n",
    "done = False\n",
    "your_rewards = []\n",
    "heuristic_agent_rewards = []\n",
    "your_total_reward = 0\n",
    "heuristic_agent_total_reward = 0\n",
    "\n",
    "median_est = (a - 1/3)/(a + b - 2/3)\n",
    "heuristic_agent_states = [state]\n",
    "\n",
    "x_axis = ['Your Reward So Far', 'RL Algorithm Reward So Far']\n",
    "\n",
    "\n",
    "def display_animation(screen, time_to_display):\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    if time_to_display is not None:\n",
    "        ipythondisplay.display(plt.gcf())\n",
    "        time.sleep(time_to_display)\n",
    "\n",
    "def plot_rewards():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    y_axis = [your_total_reward, heuristic_agent_total_reward]\n",
    "    ax.bar(x_axis, y_axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = agent.greedy(state, 0)\n",
    "    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    your_rewards.append(reward)\n",
    "    your_total_reward += reward\n",
    "\n",
    "    # by comparing the final state with the action the user chose, we can figure out where the most recent arrival was\n",
    "    previous_arrival_ind = np.argmax(np.abs(action - state))\n",
    "    previous_arrival = state[previous_arrival_ind]\n",
    "\n",
    "    # the heuristic agent always chooses to put all the ambulances at the median estimate\n",
    "    heuristic_agent_action = np.full(num_ambulance, median_est)\n",
    "\n",
    "    # the state will have one ambulance where the call arrived, and all other ambulances at the median estimate\n",
    "    # doesn't matter which ambulance responds to the call because they're all at the same place\n",
    "    heuristic_agent_state = np.concatenate([np.full(num_ambulance - 1, median_est), [previous_arrival]])\n",
    "    heuristic_agent_states.append(heuristic_agent_state)\n",
    "\n",
    "    heuristic_agent_reward = -1 * (alpha * np.sum(np.abs(heuristic_agent_states[-2] - heuristic_agent_action)) + (1 - alpha) * np.sum(np.abs(heuristic_agent_action - heuristic_agent_state)))\n",
    "    heuristic_agent_rewards.append(heuristic_agent_reward)\n",
    "    heuristic_agent_total_reward += heuristic_agent_reward\n",
    "    \n",
    "    env.viewer = rendering.PygletWindow(850, 550)\n",
    "    env.viewer.window.set_visible(False)\n",
    "    screen1, screen2, screen3 = env.render(mode='rgb_array')\n",
    "    \n",
    "    # display each step of the environment for 2 seconds\n",
    "    display_animation(screen1, 2)\n",
    "    display_animation(screen2, 2)\n",
    "    display_animation(screen3, None)\n",
    "\n",
    "    # plot your reward vs the agent's reward\n",
    "    plot_rewards()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"\\nThe most recent call arrival was at \" + str(previous_arrival) + \", and ambulance \" + str(previous_arrival_ind+1) + \" responded to the call.\\n\")\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    if not done:\n",
    "        cont = input(\"Continue? [y/n]\")\n",
    "        if cont == \"n\":\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "\n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "\n",
    "if np.sum(your_rewards) > np.sum(heuristic_agent_rewards):\n",
    "    print(\"CONGRATS! You beat the RL algorithm.\")\n",
    "else:\n",
    "    print(\"You did not get a better reward than the RL algorithm.\")\n",
    "\n",
    "print(\"\\nYour total reward over all iterations was \", round(sum(your_rewards),3))\n",
    "print(\"The RL algorithm's total reward over all iterations was \", round(sum(heuristic_agent_rewards),3), \"\\n\")\n",
    "\n",
    "plot_rewards()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-aruba",
   "metadata": {},
   "source": [
    "This problem is well-studied in the setting where the number of ambulances $k$ is small and in simple metric spaces.  However,\n",
    "\n",
    "- When the number of ambulances $k$ increases the complexity of the optimal policy increases dramatically\n",
    "- In real-world situations, the problem gets complicated in more 'realistic' metrics (and a dataset based in Ithaca is provided)\n",
    "- People construct a weighted metric for algorithm design, one cares about evaluating and balancing between multiple metrics\n",
    "- How to evaluate if your RL algorithm is good? Need to benchmark against well-known heuristics for this problem to understand the value that RL approach brings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-burst",
   "metadata": {},
   "source": [
    "# Sample Simulation and Research Questions\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-going",
   "metadata": {},
   "source": [
    "## Step 1: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-keyboard",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Monitor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8ec8b2cabd1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mambulance_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Ambulance-v0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmon_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mambulance_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Monitor' is not defined"
     ]
    }
   ],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 10\n",
    "numIters = 2\n",
    "\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1]\n",
    "\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)\n",
    "\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-shooting",
   "metadata": {},
   "source": [
    "##  Step 2: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-amplifier",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mon_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1c8e67c14aeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;34m'Random'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;34m'Stable'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mambulance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstableAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epLen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m'Median'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mambulance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedianAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epLen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mon_env' is not defined"
     ]
    }
   ],
   "source": [
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "##  Step 3: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "honest-equipment",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3443a530a19c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath_list_radar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malgo_list_radar\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dirPath'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/ambulance_metric_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ambulance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrival_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agents' is not defined"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-boutique",
   "metadata": {},
   "source": [
    "## Step 4: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions.  Also able to produce heat maps with additional custom metrics, here taken to be the mean response time and variance of mean response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4cdd7df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arrival_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8bf96e2027f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../figures/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfig_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ambulance_metric'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ambulance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrival_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_line_plot'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pdf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_line_plots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_list_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo_list_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnEps\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), \n",
      "\u001b[1;31mNameError\u001b[0m: name 'arrival_dist' is not defined"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), \n",
    "                     'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-little",
   "metadata": {},
   "source": [
    "![title](ambulance_metric_1_0.25_beta_line_plot-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-calvin",
   "metadata": {},
   "source": [
    "![title](ambulance_metric_1_0.25_beta_radar_plot-1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
