{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tender-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-unknown",
   "metadata": {},
   "source": [
    "# OR Suite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "##  Ambulance Routing Environment\n",
    "\n",
    "One potential application of reinforcement learning involves positioning a server or servers (in this case an ambulance) in an optimal way geographically to respond to incoming calls while minimizing the distance traveled by the servers. \n",
    "\n",
    "This is closely related to the [k-server problem](https://en.wikipedia.org/wiki/K-server_problem), where there are $k$ servers stationed in a space that must respond to requests arriving in that space in such a way as to minimize the total distance traveled. \n",
    "\n",
    "The ambulance routing problem addresses the problem by modeling an environment where there are ambulances stationed at locations, and calls come in that one of the ambulances must be sent to respond to. The goal of the agent is to minimize both the distance traveled by the ambulances between calls and the distance traveled to respond to a call by optimally choosing the locations to station the ambulances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-carry",
   "metadata": {},
   "source": [
    "### Environment Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The most recent call arrival was at 0.85230744, and ambulance 2 responded to the call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyvirtualdisplay import Display\n",
    "# display = Display(visible=0, size=(500, 800))\n",
    "# display.start()\n",
    "\n",
    "import or_suite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "a = 5\n",
    "b = 2\n",
    "CONFIG = {'epLen': 5,\n",
    "    'arrival_dist': lambda x : np.random.beta(a,b), \n",
    "    'alpha': 0.25, \n",
    "    'starting_state': np.array([0.0, 0.0]), \n",
    "    'num_ambulance': 2,\n",
    "    'norm': 1\n",
    "}\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "epLen = CONFIG['epLen']\n",
    "state = CONFIG['starting_state']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "agent = or_suite.agents.ambulance.command_line_metric.commandLineAgent(epLen)\n",
    "env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "env.reset()\n",
    "\n",
    "\n",
    "done = False\n",
    "your_rewards = []\n",
    "heuristic_agent_rewards = []\n",
    "your_total_reward = 0\n",
    "heuristic_agent_total_reward = 0\n",
    "\n",
    "median_est = (a - 1/3)/(a + b - 2/3)\n",
    "heuristic_agent_states = [state]\n",
    "\n",
    "x_axis = ['Your Reward So Far', 'RL Algorithm Reward So Far']\n",
    "\n",
    "\n",
    "def display_animation(screen, time_to_display):\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    if time_to_display is not None:\n",
    "        ipythondisplay.display(plt.gcf())\n",
    "        time.sleep(time_to_display)\n",
    "\n",
    "def plot_rewards():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    y_axis = [your_total_reward, heuristic_agent_total_reward]\n",
    "    ax.bar(x_axis, y_axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = agent.greedy(state, 0)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    your_rewards.append(reward)\n",
    "    your_total_reward += reward\n",
    "\n",
    "    # by comparing the final state with the action the user chose, we can figure out where the most recent arrival was\n",
    "    previous_arrival_ind = np.argmax(np.abs(action - state))\n",
    "    previous_arrival = state[previous_arrival_ind]\n",
    "\n",
    "    # the heuristic agent always chooses to put all the ambulances at the median estimate\n",
    "    heuristic_agent_action = np.full(num_ambulance, median_est)\n",
    "\n",
    "    # the state will have one ambulance where the call arrived, and all other ambulances at the median estimate\n",
    "    # doesn't matter which ambulance responds to the call because they're all at the same place\n",
    "    heuristic_agent_state = np.concatenate([np.full(num_ambulance - 1, median_est), [previous_arrival]])\n",
    "    heuristic_agent_states.append(heuristic_agent_state)\n",
    "\n",
    "    heuristic_agent_reward = -1 * (alpha * np.sum(np.abs(heuristic_agent_states[-2] - heuristic_agent_action)) + (1 - alpha) * np.sum(np.abs(heuristic_agent_action - heuristic_agent_state)))\n",
    "    heuristic_agent_rewards.append(heuristic_agent_reward)\n",
    "    heuristic_agent_total_reward += heuristic_agent_reward\n",
    "\n",
    "    screen1, screen2, screen3 = env.render(mode='rgb_array')\n",
    "\n",
    "    # display each step of the environment for 2 seconds\n",
    "    display_animation(screen1, 2)\n",
    "    display_animation(screen2, 2)\n",
    "    display_animation(screen3, None)\n",
    "\n",
    "    # plot your reward vs the agent's reward\n",
    "    plot_rewards()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"\\nThe most recent call arrival was at \" + str(previous_arrival) + \", and ambulance \" + str(previous_arrival_ind+1) + \" responded to the call.\\n\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "\n",
    "if np.sum(your_rewards) >= np.sum(heuristic_agent_rewards):\n",
    "    print(\"CONGRATS! You beat the RL algorithm.\")\n",
    "else:\n",
    "    print(\"You did not get a better reward than the RL algorithm.\")\n",
    "\n",
    "print(\"\\nYour total reward over all iterations was \", round(sum(your_rewards),3))\n",
    "print(\"The RL algorithm's total reward over all iterations was \", round(sum(heuristic_agent_rewards),3), \"\\n\")\n",
    "\n",
    "plot_rewards()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-aruba",
   "metadata": {},
   "source": [
    "This problem is well-studied in the setting where the number of ambulances $k$ is small and in simple metric spaces.  However,\n",
    "\n",
    "- When the number of ambulances $k$ increases the complexity of the optimal policy increases dramatically\n",
    "- In real-world situations, the problem gets complicated in more 'realistic' metrics (and a dataset based in Ithaca is provided)\n",
    "- People construct a weighted metric for algorithm design, one cares about evaluating and balancing between multiple metrics\n",
    "- How to evaluate if your RL algorithm is good? Need to benchmark against well-known heuristics for this problem to understand the value that RL approach brings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-burst",
   "metadata": {},
   "source": [
    "# Sample Simulation and Research Questions\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-going",
   "metadata": {},
   "source": [
    "## Step 1: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 10\n",
    "numIters = 2\n",
    "\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1]\n",
    "\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)\n",
    "\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-shooting",
   "metadata": {},
   "source": [
    "##  Step 2: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comprehensive-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/ORSuite/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:131: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a multiple of `n_steps * n_envs`.\n",
      "Info: (n_steps=5 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "##  Step 3: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "honest-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "    episode  iteration  epReward      time   memory\n",
      "0       0.0        0.0 -3.927940  3.959831  94951.0\n",
      "1       1.0        0.0 -2.500148 -3.124994  94951.0\n",
      "2       2.0        0.0 -2.114522 -3.576194  94951.0\n",
      "3       3.0        0.0 -1.948467 -3.654954  94951.0\n",
      "4       4.0        0.0 -2.950986 -3.654336  94951.0\n",
      "5       5.0        0.0 -2.437399 -3.668028  94951.0\n",
      "6       6.0        0.0 -2.632736 -3.530047  94951.0\n",
      "7       7.0        0.0 -2.171364 -3.557597  94951.0\n",
      "8       8.0        0.0 -1.536380 -3.469091  94951.0\n",
      "9       9.0        0.0 -2.254550 -3.617135  94951.0\n",
      "10      0.0        1.0 -1.734827 -3.625048  19493.0\n",
      "11      1.0        1.0 -2.070288 -3.632466  19493.0\n",
      "12      2.0        1.0 -1.934925 -3.570696  19493.0\n",
      "13      3.0        1.0 -1.355955 -3.631016  19493.0\n",
      "14      4.0        1.0 -1.224024 -3.610711  19493.0\n",
      "15      5.0        1.0 -0.999370 -3.421341  19493.0\n",
      "16      6.0        1.0 -1.958936 -3.323839  19493.0\n",
      "17      7.0        1.0 -1.606136 -3.346225  19493.0\n",
      "18      8.0        1.0 -2.109197 -3.372816  19493.0\n",
      "19      9.0        1.0 -1.781273 -3.435194  19493.0\n",
      "Writing to file ../data/ambulance_metric_SB PPO_1_0.25_beta/data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "Stable\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "Median\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-boutique",
   "metadata": {},
   "source": [
    "## Step 4: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions.  Also able to produce heat maps with additional custom metrics, here taken to be the mean response time and variance of mean response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cdd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm    Reward     Time   Space       MRT       RTV\n",
      "0    Random -1.249850  7.06612 -4590.0 -0.319004 -0.058231\n",
      "1    Stable -1.066685  7.70439 -4008.0 -0.285258 -0.065575\n",
      "2    Median -1.049120  6.55081 -6804.0 -0.153848 -0.024495\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), \n",
    "                     'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-little",
   "metadata": {},
   "source": [
    "![title](ambulance_metric_1_0.25_beta_line_plot-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-calvin",
   "metadata": {},
   "source": [
    "![title](ambulance_metric_1_0.25_beta_radar_plot-1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
