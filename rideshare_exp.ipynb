{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment for Ridesharing\n",
    "\n",
    "* The graphs that are being compared is K4 and K3-K3.\n",
    "* high_threshold, low_threshold controls the threshold level for the experiment.\n",
    "* All the uniform edges' length are 10; for non-uniform edges' length are sampled from $U[0,20]$, its expected value being 10\n",
    "* The average (expected) distance between two location is 10 and 10.9 for K4 and K3-K3, but were both rounded to 10 for convenience.\n",
    "* has_travel_time will control which version of the environment will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_threshold = 1 #multiplied to the max_distance \n",
    "low_threshold = 1/5 #multiplied to the average distance \n",
    "has_travel_time = True\n",
    "algo_tune_on = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Uniform  K4 graph with high d_threshold \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_default_config\n",
    "CONFIG['epLen'] = 500\n",
    "CONFIG['d_threshold'] = 10 * high_threshold\n",
    "CONFIG['velocity'] = 10\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "#Choosing whether to have travel time or not\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l5/43sgrxps7lbcv1k2xnpw4g5h0000gn/T/ipykernel_1697/2619255425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dirPath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/rideshare_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo_tune_on\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'maxweightfixed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_algo_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrideshare_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SB PPO'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_sb_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/ORSuite/or_suite/utils.py\u001b[0m in \u001b[0;36mrun_single_algo_tune\u001b[0;34m(env, agent, param_list, settings)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         dt = pd.DataFrame(exp.data, columns=[\n\u001b[1;32m     37\u001b[0m                           'episode', 'iteration', 'epReward', 'memory', 'time'])\n",
      "\u001b[0;32m~/Developer/ORSuite/or_suite/experiment/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;31m# steps based on the action chosen by the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mnewState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0mepReward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/ORSuite/or_suite/envs/ridesharing/rideshare_graph_traveltime.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0msink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mdispatch_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mservice_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msink\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm       Reward      Time      Space\n",
      "0  maxweightfixed  3531.163765  2.375589 -441014.16\n",
      "1      closestcar  4483.168529  2.587164 -440844.88\n",
      "2       randomcar  2398.653997  2.062932 -441077.32\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Uniform  K3-K3 graph with high d_threshold \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_exp_config\n",
    "CONFIG['epLen'] = 500\n",
    "CONFIG['d_threshold'] = 10 * high_threshold\n",
    "CONFIG['velocity'] = 10\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "#Choosing whether to have travel time or not\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm        Reward      Time      Space\n",
      "0  maxweightfixed  10989.883820  2.416813 -440958.88\n",
      "1      closestcar  11237.517524  2.529628 -440817.64\n",
      "2       randomcar   3608.045892  2.198912 -441181.92\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Non-Uniform  K4 graph with high d_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_default_config\n",
    "CONFIG['edges'] = [(0, 1, {'travel_time': 20*np.random.random()}), (0, 2, {'travel_time': 20*np.random.random()}),\n",
    "              (0, 3, {'travel_time': 20*np.random.random()}), (1, 2, {'travel_time': 20*np.random.random()}),\n",
    "              (1, 3, {'travel_time': 20*np.random.random()}), (2, 3, {'travel_time': 20*np.random.random()})]\n",
    "CONFIG['epLen'] = 500\n",
    "CONFIG['d_threshold'] = 10 * high_threshold\n",
    "CONFIG['velocity'] = 10\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm       Reward      Time      Space\n",
      "0  maxweightfixed  4772.902922  2.484235 -440882.04\n",
      "1      closestcar  5607.780025  2.533482 -440836.20\n",
      "2       randomcar  2723.752465  2.152308 -441229.60\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Non-Uniform  K3-K3 graph with high d_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_exp_config\n",
    "CONFIG['edges'] = [(0, 1, {'travel_time': 20*np.random.random()}), (1, 2, {'travel_time': 20*np.random.random()}),\n",
    "              (2, 0, {'travel_time': 20*np.random.random()}), (2, 3, {'travel_time': 20*np.random.random()}),\n",
    "              (3, 4, {'travel_time': 20*np.random.random()}), (4, 5, {'travel_time': 20*np.random.random()}),\n",
    "              (5, 6, {'travel_time': 20*np.random.random()}), (6, 4, {'travel_time': 20*np.random.random()})]\n",
    "CONFIG['epLen'] = 500\n",
    "CONFIG['d_threshold'] = 10 * high_threshold\n",
    "CONFIG['velocity'] = 10\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm        Reward      Time      Space\n",
      "0  maxweightfixed  10412.651263  2.503043 -440784.44\n",
      "1      closestcar  10769.354085  2.506936 -440892.80\n",
      "2       randomcar   3798.213340  2.198292 -441186.16\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Uniform  K4 graph with low d_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_default_config\n",
    "CONFIG['d_threshold'] = 10 * low_threshold\n",
    "CONFIG['epLen'] = 500\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm       Reward      Time      Space\n",
      "0  maxweightfixed  4356.215876  2.425546 -440822.52\n",
      "1      closestcar  4396.401259  2.564764 -440986.04\n",
      "2       randomcar  1556.018024  2.193008 -441089.24\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Uniform  K3-K3 graph with low d_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_exp_config\n",
    "CONFIG['d_threshold'] = 10 * low_threshold\n",
    "CONFIG['velocity'] = 10\n",
    "CONFIG['epLen'] = 500\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm       Reward      Time      Space\n",
      "0  maxweightfixed  7859.155404  2.452194 -440851.80\n",
      "1      closestcar  7937.273271  2.609725 -440993.44\n",
      "2       randomcar  1886.209735  2.173129 -441234.40\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Non-Uniform  K4 graph with low d_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_default_config\n",
    "CONFIG['edges'] = [(0, 1, {'travel_time': 20*np.random.random()}), (0, 2, {'travel_time': 20*np.random.random()}),\n",
    "              (0, 3, {'travel_time': 20*np.random.random()}), (1, 2, {'travel_time': 20*np.random.random()}),\n",
    "              (1, 3, {'travel_time': 20*np.random.random()}), (2, 3, {'travel_time': 20*np.random.random()})]\n",
    "CONFIG['d_threshold'] = 10 * low_threshold\n",
    "CONFIG['velocity'] = 10\n",
    "CONFIG['epLen'] = 500\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm       Reward      Time      Space\n",
      "0  maxweightfixed  4356.215876  2.697894 -440843.36\n",
      "1      closestcar  4396.401259  2.722463 -441032.36\n",
      "2       randomcar  1556.018024  2.246346 -441112.24\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration for Non-Uniform  K3-K3 graph with low d_threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_exp_config\n",
    "CONFIG['edges'] = [(0, 1, {'travel_time': 20*np.random.random()}), (1, 2, {'travel_time': 20*np.random.random()}),\n",
    "              (2, 0, {'travel_time': 20*np.random.random()}), (2, 3, {'travel_time': 20*np.random.random()}),\n",
    "              (3, 4, {'travel_time': 20*np.random.random()}), (4, 5, {'travel_time': 20*np.random.random()}),\n",
    "              (5, 6, {'travel_time': 20*np.random.random()}), (6, 4, {'travel_time': 20*np.random.random()})]\n",
    "CONFIG['d_threshold'] = 10* low_threshold\n",
    "CONFIG['epLen'] = 500\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 2\n",
    "numIters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "num_nodes = len(starting_state)\n",
    "\n",
    "if has_travel_time :\n",
    "    rideshare_env = gym.make('Rideshare-v1', config=CONFIG)\n",
    "else :\n",
    "    rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { #'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "#'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'maxweightfixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], CONFIG, [1 for _ in range(num_nodes)]),\n",
    "'closestcar' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG),\n",
    "'randomcar' : or_suite.agents.rideshare.random_car.randomCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxweightfixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "closestcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "randomcar\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare_'+str(agent)+'_'+str(num_cars)\n",
    "    if algo_tune_on and agent == 'maxweightfixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/rideshare_'+str(agent)+'_'+str(num_cars))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Algorithm       Reward      Time      Space\n",
      "0  maxweightfixed  7859.155404  2.493376 -441005.56\n",
      "1      closestcar  7937.273271  2.595409 -440856.44\n",
      "2       randomcar  1886.209735  2.240480 -441258.72\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare_'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'rideshare_'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42d2a0fd935109bf7af0945201a4df1598f849f59a8941473aae5806272937b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ORSuite': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
