{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bfc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69fe2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = or_suite.envs.env_configs.airline_default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc75b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an instance of the environment\n",
    "env = gym.make('Airline-v0',config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d267a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2.]\n",
      "MultiBinary(24)\n",
      "MultiDiscrete([3 3 3 3 3 3])\n"
     ]
    }
   ],
   "source": [
    "print(env.state)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1933a1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 2. 2. 2. 2.]\n",
      "140\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "action = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "# testing the step function\n",
    "newState, reward,  done, info = env.step(action)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831392a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 2. 2. 2. 2.]\n",
      "165\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(action)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "034ab0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 2. 2. 2. 2.]\n",
      "140\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(action)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d841618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 2. 2. 2. 2.]\n",
      "0.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(action)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd47aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661c5ff",
   "metadata": {},
   "source": [
    "# Vaccine Allotment Code Demonstration\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook we walk through generating plots, and applying the problem to the `vaccine allotment` problem with a population of size $P$ split into four risk classes, a discrete state space $\\mathcal{S} = \\{0, 1, 2, \\ldots, P\\}^{11}$, and a discrete action space consisting of \"priority orders\" corresponding to how we allot vaccines to the four risk classes. In this case, a valid priority order is one of two options: \n",
    "1. an empty list -- interpreted as no priority order, meaning we vaccinate the population randomly\n",
    "2. a permutation of the numbers $\\{1,2,3,4\\}$ -- interpreted as the order in which we vaccinate the risk classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8b32d",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Packages\n",
    "\n",
    "The main package for ORSuite is contained in `or_suite`.  However, some additional packages may be required for specific environments / algorithms.  Here, we include `stable baselines`, a package containing implementation for state of the art deep RL algorithms, and `matploblib` for the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76309c2e",
   "metadata": {},
   "source": [
    "### Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG = or_suite.envs.env_configs.vaccine_default_config1\n",
    "epLen = DEFAULT_CONFIG['epLen']\n",
    "nEps = 200\n",
    "numIters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1680ee",
   "metadata": {},
   "source": [
    "### Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation.  This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cf096",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/vaccine/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters,\n",
    "                    'render': False,\n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'pickle': False}\n",
    "\n",
    "vaccine_env = gym.make('Vaccine-v0', config=DEFAULT_CONFIG)\n",
    "mon_env = Monitor(vaccine_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c3347",
   "metadata": {},
   "source": [
    "### Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `random` policy, and some `RL discretization based` algorithms.  Here we pick a couple of the heuristics, and a PPO algorithm implemented from `stable baselines` just to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "          'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a1d66",
   "metadata": {},
   "source": [
    "### Step 5: Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or_suite.utils.run_single_algo(mon_env, agents['Random'], DEFAULT_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/vaccine_metric_test_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(mon_env, agents[agent], DEFAULT_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18542c50",
   "metadata": {},
   "source": [
    "### Step 6: Generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Plots for just the random agent\n",
    "\n",
    "path_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_line = []\n",
    "algo_list_radar = []\n",
    "\n",
    "#print(str(agents['Random']))\n",
    "path_list_line.append('../data/vaccine_metric_test_'+'Random')\n",
    "algo_list_line.append(\"Random\")\n",
    "path_list_radar.append('../data/vaccine_metric_test_'+'Random'+'/')\n",
    "algo_list_radar.append(\"Random\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Plots for just the random agent\n",
    "\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'test_vaccine_metric.pdf'\n",
    "\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40) + 1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18bf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y))}\n",
    "\n",
    "#or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar, fig_path, fig_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_line = []\n",
    "algo_list_radar = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(str(agent))\n",
    "    path_list_line.append('../data/vaccine_metric_test_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':    \n",
    "        path_list_radar.append('../data/vaccine_metric_test_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))\n",
    "\n",
    "    \n",
    "\n",
    "fig_path = '../figures/'\n",
    "fig_name1 = 'test_vaccine_metric_line.pdf'\n",
    "fig_name2 = 'test_vaccine_metric_radar.pdf'\n",
    "\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name1, int(nEps / 40) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_metric = None\n",
    "\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar, fig_path, fig_name2, additional_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c8f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
