{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-unknown",
   "metadata": {},
   "source": [
    "# OR Suite \n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making, including inventory control, resource allocation, ridesharing systems, and ambulance routing. In these models, an agent interacts with a system that has stochastic transitions and rewards, and aims to control the system by maximizing their cumulative rewards across the trajectory. Reinforcement learning has been shown in practice to be an effective technique for learning complex control policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "# Ambulance Routing Code Demo\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook, we walk through the Ambulance Routing problem with a 1-dimensional reinforcement learning environment in the space $X = [0, 1]$. Each ambulance in the problem can be located anywhere in $X$, so the state space is $S = X^k$, where $k$ is the number of ambulances. For this example there will be only one ambulance, so $k = 1$.\n",
    "\n",
    "The default distribution for call arrivals is $Beta(5, 2)$ over $[0,1]$, however any probability distribution defined over the interval $[0,1]$ is valid. The probability distribution can also change with each timestep.\n",
    "\n",
    "For example, in a problem with two ambulances, imagine the ambulances are initially located at $0.4$ and $0.6$, and the distance function being used is the $\\ell_1$ norm. The agent could choose to move the ambulances to $0.342$ and $0.887$. If a call arrived at $0.115$, ambulance 1, which was at $0.342$, would respond to that call, and the state at the end of the iteration would be ambulance 1 at $0.115$ and ambulance 2 at $0.887$. The agent could then choose new locations to move the ambulances to, and the cycle would repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-universe",
   "metadata": {},
   "source": [
    "# Step 1: Package Installation\n",
    "First we import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-burst",
   "metadata": {},
   "source": [
    "# Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1, 0.3, 1, 5]\n",
    "\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-going",
   "metadata": {},
   "source": [
    "# Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-shooting",
   "metadata": {},
   "source": [
    "# Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comprehensive-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "#'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "#'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "#'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "# 'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "# 'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "# 'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "# 'Command Line': or_suite.agents.ambulance.command_line_metric.commandLineAgent(CONFIG['epLen'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "honest-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "new state: [0.9017086]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 0, 'step': 0, 'oldState': array([0.]), 'action': array([0.9178641], dtype=float32), 'reward': -0.24158263206481934, 'newState': array([0.9017086], dtype=float32), 'info': {'arrival': 0.9017086254601233}}\n",
      "new state: [0.8516732]\n",
      "old state: [0.9017086]\n",
      "{'iter': 0, 'episode': 0, 'step': 1, 'oldState': array([0.9017086], dtype=float32), 'action': array([0.23102365], dtype=float32), 'reward': -0.6331583708524704, 'newState': array([0.8516732], dtype=float32), 'info': {'arrival': 0.8516731965445568}}\n",
      "new state: [0.91692984]\n",
      "old state: [0.8516732]\n",
      "{'iter': 0, 'episode': 0, 'step': 2, 'oldState': array([0.8516732], dtype=float32), 'action': array([0.02058637], dtype=float32), 'reward': -0.8800293058156967, 'newState': array([0.91692984], dtype=float32), 'info': {'arrival': 0.9169298378289636}}\n",
      "new state: [0.98049366]\n",
      "old state: [0.91692984]\n",
      "{'iter': 0, 'episode': 0, 'step': 3, 'oldState': array([0.91692984], dtype=float32), 'action': array([0.89905876], dtype=float32), 'reward': -0.06554394960403442, 'newState': array([0.98049366], dtype=float32), 'info': {'arrival': 0.9804936830220771}}\n",
      "new state: [0.9252191]\n",
      "old state: [0.98049366]\n",
      "{'iter': 0, 'episode': 0, 'step': 4, 'oldState': array([0.98049366], dtype=float32), 'action': array([0.383242], dtype=float32), 'reward': -0.55579574406147, 'newState': array([0.9252191], dtype=float32), 'info': {'arrival': 0.9252191190474063}}\n",
      "new state: [0.8481079]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 1, 'step': 0, 'oldState': array([0.]), 'action': array([0.12607136], dtype=float32), 'reward': -0.5730452015995979, 'newState': array([0.8481079], dtype=float32), 'info': {'arrival': 0.8481078503559737}}\n",
      "new state: [0.42419007]\n",
      "old state: [0.8481079]\n",
      "{'iter': 0, 'episode': 1, 'step': 1, 'oldState': array([0.8481079], dtype=float32), 'action': array([0.6871144], dtype=float32), 'reward': -0.23744162172079086, 'newState': array([0.42419007], dtype=float32), 'info': {'arrival': 0.4241900611065423}}\n",
      "new state: [0.8810905]\n",
      "old state: [0.42419007]\n",
      "{'iter': 0, 'episode': 1, 'step': 2, 'oldState': array([0.42419007], dtype=float32), 'action': array([0.9020919], dtype=float32), 'reward': -0.1352265104651451, 'newState': array([0.8810905], dtype=float32), 'info': {'arrival': 0.8810905037530262}}\n",
      "new state: [0.62667096]\n",
      "old state: [0.8810905]\n",
      "{'iter': 0, 'episode': 1, 'step': 3, 'oldState': array([0.8810905], dtype=float32), 'action': array([0.6405762], dtype=float32), 'reward': -0.07055750489234924, 'newState': array([0.62667096], dtype=float32), 'info': {'arrival': 0.6266709773183278}}\n",
      "new state: [0.8072047]\n",
      "old state: [0.62667096]\n",
      "{'iter': 0, 'episode': 1, 'step': 4, 'oldState': array([0.62667096], dtype=float32), 'action': array([0.49584377], dtype=float32), 'reward': -0.26622751355171204, 'newState': array([0.8072047], dtype=float32), 'info': {'arrival': 0.8072047395760044}}\n",
      "new state: [0.57092637]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 2, 'step': 0, 'oldState': array([0.]), 'action': array([0.91217273], dtype=float32), 'reward': -0.48397795855998993, 'newState': array([0.57092637], dtype=float32), 'info': {'arrival': 0.5709263410105393}}\n",
      "new state: [0.8481798]\n",
      "old state: [0.57092637]\n",
      "{'iter': 0, 'episode': 2, 'step': 1, 'oldState': array([0.57092637], dtype=float32), 'action': array([0.3495812], dtype=float32), 'reward': -0.4292852431535721, 'newState': array([0.8481798], dtype=float32), 'info': {'arrival': 0.8481798221726445}}\n",
      "new state: [0.83091414]\n",
      "old state: [0.8481798]\n",
      "{'iter': 0, 'episode': 2, 'step': 2, 'oldState': array([0.8481798], dtype=float32), 'action': array([0.7653994], dtype=float32), 'reward': -0.06983116269111633, 'newState': array([0.83091414], dtype=float32), 'info': {'arrival': 0.8309141393089935}}\n",
      "new state: [0.65500784]\n",
      "old state: [0.83091414]\n",
      "{'iter': 0, 'episode': 2, 'step': 3, 'oldState': array([0.83091414], dtype=float32), 'action': array([0.91468084], dtype=float32), 'reward': -0.21569642424583435, 'newState': array([0.65500784], dtype=float32), 'info': {'arrival': 0.655007827910831}}\n",
      "new state: [0.81023175]\n",
      "old state: [0.65500784]\n",
      "{'iter': 0, 'episode': 2, 'step': 4, 'oldState': array([0.65500784], dtype=float32), 'action': array([0.17010538], dtype=float32), 'reward': -0.6013203710317612, 'newState': array([0.81023175], dtype=float32), 'info': {'arrival': 0.8102317351053919}}\n",
      "new state: [0.62438935]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 3, 'step': 0, 'oldState': array([0.]), 'action': array([0.37235615], dtype=float32), 'reward': -0.2821139395236969, 'newState': array([0.62438935], dtype=float32), 'info': {'arrival': 0.6243893606344526}}\n",
      "new state: [0.6321625]\n",
      "old state: [0.62438935]\n",
      "{'iter': 0, 'episode': 3, 'step': 1, 'oldState': array([0.62438935], dtype=float32), 'action': array([0.2055788], dtype=float32), 'reward': -0.424640417098999, 'newState': array([0.6321625], dtype=float32), 'info': {'arrival': 0.6321624965389048}}\n",
      "new state: [0.8173362]\n",
      "old state: [0.6321625]\n",
      "{'iter': 0, 'episode': 3, 'step': 2, 'oldState': array([0.6321625], dtype=float32), 'action': array([0.36719397], dtype=float32), 'reward': -0.4038488119840622, 'newState': array([0.8173362], dtype=float32), 'info': {'arrival': 0.8173362025999291}}\n",
      "new state: [0.62698865]\n",
      "old state: [0.8173362]\n",
      "{'iter': 0, 'episode': 3, 'step': 3, 'oldState': array([0.8173362], dtype=float32), 'action': array([0.89715517], dtype=float32), 'reward': -0.22257962822914124, 'newState': array([0.62698865], dtype=float32), 'info': {'arrival': 0.6269886780619566}}\n",
      "new state: [0.9624207]\n",
      "old state: [0.62698865]\n",
      "{'iter': 0, 'episode': 3, 'step': 4, 'oldState': array([0.62698865], dtype=float32), 'action': array([0.43096635], dtype=float32), 'reward': -0.44759631901979446, 'newState': array([0.9624207], dtype=float32), 'info': {'arrival': 0.9624207107922589}}\n",
      "new state: [0.62033707]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 4, 'step': 0, 'oldState': array([0.]), 'action': array([0.58280724], dtype=float32), 'reward': -0.1738491803407669, 'newState': array([0.62033707], dtype=float32), 'info': {'arrival': 0.6203370717321872}}\n",
      "new state: [0.96731263]\n",
      "old state: [0.62033707]\n",
      "{'iter': 0, 'episode': 4, 'step': 1, 'oldState': array([0.62033707], dtype=float32), 'action': array([0.31692123], dtype=float32), 'reward': -0.5636475086212158, 'newState': array([0.96731263], dtype=float32), 'info': {'arrival': 0.967312654527899}}\n",
      "new state: [0.64461595]\n",
      "old state: [0.96731263]\n",
      "{'iter': 0, 'episode': 4, 'step': 2, 'oldState': array([0.96731263], dtype=float32), 'action': array([0.3124677], dtype=float32), 'reward': -0.412822425365448, 'newState': array([0.64461595], dtype=float32), 'info': {'arrival': 0.6446159286263234}}\n",
      "new state: [0.7473591]\n",
      "old state: [0.64461595]\n",
      "{'iter': 0, 'episode': 4, 'step': 3, 'oldState': array([0.64461595], dtype=float32), 'action': array([0.17320296], dtype=float32), 'reward': -0.5484703704714775, 'newState': array([0.7473591], dtype=float32), 'info': {'arrival': 0.7473590720440632}}\n",
      "new state: [0.73676896]\n",
      "old state: [0.7473591]\n",
      "{'iter': 0, 'episode': 4, 'step': 4, 'oldState': array([0.7473591], dtype=float32), 'action': array([0.48420492], dtype=float32), 'reward': -0.25521157681941986, 'newState': array([0.73676896], dtype=float32), 'info': {'arrival': 0.7367689572302917}}\n",
      "new state: [0.57878065]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 5, 'step': 0, 'oldState': array([0.]), 'action': array([0.24762446], dtype=float32), 'reward': -0.31027325987815857, 'newState': array([0.57878065], dtype=float32), 'info': {'arrival': 0.5787806441120279}}\n",
      "new state: [0.8008068]\n",
      "old state: [0.57878065]\n",
      "{'iter': 0, 'episode': 5, 'step': 1, 'oldState': array([0.57878065], dtype=float32), 'action': array([0.47500357], dtype=float32), 'reward': -0.27029670774936676, 'newState': array([0.8008068], dtype=float32), 'info': {'arrival': 0.8008068219943206}}\n",
      "new state: [0.69688046]\n",
      "old state: [0.8008068]\n",
      "{'iter': 0, 'episode': 5, 'step': 2, 'oldState': array([0.8008068], dtype=float32), 'action': array([0.61055076], dtype=float32), 'reward': -0.11231128871440887, 'newState': array([0.69688046], dtype=float32), 'info': {'arrival': 0.696880431600047}}\n",
      "new state: [0.49774563]\n",
      "old state: [0.69688046]\n",
      "{'iter': 0, 'episode': 5, 'step': 3, 'oldState': array([0.69688046], dtype=float32), 'action': array([0.20356171], dtype=float32), 'reward': -0.34396761655807495, 'newState': array([0.49774563], dtype=float32), 'info': {'arrival': 0.49774563109937137}}\n",
      "new state: [0.58565056]\n",
      "old state: [0.49774563]\n",
      "{'iter': 0, 'episode': 5, 'step': 4, 'oldState': array([0.49774563], dtype=float32), 'action': array([0.62759334], dtype=float32), 'reward': -0.06391900777816772, 'newState': array([0.58565056], dtype=float32), 'info': {'arrival': 0.5856505584454232}}\n",
      "new state: [0.9004541]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 6, 'step': 0, 'oldState': array([0.]), 'action': array([0.649475], dtype=float32), 'reward': -0.3506030887365341, 'newState': array([0.9004541], dtype=float32), 'info': {'arrival': 0.9004540896302045}}\n",
      "new state: [0.5201443]\n",
      "old state: [0.9004541]\n",
      "{'iter': 0, 'episode': 6, 'step': 1, 'oldState': array([0.9004541], dtype=float32), 'action': array([0.10748483], dtype=float32), 'reward': -0.5077369213104248, 'newState': array([0.5201443], dtype=float32), 'info': {'arrival': 0.5201442844736257}}\n",
      "new state: [0.9190038]\n",
      "old state: [0.5201443]\n",
      "{'iter': 0, 'episode': 6, 'step': 2, 'oldState': array([0.5201443], dtype=float32), 'action': array([0.20158732], dtype=float32), 'reward': -0.6177015900611877, 'newState': array([0.9190038], dtype=float32), 'info': {'arrival': 0.9190037628038885}}\n",
      "new state: [0.93285143]\n",
      "old state: [0.9190038]\n",
      "{'iter': 0, 'episode': 6, 'step': 3, 'oldState': array([0.9190038], dtype=float32), 'action': array([0.38781092], dtype=float32), 'reward': -0.5415785908699036, 'newState': array([0.93285143], dtype=float32), 'info': {'arrival': 0.9328514448116039}}\n",
      "new state: [0.84398466]\n",
      "old state: [0.93285143]\n",
      "{'iter': 0, 'episode': 6, 'step': 4, 'oldState': array([0.93285143], dtype=float32), 'action': array([0.38538322], dtype=float32), 'reward': -0.48081813007593155, 'newState': array([0.84398466], dtype=float32), 'info': {'arrival': 0.8439846618687031}}\n",
      "new state: [0.30684045]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 7, 'step': 0, 'oldState': array([0.]), 'action': array([0.5841373], dtype=float32), 'reward': -0.35400698333978653, 'newState': array([0.30684045], dtype=float32), 'info': {'arrival': 0.3068404524095928}}\n",
      "new state: [0.4531425]\n",
      "old state: [0.30684045]\n",
      "{'iter': 0, 'episode': 7, 'step': 1, 'oldState': array([0.30684045], dtype=float32), 'action': array([0.44865918], dtype=float32), 'reward': -0.03881716728210449, 'newState': array([0.4531425], dtype=float32), 'info': {'arrival': 0.453142486318069}}\n",
      "new state: [0.49986416]\n",
      "old state: [0.4531425]\n",
      "{'iter': 0, 'episode': 7, 'step': 2, 'oldState': array([0.4531425], dtype=float32), 'action': array([0.06651159], dtype=float32), 'reward': -0.42167216539382935, 'newState': array([0.49986416], dtype=float32), 'info': {'arrival': 0.49986417071417716}}\n",
      "new state: [0.87017006]\n",
      "old state: [0.49986416]\n",
      "{'iter': 0, 'episode': 7, 'step': 3, 'oldState': array([0.49986416], dtype=float32), 'action': array([0.4264369], dtype=float32), 'reward': -0.35115668177604675, 'newState': array([0.87017006], dtype=float32), 'info': {'arrival': 0.8701700413864164}}\n",
      "new state: [0.79310167]\n",
      "old state: [0.87017006]\n",
      "{'iter': 0, 'episode': 7, 'step': 4, 'oldState': array([0.87017006], dtype=float32), 'action': array([0.9584303], dtype=float32), 'reward': -0.14606152474880219, 'newState': array([0.79310167], dtype=float32), 'info': {'arrival': 0.793101648874233}}\n",
      "new state: [0.70594096]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 8, 'step': 0, 'oldState': array([0.]), 'action': array([0.44339657], dtype=float32), 'reward': -0.3077574372291565, 'newState': array([0.70594096], dtype=float32), 'info': {'arrival': 0.7059409676358296}}\n",
      "new state: [0.7614064]\n",
      "old state: [0.70594096]\n",
      "{'iter': 0, 'episode': 8, 'step': 1, 'oldState': array([0.70594096], dtype=float32), 'action': array([0.32164118], dtype=float32), 'reward': -0.42589887976646423, 'newState': array([0.7614064], dtype=float32), 'info': {'arrival': 0.7614064331351063}}\n",
      "new state: [0.65665084]\n",
      "old state: [0.7614064]\n",
      "{'iter': 0, 'episode': 8, 'step': 2, 'oldState': array([0.7614064], dtype=float32), 'action': array([0.14811772], dtype=float32), 'reward': -0.5347220152616501, 'newState': array([0.65665084], dtype=float32), 'info': {'arrival': 0.6566508283019078}}\n",
      "new state: [0.75985354]\n",
      "old state: [0.65665084]\n",
      "{'iter': 0, 'episode': 8, 'step': 3, 'oldState': array([0.65665084], dtype=float32), 'action': array([0.54404086], dtype=float32), 'reward': -0.19001200795173645, 'newState': array([0.75985354], dtype=float32), 'info': {'arrival': 0.7598535537086643}}\n",
      "new state: [0.7250078]\n",
      "old state: [0.75985354]\n",
      "{'iter': 0, 'episode': 8, 'step': 4, 'oldState': array([0.75985354], dtype=float32), 'action': array([0.9600275], dtype=float32), 'reward': -0.22630830109119415, 'newState': array([0.7250078], dtype=float32), 'info': {'arrival': 0.7250077671100035}}\n",
      "new state: [0.7087285]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 9, 'step': 0, 'oldState': array([0.]), 'action': array([0.58462864], dtype=float32), 'reward': -0.23923204839229584, 'newState': array([0.7087285], dtype=float32), 'info': {'arrival': 0.7087285163596484}}\n",
      "new state: [0.5417746]\n",
      "old state: [0.7087285]\n",
      "{'iter': 0, 'episode': 9, 'step': 1, 'oldState': array([0.7087285], dtype=float32), 'action': array([0.28296962], dtype=float32), 'reward': -0.3005434274673462, 'newState': array([0.5417746], dtype=float32), 'info': {'arrival': 0.5417745471689501}}\n",
      "new state: [0.4019758]\n",
      "old state: [0.5417746]\n",
      "{'iter': 0, 'episode': 9, 'step': 2, 'oldState': array([0.5417746], dtype=float32), 'action': array([0.92152447], dtype=float32), 'reward': -0.48459896445274353, 'newState': array([0.4019758], dtype=float32), 'info': {'arrival': 0.40197580382004}}\n",
      "new state: [0.17999922]\n",
      "old state: [0.4019758]\n",
      "{'iter': 0, 'episode': 9, 'step': 3, 'oldState': array([0.4019758], dtype=float32), 'action': array([0.05221219], dtype=float32), 'reward': -0.18328117579221725, 'newState': array([0.17999922], dtype=float32), 'info': {'arrival': 0.17999922155227596}}\n",
      "new state: [0.5064488]\n",
      "old state: [0.17999922]\n",
      "{'iter': 0, 'episode': 9, 'step': 4, 'oldState': array([0.17999922], dtype=float32), 'action': array([0.3806947], dtype=float32), 'reward': -0.14448945596814156, 'newState': array([0.5064488], dtype=float32), 'info': {'arrival': 0.5064487970659461}}\n",
      "new state: [0.88979363]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 10, 'step': 0, 'oldState': array([0.]), 'action': array([0.7234155], dtype=float32), 'reward': -0.3056374788284302, 'newState': array([0.88979363], dtype=float32), 'info': {'arrival': 0.8897936059564414}}\n",
      "new state: [0.77870876]\n",
      "old state: [0.88979363]\n",
      "{'iter': 0, 'episode': 10, 'step': 1, 'oldState': array([0.88979363], dtype=float32), 'action': array([0.99503756], dtype=float32), 'reward': -0.18855758011341095, 'newState': array([0.77870876], dtype=float32), 'info': {'arrival': 0.7787087521573837}}\n",
      "new state: [0.6270091]\n",
      "old state: [0.77870876]\n",
      "{'iter': 0, 'episode': 10, 'step': 2, 'oldState': array([0.77870876], dtype=float32), 'action': array([0.567789], dtype=float32), 'reward': -0.09714499115943909, 'newState': array([0.6270091], dtype=float32), 'info': {'arrival': 0.627009097695364}}\n",
      "new state: [0.44909468]\n",
      "old state: [0.6270091]\n",
      "{'iter': 0, 'episode': 10, 'step': 3, 'oldState': array([0.6270091], dtype=float32), 'action': array([0.10088542], dtype=float32), 'reward': -0.3926878571510315, 'newState': array([0.44909468], dtype=float32), 'info': {'arrival': 0.4490946878838044}}\n",
      "new state: [0.744725]\n",
      "old state: [0.44909468]\n",
      "{'iter': 0, 'episode': 10, 'step': 4, 'oldState': array([0.44909468], dtype=float32), 'action': array([0.4499924], dtype=float32), 'reward': -0.22127387672662735, 'newState': array([0.744725], dtype=float32), 'info': {'arrival': 0.7447249736527074}}\n",
      "new state: [0.8243231]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 11, 'step': 0, 'oldState': array([0.]), 'action': array([0.8736383], dtype=float32), 'reward': -0.25539593398571014, 'newState': array([0.8243231], dtype=float32), 'info': {'arrival': 0.8243230902643063}}\n",
      "new state: [0.9341989]\n",
      "old state: [0.8243231]\n",
      "{'iter': 0, 'episode': 11, 'step': 1, 'oldState': array([0.8243231], dtype=float32), 'action': array([0.54675764], dtype=float32), 'reward': -0.3599723279476166, 'newState': array([0.9341989], dtype=float32), 'info': {'arrival': 0.9341988946602923}}\n",
      "new state: [0.75056547]\n",
      "old state: [0.9341989]\n",
      "{'iter': 0, 'episode': 11, 'step': 2, 'oldState': array([0.9341989], dtype=float32), 'action': array([0.70264983], dtype=float32), 'reward': -0.09382399916648865, 'newState': array([0.75056547], dtype=float32), 'info': {'arrival': 0.7505654835721284}}\n",
      "new state: [0.88945013]\n",
      "old state: [0.75056547]\n",
      "{'iter': 0, 'episode': 11, 'step': 3, 'oldState': array([0.75056547], dtype=float32), 'action': array([0.95857275], dtype=float32), 'reward': -0.10384377837181091, 'newState': array([0.88945013], dtype=float32), 'info': {'arrival': 0.8894501182031804}}\n",
      "new state: [0.8156703]\n",
      "old state: [0.88945013]\n",
      "{'iter': 0, 'episode': 11, 'step': 4, 'oldState': array([0.88945013], dtype=float32), 'action': array([0.7192624], dtype=float32), 'reward': -0.11485284566879272, 'newState': array([0.8156703], dtype=float32), 'info': {'arrival': 0.8156702843975144}}\n",
      "new state: [0.61772424]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 12, 'step': 0, 'oldState': array([0.]), 'action': array([0.72842425], dtype=float32), 'reward': -0.26513107120990753, 'newState': array([0.61772424], dtype=float32), 'info': {'arrival': 0.6177242508077252}}\n",
      "new state: [0.51850754]\n",
      "old state: [0.61772424]\n",
      "{'iter': 0, 'episode': 12, 'step': 1, 'oldState': array([0.61772424], dtype=float32), 'action': array([0.10852765], dtype=float32), 'reward': -0.43478405475616455, 'newState': array([0.51850754], dtype=float32), 'info': {'arrival': 0.5185075641447854}}\n",
      "new state: [0.82281166]\n",
      "old state: [0.51850754]\n",
      "{'iter': 0, 'episode': 12, 'step': 2, 'oldState': array([0.51850754], dtype=float32), 'action': array([0.5545272], dtype=float32), 'reward': -0.21021825075149536, 'newState': array([0.82281166], dtype=float32), 'info': {'arrival': 0.8228116478279418}}\n",
      "new state: [0.6800098]\n",
      "old state: [0.82281166]\n",
      "{'iter': 0, 'episode': 12, 'step': 3, 'oldState': array([0.82281166], dtype=float32), 'action': array([0.6763843], dtype=float32), 'reward': -0.03932592272758484, 'newState': array([0.6800098], dtype=float32), 'info': {'arrival': 0.6800097740551242}}\n",
      "new state: [0.77143234]\n",
      "old state: [0.6800098]\n",
      "{'iter': 0, 'episode': 12, 'step': 4, 'oldState': array([0.6800098], dtype=float32), 'action': array([0.43734884], dtype=float32), 'reward': -0.31122785806655884, 'newState': array([0.77143234], dtype=float32), 'info': {'arrival': 0.7714323501101602}}\n",
      "new state: [0.89039636]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 13, 'step': 0, 'oldState': array([0.]), 'action': array([0.27430466], dtype=float32), 'reward': -0.5306449607014656, 'newState': array([0.89039636], dtype=float32), 'info': {'arrival': 0.8903963401468412}}\n",
      "new state: [0.85841686]\n",
      "old state: [0.89039636]\n",
      "{'iter': 0, 'episode': 13, 'step': 1, 'oldState': array([0.89039636], dtype=float32), 'action': array([0.33887064], dtype=float32), 'reward': -0.5275410860776901, 'newState': array([0.85841686], dtype=float32), 'info': {'arrival': 0.8584168347920407}}\n",
      "new state: [0.8370836]\n",
      "old state: [0.85841686]\n",
      "{'iter': 0, 'episode': 13, 'step': 2, 'oldState': array([0.85841686], dtype=float32), 'action': array([0.34237814], dtype=float32), 'reward': -0.5000387579202652, 'newState': array([0.8370836], dtype=float32), 'info': {'arrival': 0.83708360603603}}\n",
      "new state: [0.5439123]\n",
      "old state: [0.8370836]\n",
      "{'iter': 0, 'episode': 13, 'step': 3, 'oldState': array([0.8370836], dtype=float32), 'action': array([0.36122605], dtype=float32), 'reward': -0.255979061126709, 'newState': array([0.5439123], dtype=float32), 'info': {'arrival': 0.5439122682868344}}\n",
      "new state: [0.9850225]\n",
      "old state: [0.5439123]\n",
      "{'iter': 0, 'episode': 13, 'step': 4, 'oldState': array([0.5439123], dtype=float32), 'action': array([0.8565941], dtype=float32), 'reward': -0.174491748213768, 'newState': array([0.9850225], dtype=float32), 'info': {'arrival': 0.9850225021866104}}\n",
      "new state: [0.6316468]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 14, 'step': 0, 'oldState': array([0.]), 'action': array([0.9709146], dtype=float32), 'reward': -0.4971794933080673, 'newState': array([0.6316468], dtype=float32), 'info': {'arrival': 0.6316467870338943}}\n",
      "new state: [0.7699445]\n",
      "old state: [0.6316468]\n",
      "{'iter': 0, 'episode': 14, 'step': 1, 'oldState': array([0.6316468], dtype=float32), 'action': array([0.7125494], dtype=float32), 'reward': -0.06327196955680847, 'newState': array([0.7699445], dtype=float32), 'info': {'arrival': 0.7699445172841977}}\n",
      "new state: [0.41683495]\n",
      "old state: [0.7699445]\n",
      "{'iter': 0, 'episode': 14, 'step': 2, 'oldState': array([0.7699445], dtype=float32), 'action': array([0.8916982], dtype=float32), 'reward': -0.3865858465433121, 'newState': array([0.41683495], dtype=float32), 'info': {'arrival': 0.4168349629266814}}\n",
      "new state: [0.6543568]\n",
      "old state: [0.41683495]\n",
      "{'iter': 0, 'episode': 14, 'step': 3, 'oldState': array([0.41683495], dtype=float32), 'action': array([0.02616614], dtype=float32), 'reward': -0.5688101798295975, 'newState': array([0.6543568], dtype=float32), 'info': {'arrival': 0.6543567973664853}}\n",
      "new state: [0.6370027]\n",
      "old state: [0.6543568]\n",
      "{'iter': 0, 'episode': 14, 'step': 4, 'oldState': array([0.6543568], dtype=float32), 'action': array([0.20829508], dtype=float32), 'reward': -0.4330461472272873, 'newState': array([0.6370027], dtype=float32), 'info': {'arrival': 0.6370027173514268}}\n",
      "new state: [0.7565228]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 15, 'step': 0, 'oldState': array([0.]), 'action': array([0.74481034], dtype=float32), 'reward': -0.19498690962791443, 'newState': array([0.7565228], dtype=float32), 'info': {'arrival': 0.756522768314495}}\n",
      "new state: [0.9431816]\n",
      "old state: [0.7565228]\n",
      "{'iter': 0, 'episode': 15, 'step': 1, 'oldState': array([0.7565228], dtype=float32), 'action': array([0.22401223], dtype=float32), 'reward': -0.6725046634674072, 'newState': array([0.9431816], dtype=float32), 'info': {'arrival': 0.943181551564354}}\n",
      "new state: [0.9027671]\n",
      "old state: [0.9431816]\n",
      "{'iter': 0, 'episode': 15, 'step': 2, 'oldState': array([0.9431816], dtype=float32), 'action': array([0.3272741], dtype=float32), 'reward': -0.5855965912342072, 'newState': array([0.9027671], dtype=float32), 'info': {'arrival': 0.902767144405462}}\n",
      "new state: [0.6842214]\n",
      "old state: [0.9027671]\n",
      "{'iter': 0, 'episode': 15, 'step': 3, 'oldState': array([0.9027671], dtype=float32), 'action': array([0.8043023], dtype=float32), 'reward': -0.11467687785625458, 'newState': array([0.6842214], dtype=float32), 'info': {'arrival': 0.6842213748500587}}\n",
      "new state: [0.89529145]\n",
      "old state: [0.6842214]\n",
      "{'iter': 0, 'episode': 15, 'step': 4, 'oldState': array([0.6842214], dtype=float32), 'action': array([0.2457686], dtype=float32), 'reward': -0.59675532579422, 'newState': array([0.89529145], dtype=float32), 'info': {'arrival': 0.8952914508735211}}\n",
      "new state: [0.669926]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 16, 'step': 0, 'oldState': array([0.]), 'action': array([0.32597995], dtype=float32), 'reward': -0.3394545167684555, 'newState': array([0.669926], dtype=float32), 'info': {'arrival': 0.6699259791827223}}\n",
      "new state: [0.5962193]\n",
      "old state: [0.669926]\n",
      "{'iter': 0, 'episode': 16, 'step': 1, 'oldState': array([0.669926], dtype=float32), 'action': array([0.94089115], dtype=float32), 'reward': -0.32624517381191254, 'newState': array([0.5962193], dtype=float32), 'info': {'arrival': 0.5962193045964752}}\n",
      "new state: [0.9429948]\n",
      "old state: [0.5962193]\n",
      "{'iter': 0, 'episode': 16, 'step': 2, 'oldState': array([0.5962193], dtype=float32), 'action': array([0.44116423], dtype=float32), 'reward': -0.4151367023587227, 'newState': array([0.9429948], dtype=float32), 'info': {'arrival': 0.9429947830781332}}\n",
      "new state: [0.80094737]\n",
      "old state: [0.9429948]\n",
      "{'iter': 0, 'episode': 16, 'step': 3, 'oldState': array([0.9429948], dtype=float32), 'action': array([0.34042537], dtype=float32), 'reward': -0.49603384733200073, 'newState': array([0.80094737], dtype=float32), 'info': {'arrival': 0.8009473651536184}}\n",
      "new state: [0.83601063]\n",
      "old state: [0.80094737]\n",
      "{'iter': 0, 'episode': 16, 'step': 4, 'oldState': array([0.80094737], dtype=float32), 'action': array([0.8158232], dtype=float32), 'reward': -0.018859535455703735, 'newState': array([0.83601063], dtype=float32), 'info': {'arrival': 0.8360106319891155}}\n",
      "new state: [0.78272134]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 17, 'step': 0, 'oldState': array([0.]), 'action': array([0.7003152], dtype=float32), 'reward': -0.23688341677188873, 'newState': array([0.78272134], dtype=float32), 'info': {'arrival': 0.78272134535844}}\n",
      "new state: [0.7151336]\n",
      "old state: [0.78272134]\n",
      "{'iter': 0, 'episode': 17, 'step': 1, 'oldState': array([0.78272134], dtype=float32), 'action': array([0.60173], dtype=float32), 'reward': -0.13030055165290833, 'newState': array([0.7151336], dtype=float32), 'info': {'arrival': 0.7151336284614269}}\n",
      "new state: [0.7526974]\n",
      "old state: [0.7151336]\n",
      "{'iter': 0, 'episode': 17, 'step': 2, 'oldState': array([0.7151336], dtype=float32), 'action': array([0.80068064], dtype=float32), 'reward': -0.05737417936325073, 'newState': array([0.7526974], dtype=float32), 'info': {'arrival': 0.752697420764452}}\n",
      "new state: [0.5472593]\n",
      "old state: [0.7526974]\n",
      "{'iter': 0, 'episode': 17, 'step': 3, 'oldState': array([0.7526974], dtype=float32), 'action': array([0.52606386], dtype=float32), 'reward': -0.07255494594573975, 'newState': array([0.5472593], dtype=float32), 'info': {'arrival': 0.5472592683716826}}\n",
      "new state: [0.8365359]\n",
      "old state: [0.5472593]\n",
      "{'iter': 0, 'episode': 17, 'step': 4, 'oldState': array([0.5472593], dtype=float32), 'action': array([0.34007183], dtype=float32), 'reward': -0.4241448938846588, 'newState': array([0.8365359], dtype=float32), 'info': {'arrival': 0.8365358807965149}}\n",
      "new state: [0.9179384]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 18, 'step': 0, 'oldState': array([0.]), 'action': array([0.8936732], dtype=float32), 'reward': -0.24161721765995026, 'newState': array([0.9179384], dtype=float32), 'info': {'arrival': 0.9179383879048311}}\n",
      "new state: [0.5062346]\n",
      "old state: [0.9179384]\n",
      "{'iter': 0, 'episode': 18, 'step': 1, 'oldState': array([0.9179384], dtype=float32), 'action': array([0.72391605], dtype=float32), 'reward': -0.21176669001579285, 'newState': array([0.5062346], dtype=float32), 'info': {'arrival': 0.5062345937726601}}\n",
      "new state: [0.95677274]\n",
      "old state: [0.5062346]\n",
      "{'iter': 0, 'episode': 18, 'step': 2, 'oldState': array([0.5062346], dtype=float32), 'action': array([0.27147123], dtype=float32), 'reward': -0.5726669952273369, 'newState': array([0.95677274], dtype=float32), 'info': {'arrival': 0.9567727409369825}}\n",
      "new state: [0.6403544]\n",
      "old state: [0.95677274]\n",
      "{'iter': 0, 'episode': 18, 'step': 3, 'oldState': array([0.95677274], dtype=float32), 'action': array([0.06178644], dtype=float32), 'reward': -0.657672569155693, 'newState': array([0.6403544], dtype=float32), 'info': {'arrival': 0.6403544048301333}}\n",
      "new state: [0.72544855]\n",
      "old state: [0.6403544]\n",
      "{'iter': 0, 'episode': 18, 'step': 4, 'oldState': array([0.6403544], dtype=float32), 'action': array([0.92185825], dtype=float32), 'reward': -0.21768324077129364, 'newState': array([0.72544855], dtype=float32), 'info': {'arrival': 0.7254485615553437}}\n",
      "new state: [0.7481515]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 19, 'step': 0, 'oldState': array([0.]), 'action': array([0.40562496], dtype=float32), 'reward': -0.3583011329174042, 'newState': array([0.7481515], dtype=float32), 'info': {'arrival': 0.7481515045453815}}\n",
      "new state: [0.6952488]\n",
      "old state: [0.7481515]\n",
      "{'iter': 0, 'episode': 19, 'step': 1, 'oldState': array([0.7481515], dtype=float32), 'action': array([0.33172765], dtype=float32), 'reward': -0.37674680352211, 'newState': array([0.6952488], dtype=float32), 'info': {'arrival': 0.6952487693146072}}\n",
      "new state: [0.75657374]\n",
      "old state: [0.6952488]\n",
      "{'iter': 0, 'episode': 19, 'step': 2, 'oldState': array([0.6952488], dtype=float32), 'action': array([0.5223945], dtype=float32), 'reward': -0.21884801983833313, 'newState': array([0.75657374], dtype=float32), 'info': {'arrival': 0.7565737622029164}}\n",
      "new state: [0.8000286]\n",
      "old state: [0.75657374]\n",
      "{'iter': 0, 'episode': 19, 'step': 3, 'oldState': array([0.75657374], dtype=float32), 'action': array([0.59083897], dtype=float32), 'reward': -0.19832593202590942, 'newState': array([0.8000286], dtype=float32), 'info': {'arrival': 0.8000286240716391}}\n",
      "new state: [0.4252806]\n",
      "old state: [0.8000286]\n",
      "{'iter': 0, 'episode': 19, 'step': 4, 'oldState': array([0.8000286], dtype=float32), 'action': array([0.23935293], dtype=float32), 'reward': -0.2796146757900715, 'newState': array([0.4252806], dtype=float32), 'info': {'arrival': 0.42528059425530945}}\n",
      "new state: [0.99370295]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 20, 'step': 0, 'oldState': array([0.]), 'action': array([0.5633369], dtype=float32), 'reward': -0.4636087566614151, 'newState': array([0.99370295], dtype=float32), 'info': {'arrival': 0.9937029562988815}}\n",
      "new state: [0.74029833]\n",
      "old state: [0.99370295]\n",
      "{'iter': 0, 'episode': 20, 'step': 1, 'oldState': array([0.99370295], dtype=float32), 'action': array([0.7266847], dtype=float32), 'reward': -0.07696479558944702, 'newState': array([0.74029833], dtype=float32), 'info': {'arrival': 0.7402983341701184}}\n",
      "new state: [0.8505596]\n",
      "old state: [0.74029833]\n",
      "{'iter': 0, 'episode': 20, 'step': 2, 'oldState': array([0.74029833], dtype=float32), 'action': array([0.71738374], dtype=float32), 'reward': -0.10561053454875946, 'newState': array([0.8505596], dtype=float32), 'info': {'arrival': 0.8505595641662881}}\n",
      "new state: [0.9285689]\n",
      "old state: [0.8505596]\n",
      "{'iter': 0, 'episode': 20, 'step': 3, 'oldState': array([0.8505596], dtype=float32), 'action': array([0.42623577], dtype=float32), 'reward': -0.48283082991838455, 'newState': array([0.9285689], dtype=float32), 'info': {'arrival': 0.9285689178787047}}\n",
      "new state: [0.39496034]\n",
      "old state: [0.9285689]\n",
      "{'iter': 0, 'episode': 20, 'step': 4, 'oldState': array([0.9285689], dtype=float32), 'action': array([0.5716783], dtype=float32), 'reward': -0.22176110744476318, 'newState': array([0.39496034], dtype=float32), 'info': {'arrival': 0.3949603583409322}}\n",
      "new state: [0.6422371]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 21, 'step': 0, 'oldState': array([0.]), 'action': array([0.21654686], dtype=float32), 'reward': -0.3734044134616852, 'newState': array([0.6422371], dtype=float32), 'info': {'arrival': 0.6422371013687811}}\n",
      "new state: [0.7529722]\n",
      "old state: [0.6422371]\n",
      "{'iter': 0, 'episode': 21, 'step': 1, 'oldState': array([0.6422371], dtype=float32), 'action': array([0.40331495], dtype=float32), 'reward': -0.3219734728336334, 'newState': array([0.7529722], dtype=float32), 'info': {'arrival': 0.752972162579305}}\n",
      "new state: [0.30062705]\n",
      "old state: [0.7529722]\n",
      "{'iter': 0, 'episode': 21, 'step': 2, 'oldState': array([0.7529722], dtype=float32), 'action': array([0.4251114], dtype=float32), 'reward': -0.17532846331596375, 'newState': array([0.30062705], dtype=float32), 'info': {'arrival': 0.3006270660173386}}\n",
      "new state: [0.48875916]\n",
      "old state: [0.30062705]\n",
      "{'iter': 0, 'episode': 21, 'step': 3, 'oldState': array([0.30062705], dtype=float32), 'action': array([0.46771926], dtype=float32), 'reward': -0.05755297839641571, 'newState': array([0.48875916], dtype=float32), 'info': {'arrival': 0.4887591700041188}}\n",
      "new state: [0.42756724]\n",
      "old state: [0.48875916]\n",
      "{'iter': 0, 'episode': 21, 'step': 4, 'oldState': array([0.48875916], dtype=float32), 'action': array([0.8100554], dtype=float32), 'reward': -0.3671901524066925, 'newState': array([0.42756724], dtype=float32), 'info': {'arrival': 0.42756725584689426}}\n",
      "new state: [0.59046024]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 22, 'step': 0, 'oldState': array([0.]), 'action': array([0.10096328], dtype=float32), 'reward': -0.3923635296523571, 'newState': array([0.59046024], dtype=float32), 'info': {'arrival': 0.5904602197030132}}\n",
      "new state: [0.6815617]\n",
      "old state: [0.59046024]\n",
      "{'iter': 0, 'episode': 22, 'step': 1, 'oldState': array([0.59046024], dtype=float32), 'action': array([0.86960095], dtype=float32), 'reward': -0.21081461012363434, 'newState': array([0.6815617], dtype=float32), 'info': {'arrival': 0.681561728066073}}\n",
      "new state: [0.5713845]\n",
      "old state: [0.6815617]\n",
      "{'iter': 0, 'episode': 22, 'step': 2, 'oldState': array([0.6815617], dtype=float32), 'action': array([0.72926533], dtype=float32), 'reward': -0.13033653795719147, 'newState': array([0.5713845], dtype=float32), 'info': {'arrival': 0.5713844902364564}}\n",
      "new state: [0.5933]\n",
      "old state: [0.5713845]\n",
      "{'iter': 0, 'episode': 22, 'step': 3, 'oldState': array([0.5713845], dtype=float32), 'action': array([0.98117846], dtype=float32), 'reward': -0.3933573514223099, 'newState': array([0.5933], dtype=float32), 'info': {'arrival': 0.5932999566366682}}\n",
      "new state: [0.8421086]\n",
      "old state: [0.5933]\n",
      "{'iter': 0, 'episode': 22, 'step': 4, 'oldState': array([0.5933], dtype=float32), 'action': array([0.5476047], dtype=float32), 'reward': -0.2323017716407776, 'newState': array([0.8421086], dtype=float32), 'info': {'arrival': 0.8421085892553299}}\n",
      "new state: [0.7816002]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 23, 'step': 0, 'oldState': array([0.]), 'action': array([0.8405558], dtype=float32), 'reward': -0.25435565412044525, 'newState': array([0.7816002], dtype=float32), 'info': {'arrival': 0.7816002008073403}}\n",
      "new state: [0.5409215]\n",
      "old state: [0.7816002]\n",
      "{'iter': 0, 'episode': 23, 'step': 1, 'oldState': array([0.7816002], dtype=float32), 'action': array([0.5938531], dtype=float32), 'reward': -0.08663547039031982, 'newState': array([0.5409215], dtype=float32), 'info': {'arrival': 0.5409215134800991}}\n",
      "new state: [0.7420913]\n",
      "old state: [0.5409215]\n",
      "{'iter': 0, 'episode': 23, 'step': 2, 'oldState': array([0.5409215], dtype=float32), 'action': array([0.67743695], dtype=float32), 'reward': -0.08261962234973907, 'newState': array([0.7420913], dtype=float32), 'info': {'arrival': 0.7420913027469964}}\n",
      "new state: [0.59213036]\n",
      "old state: [0.7420913]\n",
      "{'iter': 0, 'episode': 23, 'step': 3, 'oldState': array([0.7420913], dtype=float32), 'action': array([0.67430717], dtype=float32), 'reward': -0.0785786360502243, 'newState': array([0.59213036], dtype=float32), 'info': {'arrival': 0.5921303565941431}}\n",
      "new state: [0.67436844]\n",
      "old state: [0.59213036]\n",
      "{'iter': 0, 'episode': 23, 'step': 4, 'oldState': array([0.59213036], dtype=float32), 'action': array([0.5699395], dtype=float32), 'reward': -0.08386942744255066, 'newState': array([0.67436844], dtype=float32), 'info': {'arrival': 0.6743684546223636}}\n",
      "new state: [0.6076709]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 24, 'step': 0, 'oldState': array([0.]), 'action': array([0.13745688], dtype=float32), 'reward': -0.38702472671866417, 'newState': array([0.6076709], dtype=float32), 'info': {'arrival': 0.6076709198259183}}\n",
      "new state: [0.94423956]\n",
      "old state: [0.6076709]\n",
      "{'iter': 0, 'episode': 24, 'step': 1, 'oldState': array([0.6076709], dtype=float32), 'action': array([0.12339085], dtype=float32), 'reward': -0.7367065399885178, 'newState': array([0.94423956], dtype=float32), 'info': {'arrival': 0.9442395436780368}}\n",
      "new state: [0.9123054]\n",
      "old state: [0.94423956]\n",
      "{'iter': 0, 'episode': 24, 'step': 2, 'oldState': array([0.94423956], dtype=float32), 'action': array([0.7204009], dtype=float32), 'reward': -0.19988802075386047, 'newState': array([0.9123054], dtype=float32), 'info': {'arrival': 0.9123054289259206}}\n",
      "new state: [0.8703384]\n",
      "old state: [0.9123054]\n",
      "{'iter': 0, 'episode': 24, 'step': 3, 'oldState': array([0.9123054], dtype=float32), 'action': array([0.8195547], dtype=float32), 'reward': -0.06127545237541199, 'newState': array([0.8703384], dtype=float32), 'info': {'arrival': 0.8703383623642161}}\n",
      "new state: [0.68086207]\n",
      "old state: [0.8703384]\n",
      "{'iter': 0, 'episode': 24, 'step': 4, 'oldState': array([0.8703384], dtype=float32), 'action': array([0.9155168], dtype=float32), 'reward': -0.1872856467962265, 'newState': array([0.68086207], dtype=float32), 'info': {'arrival': 0.6808620593797683}}\n",
      "new state: [0.7518473]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 25, 'step': 0, 'oldState': array([0.]), 'action': array([0.6153499], dtype=float32), 'reward': -0.2562105506658554, 'newState': array([0.7518473], dtype=float32), 'info': {'arrival': 0.7518473201580582}}\n",
      "new state: [0.50617105]\n",
      "old state: [0.7518473]\n",
      "{'iter': 0, 'episode': 25, 'step': 1, 'oldState': array([0.7518473], dtype=float32), 'action': array([0.16133316], dtype=float32), 'reward': -0.4062569737434387, 'newState': array([0.50617105], dtype=float32), 'info': {'arrival': 0.5061710495928101}}\n",
      "new state: [0.72491735]\n",
      "old state: [0.50617105]\n",
      "{'iter': 0, 'episode': 25, 'step': 2, 'oldState': array([0.50617105], dtype=float32), 'action': array([0.08785948], dtype=float32), 'reward': -0.5823713168501854, 'newState': array([0.72491735], dtype=float32), 'info': {'arrival': 0.7249173505759314}}\n",
      "new state: [0.76915413]\n",
      "old state: [0.72491735]\n",
      "{'iter': 0, 'episode': 25, 'step': 3, 'oldState': array([0.72491735], dtype=float32), 'action': array([0.22507457], dtype=float32), 'reward': -0.5330203473567963, 'newState': array([0.76915413], dtype=float32), 'info': {'arrival': 0.7691541464090966}}\n",
      "new state: [0.78877646]\n",
      "old state: [0.76915413]\n",
      "{'iter': 0, 'episode': 25, 'step': 4, 'oldState': array([0.76915413], dtype=float32), 'action': array([0.1434493], dtype=float32), 'reward': -0.6404215693473816, 'newState': array([0.78877646], dtype=float32), 'info': {'arrival': 0.788776448636388}}\n",
      "new state: [0.61505944]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 26, 'step': 0, 'oldState': array([0.]), 'action': array([0.6739051], dtype=float32), 'reward': -0.21261049807071686, 'newState': array([0.61505944], dtype=float32), 'info': {'arrival': 0.6150594565686524}}\n",
      "new state: [0.7944121]\n",
      "old state: [0.61505944]\n",
      "{'iter': 0, 'episode': 26, 'step': 1, 'oldState': array([0.61505944], dtype=float32), 'action': array([0.3845619], dtype=float32), 'reward': -0.3650120198726654, 'newState': array([0.7944121], dtype=float32), 'info': {'arrival': 0.7944120986601131}}\n",
      "new state: [0.62673867]\n",
      "old state: [0.7944121]\n",
      "{'iter': 0, 'episode': 26, 'step': 2, 'oldState': array([0.7944121], dtype=float32), 'action': array([0.24104933], dtype=float32), 'reward': -0.4276076704263687, 'newState': array([0.62673867], dtype=float32), 'info': {'arrival': 0.6267386805744021}}\n",
      "new state: [0.85970926]\n",
      "old state: [0.62673867]\n",
      "{'iter': 0, 'episode': 26, 'step': 3, 'oldState': array([0.62673867], dtype=float32), 'action': array([0.29196763], dtype=float32), 'reward': -0.5094989836215973, 'newState': array([0.85970926], dtype=float32), 'info': {'arrival': 0.859709264351954}}\n",
      "new state: [0.8386074]\n",
      "old state: [0.85970926]\n",
      "{'iter': 0, 'episode': 26, 'step': 4, 'oldState': array([0.85970926], dtype=float32), 'action': array([0.9957995], dtype=float32), 'reward': -0.15191663801670074, 'newState': array([0.8386074], dtype=float32), 'info': {'arrival': 0.8386073734186852}}\n",
      "new state: [0.70011574]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 27, 'step': 0, 'oldState': array([0.]), 'action': array([0.28540403], dtype=float32), 'reward': -0.382384791970253, 'newState': array([0.70011574], dtype=float32), 'info': {'arrival': 0.7001157162513402}}\n",
      "new state: [0.8205469]\n",
      "old state: [0.70011574]\n",
      "{'iter': 0, 'episode': 27, 'step': 1, 'oldState': array([0.70011574], dtype=float32), 'action': array([0.5530435], dtype=float32), 'reward': -0.23739564418792725, 'newState': array([0.8205469], dtype=float32), 'info': {'arrival': 0.8205469352659844}}\n",
      "new state: [0.77964085]\n",
      "old state: [0.8205469]\n",
      "{'iter': 0, 'episode': 27, 'step': 2, 'oldState': array([0.8205469], dtype=float32), 'action': array([0.4256428], dtype=float32), 'reward': -0.3642245829105377, 'newState': array([0.77964085], dtype=float32), 'info': {'arrival': 0.7796408702891356}}\n",
      "new state: [0.8303276]\n",
      "old state: [0.77964085]\n",
      "{'iter': 0, 'episode': 27, 'step': 3, 'oldState': array([0.77964085], dtype=float32), 'action': array([0.52312714], dtype=float32), 'reward': -0.2945287525653839, 'newState': array([0.8303276], dtype=float32), 'info': {'arrival': 0.8303275709736081}}\n",
      "new state: [0.49561754]\n",
      "old state: [0.8303276]\n",
      "{'iter': 0, 'episode': 27, 'step': 4, 'oldState': array([0.8303276], dtype=float32), 'action': array([0.23613136], dtype=float32), 'reward': -0.34316369891166687, 'newState': array([0.49561754], dtype=float32), 'info': {'arrival': 0.49561754322256973}}\n",
      "new state: [0.6514295]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 28, 'step': 0, 'oldState': array([0.]), 'action': array([0.41459495], dtype=float32), 'reward': -0.28127463161945343, 'newState': array([0.6514295], dtype=float32), 'info': {'arrival': 0.6514294852143766}}\n",
      "new state: [0.62700045]\n",
      "old state: [0.6514295]\n",
      "{'iter': 0, 'episode': 28, 'step': 1, 'oldState': array([0.6514295], dtype=float32), 'action': array([0.30825603], dtype=float32), 'reward': -0.3248516768217087, 'newState': array([0.62700045], dtype=float32), 'info': {'arrival': 0.6270004408036985}}\n",
      "new state: [0.8029695]\n",
      "old state: [0.62700045]\n",
      "{'iter': 0, 'episode': 28, 'step': 2, 'oldState': array([0.62700045], dtype=float32), 'action': array([0.99037755], dtype=float32), 'reward': -0.2314002960920334, 'newState': array([0.8029695], dtype=float32), 'info': {'arrival': 0.8029694908880644}}\n",
      "new state: [0.70654577]\n",
      "old state: [0.8029695]\n",
      "{'iter': 0, 'episode': 28, 'step': 3, 'oldState': array([0.8029695], dtype=float32), 'action': array([0.7806753], dtype=float32), 'reward': -0.06117069721221924, 'newState': array([0.70654577], dtype=float32), 'info': {'arrival': 0.7065457995952121}}\n",
      "new state: [0.42237693]\n",
      "old state: [0.70654577]\n",
      "{'iter': 0, 'episode': 28, 'step': 4, 'oldState': array([0.70654577], dtype=float32), 'action': array([0.26045105], dtype=float32), 'reward': -0.23296809196472168, 'newState': array([0.42237693], dtype=float32), 'info': {'arrival': 0.42237693601583565}}\n",
      "new state: [0.6969172]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 29, 'step': 0, 'oldState': array([0.]), 'action': array([0.05228974], dtype=float32), 'reward': -0.4965430237352848, 'newState': array([0.6969172], dtype=float32), 'info': {'arrival': 0.696917161885649}}\n",
      "new state: [0.67124915]\n",
      "old state: [0.6969172]\n",
      "{'iter': 0, 'episode': 29, 'step': 1, 'oldState': array([0.6969172], dtype=float32), 'action': array([0.9521573], dtype=float32), 'reward': -0.27449116110801697, 'newState': array([0.67124915], dtype=float32), 'info': {'arrival': 0.6712491262501076}}\n",
      "new state: [0.77023846]\n",
      "old state: [0.67124915]\n",
      "{'iter': 0, 'episode': 29, 'step': 2, 'oldState': array([0.67124915], dtype=float32), 'action': array([0.31181997], dtype=float32), 'reward': -0.43367116153240204, 'newState': array([0.77023846], dtype=float32), 'info': {'arrival': 0.770238443398394}}\n",
      "new state: [0.9170675]\n",
      "old state: [0.77023846]\n",
      "{'iter': 0, 'episode': 29, 'step': 3, 'oldState': array([0.77023846], dtype=float32), 'action': array([0.74896413], dtype=float32), 'reward': -0.1313961297273636, 'newState': array([0.9170675], dtype=float32), 'info': {'arrival': 0.917067535045792}}\n",
      "new state: [0.9336523]\n",
      "old state: [0.9170675]\n",
      "{'iter': 0, 'episode': 29, 'step': 4, 'oldState': array([0.9170675], dtype=float32), 'action': array([0.32905576], dtype=float32), 'reward': -0.6004503071308136, 'newState': array([0.9336523], dtype=float32), 'info': {'arrival': 0.9336523075313291}}\n",
      "new state: [0.94808066]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 30, 'step': 0, 'oldState': array([0.]), 'action': array([0.00680943], dtype=float32), 'reward': -0.7076557903783396, 'newState': array([0.94808066], dtype=float32), 'info': {'arrival': 0.9480806489515368}}\n",
      "new state: [0.48987296]\n",
      "old state: [0.94808066]\n",
      "{'iter': 0, 'episode': 30, 'step': 1, 'oldState': array([0.94808066], dtype=float32), 'action': array([0.37885442], dtype=float32), 'reward': -0.2255704700946808, 'newState': array([0.48987296], dtype=float32), 'info': {'arrival': 0.48987295186693536}}\n",
      "new state: [0.81919575]\n",
      "old state: [0.48987296]\n",
      "{'iter': 0, 'episode': 30, 'step': 2, 'oldState': array([0.48987296], dtype=float32), 'action': array([0.5552971], dtype=float32), 'reward': -0.21428003162145615, 'newState': array([0.81919575], dtype=float32), 'info': {'arrival': 0.8191957315216424}}\n",
      "new state: [0.123844]\n",
      "old state: [0.81919575]\n",
      "{'iter': 0, 'episode': 30, 'step': 3, 'oldState': array([0.81919575], dtype=float32), 'action': array([0.89386016], dtype=float32), 'reward': -0.5961782485246658, 'newState': array([0.123844], dtype=float32), 'info': {'arrival': 0.1238439999314215}}\n",
      "new state: [0.7744783]\n",
      "old state: [0.123844]\n",
      "{'iter': 0, 'episode': 30, 'step': 4, 'oldState': array([0.123844], dtype=float32), 'action': array([0.6196092], dtype=float32), 'reward': -0.2400931492447853, 'newState': array([0.7744783], dtype=float32), 'info': {'arrival': 0.7744783044949098}}\n",
      "new state: [0.5859097]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 31, 'step': 0, 'oldState': array([0.]), 'action': array([0.20522578], dtype=float32), 'reward': -0.336819414049387, 'newState': array([0.5859097], dtype=float32), 'info': {'arrival': 0.5859097107662578}}\n",
      "new state: [0.67288107]\n",
      "old state: [0.5859097]\n",
      "{'iter': 0, 'episode': 31, 'step': 1, 'oldState': array([0.5859097], dtype=float32), 'action': array([0.36835763], dtype=float32), 'reward': -0.28278060257434845, 'newState': array([0.67288107], dtype=float32), 'info': {'arrival': 0.6728810567402984}}\n",
      "new state: [0.7882725]\n",
      "old state: [0.67288107]\n",
      "{'iter': 0, 'episode': 31, 'step': 2, 'oldState': array([0.67288107], dtype=float32), 'action': array([0.57003504], dtype=float32), 'reward': -0.18938960134983063, 'newState': array([0.7882725], dtype=float32), 'info': {'arrival': 0.7882724822265326}}\n",
      "new state: [0.54807836]\n",
      "old state: [0.7882725]\n",
      "{'iter': 0, 'episode': 31, 'step': 3, 'oldState': array([0.7882725], dtype=float32), 'action': array([0.83078825], dtype=float32), 'reward': -0.2226613610982895, 'newState': array([0.54807836], dtype=float32), 'info': {'arrival': 0.5480783389104714}}\n",
      "new state: [0.62639165]\n",
      "old state: [0.54807836]\n",
      "{'iter': 0, 'episode': 31, 'step': 4, 'oldState': array([0.54807836], dtype=float32), 'action': array([0.6155478], dtype=float32), 'reward': -0.025000259280204773, 'newState': array([0.62639165], dtype=float32), 'info': {'arrival': 0.6263916736194892}}\n",
      "new state: [0.82427216]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 32, 'step': 0, 'oldState': array([0.]), 'action': array([0.5309365], dtype=float32), 'reward': -0.35273587703704834, 'newState': array([0.82427216], dtype=float32), 'info': {'arrival': 0.8242721530019619}}\n",
      "new state: [0.8313859]\n",
      "old state: [0.82427216]\n",
      "{'iter': 0, 'episode': 32, 'step': 1, 'oldState': array([0.82427216], dtype=float32), 'action': array([0.20912865], dtype=float32), 'reward': -0.6204788088798523, 'newState': array([0.8313859], dtype=float32), 'info': {'arrival': 0.8313859038035443}}\n",
      "new state: [0.62509793]\n",
      "old state: [0.8313859]\n",
      "{'iter': 0, 'episode': 32, 'step': 2, 'oldState': array([0.8313859], dtype=float32), 'action': array([0.43993166], dtype=float32), 'reward': -0.23673826456069946, 'newState': array([0.62509793], dtype=float32), 'info': {'arrival': 0.625097913952053}}\n",
      "new state: [0.77888703]\n",
      "old state: [0.62509793]\n",
      "{'iter': 0, 'episode': 32, 'step': 3, 'oldState': array([0.62509793], dtype=float32), 'action': array([0.36400324], dtype=float32), 'reward': -0.3764365166425705, 'newState': array([0.77888703], dtype=float32), 'info': {'arrival': 0.7788870594977179}}\n",
      "new state: [0.9189249]\n",
      "old state: [0.77888703]\n",
      "{'iter': 0, 'episode': 32, 'step': 4, 'oldState': array([0.77888703], dtype=float32), 'action': array([0.03262014], dtype=float32), 'reward': -0.8512953221797943, 'newState': array([0.9189249], dtype=float32), 'info': {'arrival': 0.9189249259194541}}\n",
      "new state: [0.9353376]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 33, 'step': 0, 'oldState': array([0.]), 'action': array([0.8147088], dtype=float32), 'reward': -0.294148787856102, 'newState': array([0.9353376], dtype=float32), 'info': {'arrival': 0.9353376195458556}}\n",
      "new state: [0.88731754]\n",
      "old state: [0.9353376]\n",
      "{'iter': 0, 'episode': 33, 'step': 1, 'oldState': array([0.9353376], dtype=float32), 'action': array([0.11773691], dtype=float32), 'reward': -0.781585618853569, 'newState': array([0.88731754], dtype=float32), 'info': {'arrival': 0.8873175650967237}}\n",
      "new state: [0.74826324]\n",
      "old state: [0.88731754]\n",
      "{'iter': 0, 'episode': 33, 'step': 2, 'oldState': array([0.88731754], dtype=float32), 'action': array([0.08359084], dtype=float32), 'reward': -0.6994359493255615, 'newState': array([0.74826324], dtype=float32), 'info': {'arrival': 0.7482632190654778}}\n",
      "new state: [0.47011968]\n",
      "old state: [0.74826324]\n",
      "{'iter': 0, 'episode': 33, 'step': 3, 'oldState': array([0.74826324], dtype=float32), 'action': array([0.05915054], dtype=float32), 'reward': -0.480505034327507, 'newState': array([0.47011968], dtype=float32), 'info': {'arrival': 0.4701196819083506}}\n",
      "new state: [0.55165565]\n",
      "old state: [0.47011968]\n",
      "{'iter': 0, 'episode': 33, 'step': 4, 'oldState': array([0.47011968], dtype=float32), 'action': array([0.8500108], dtype=float32), 'reward': -0.318739153444767, 'newState': array([0.55165565], dtype=float32), 'info': {'arrival': 0.5516556340035177}}\n",
      "new state: [0.3589779]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 34, 'step': 0, 'oldState': array([0.]), 'action': array([0.6564191], dtype=float32), 'reward': -0.387185662984848, 'newState': array([0.3589779], dtype=float32), 'info': {'arrival': 0.3589779014926121}}\n",
      "new state: [0.6432537]\n",
      "old state: [0.3589779]\n",
      "{'iter': 0, 'episode': 34, 'step': 1, 'oldState': array([0.3589779], dtype=float32), 'action': array([0.2593846], dtype=float32), 'reward': -0.3128001391887665, 'newState': array([0.6432537], dtype=float32), 'info': {'arrival': 0.6432536961822334}}\n",
      "new state: [0.56576216]\n",
      "old state: [0.6432537]\n",
      "{'iter': 0, 'episode': 34, 'step': 2, 'oldState': array([0.6432537], dtype=float32), 'action': array([0.43643078], dtype=float32), 'reward': -0.14870426058769226, 'newState': array([0.56576216], dtype=float32), 'info': {'arrival': 0.5657621535977899}}\n",
      "new state: [0.80544615]\n",
      "old state: [0.56576216]\n",
      "{'iter': 0, 'episode': 34, 'step': 3, 'oldState': array([0.56576216], dtype=float32), 'action': array([0.7146028], dtype=float32), 'reward': -0.10534265637397766, 'newState': array([0.80544615], dtype=float32), 'info': {'arrival': 0.8054461652964209}}\n",
      "new state: [0.6404324]\n",
      "old state: [0.80544615]\n",
      "{'iter': 0, 'episode': 34, 'step': 4, 'oldState': array([0.80544615], dtype=float32), 'action': array([0.706585], dtype=float32), 'reward': -0.07432971894741058, 'newState': array([0.6404324], dtype=float32), 'info': {'arrival': 0.6404324232891173}}\n",
      "new state: [0.91877127]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 35, 'step': 0, 'oldState': array([0.]), 'action': array([0.5230708], dtype=float32), 'reward': -0.427543044090271, 'newState': array([0.91877127], dtype=float32), 'info': {'arrival': 0.9187712597555636}}\n",
      "new state: [0.85492474]\n",
      "old state: [0.91877127]\n",
      "{'iter': 0, 'episode': 35, 'step': 1, 'oldState': array([0.91877127], dtype=float32), 'action': array([0.4744009], dtype=float32), 'reward': -0.39648546278476715, 'newState': array([0.85492474], dtype=float32), 'info': {'arrival': 0.854924736182262}}\n",
      "new state: [0.48191422]\n",
      "old state: [0.85492474]\n",
      "{'iter': 0, 'episode': 35, 'step': 2, 'oldState': array([0.85492474], dtype=float32), 'action': array([0.8922554], dtype=float32), 'reward': -0.3170885741710663, 'newState': array([0.48191422], dtype=float32), 'info': {'arrival': 0.48191422196582107}}\n",
      "new state: [0.6922448]\n",
      "old state: [0.48191422]\n",
      "{'iter': 0, 'episode': 35, 'step': 3, 'oldState': array([0.48191422], dtype=float32), 'action': array([0.20590436], dtype=float32), 'reward': -0.43375781178474426, 'newState': array([0.6922448], dtype=float32), 'info': {'arrival': 0.6922448278780112}}\n",
      "new state: [0.75618345]\n",
      "old state: [0.6922448]\n",
      "{'iter': 0, 'episode': 35, 'step': 4, 'oldState': array([0.6922448], dtype=float32), 'action': array([0.39470336], dtype=float32), 'reward': -0.34549543261528015, 'newState': array([0.75618345], dtype=float32), 'info': {'arrival': 0.7561834723534577}}\n",
      "new state: [0.23980293]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 36, 'step': 0, 'oldState': array([0.]), 'action': array([0.9845121], dtype=float32), 'reward': -0.8046598732471466, 'newState': array([0.23980293], dtype=float32), 'info': {'arrival': 0.23980292727326286}}\n",
      "new state: [0.8515904]\n",
      "old state: [0.23980293]\n",
      "{'iter': 0, 'episode': 36, 'step': 1, 'oldState': array([0.23980293], dtype=float32), 'action': array([0.4538685], dtype=float32), 'reward': -0.3518078103661537, 'newState': array([0.8515904], dtype=float32), 'info': {'arrival': 0.8515903686427131}}\n",
      "new state: [0.70488614]\n",
      "old state: [0.8515904]\n",
      "{'iter': 0, 'episode': 36, 'step': 2, 'oldState': array([0.8515904], dtype=float32), 'action': array([0.38689393], dtype=float32), 'reward': -0.3546682745218277, 'newState': array([0.70488614], dtype=float32), 'info': {'arrival': 0.7048861538771087}}\n",
      "new state: [0.76251906]\n",
      "old state: [0.70488614]\n",
      "{'iter': 0, 'episode': 36, 'step': 3, 'oldState': array([0.70488614], dtype=float32), 'action': array([0.77952117], dtype=float32), 'reward': -0.0314103364944458, 'newState': array([0.76251906], dtype=float32), 'info': {'arrival': 0.7625190798820192}}\n",
      "new state: [0.67421925]\n",
      "old state: [0.76251906]\n",
      "{'iter': 0, 'episode': 36, 'step': 4, 'oldState': array([0.76251906], dtype=float32), 'action': array([0.625825], dtype=float32), 'reward': -0.0704692155122757, 'newState': array([0.67421925], dtype=float32), 'info': {'arrival': 0.6742192359141851}}\n",
      "new state: [0.33654237]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 37, 'step': 0, 'oldState': array([0.]), 'action': array([0.9500568], dtype=float32), 'reward': -0.6976500153541565, 'newState': array([0.33654237], dtype=float32), 'info': {'arrival': 0.3365423802337875}}\n",
      "new state: [0.4433625]\n",
      "old state: [0.33654237]\n",
      "{'iter': 0, 'episode': 37, 'step': 1, 'oldState': array([0.33654237], dtype=float32), 'action': array([0.8356644], dtype=float32), 'reward': -0.41900692135095596, 'newState': array([0.4433625], dtype=float32), 'info': {'arrival': 0.44336251479721756}}\n",
      "new state: [0.87152755]\n",
      "old state: [0.4433625]\n",
      "{'iter': 0, 'episode': 37, 'step': 2, 'oldState': array([0.4433625], dtype=float32), 'action': array([0.7264685], dtype=float32), 'reward': -0.1795707866549492, 'newState': array([0.87152755], dtype=float32), 'info': {'arrival': 0.8715275308086075}}\n",
      "new state: [0.7612231]\n",
      "old state: [0.87152755]\n",
      "{'iter': 0, 'episode': 37, 'step': 3, 'oldState': array([0.87152755], dtype=float32), 'action': array([0.6584746], dtype=float32), 'reward': -0.1303245723247528, 'newState': array([0.7612231], dtype=float32), 'info': {'arrival': 0.7612230891727588}}\n",
      "new state: [0.88689333]\n",
      "old state: [0.7612231]\n",
      "{'iter': 0, 'episode': 37, 'step': 4, 'oldState': array([0.7612231], dtype=float32), 'action': array([0.52836233], dtype=float32), 'reward': -0.32711343467235565, 'newState': array([0.88689333], dtype=float32), 'info': {'arrival': 0.8868933243095445}}\n",
      "new state: [0.7016407]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 38, 'step': 0, 'oldState': array([0.]), 'action': array([0.70198065], dtype=float32), 'reward': -0.17575010657310486, 'newState': array([0.7016407], dtype=float32), 'info': {'arrival': 0.7016406967275078}}\n",
      "new state: [0.9487861]\n",
      "old state: [0.7016407]\n",
      "{'iter': 0, 'episode': 38, 'step': 1, 'oldState': array([0.7016407], dtype=float32), 'action': array([0.6669974], dtype=float32), 'reward': -0.22000236809253693, 'newState': array([0.9487861], dtype=float32), 'info': {'arrival': 0.9487860549504429}}\n",
      "new state: [0.8886589]\n",
      "old state: [0.9487861]\n",
      "{'iter': 0, 'episode': 38, 'step': 2, 'oldState': array([0.9487861], dtype=float32), 'action': array([0.98428094], dtype=float32), 'reward': -0.08059026300907135, 'newState': array([0.8886589], dtype=float32), 'info': {'arrival': 0.888658863950032}}\n",
      "new state: [0.3765591]\n",
      "old state: [0.8886589]\n",
      "{'iter': 0, 'episode': 38, 'step': 3, 'oldState': array([0.8886589], dtype=float32), 'action': array([0.97502226], dtype=float32), 'reward': -0.47043822705745697, 'newState': array([0.3765591], dtype=float32), 'info': {'arrival': 0.376559105663882}}\n",
      "new state: [0.80547845]\n",
      "old state: [0.3765591]\n",
      "{'iter': 0, 'episode': 38, 'step': 4, 'oldState': array([0.3765591], dtype=float32), 'action': array([0.8713214], dtype=float32), 'reward': -0.17307276278734207, 'newState': array([0.80547845], dtype=float32), 'info': {'arrival': 0.8054784462329124}}\n",
      "new state: [0.5700901]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 39, 'step': 0, 'oldState': array([0.]), 'action': array([0.86508197], dtype=float32), 'reward': -0.43751437962055206, 'newState': array([0.5700901], dtype=float32), 'info': {'arrival': 0.5700901433367834}}\n",
      "new state: [0.68414307]\n",
      "old state: [0.5700901]\n",
      "{'iter': 0, 'episode': 39, 'step': 1, 'oldState': array([0.5700901], dtype=float32), 'action': array([0.9262974], dtype=float32), 'reward': -0.27066759765148163, 'newState': array([0.68414307], dtype=float32), 'info': {'arrival': 0.6841430887049704}}\n",
      "new state: [0.742024]\n",
      "old state: [0.68414307]\n",
      "{'iter': 0, 'episode': 39, 'step': 2, 'oldState': array([0.68414307], dtype=float32), 'action': array([0.08115514], dtype=float32), 'reward': -0.6463986486196518, 'newState': array([0.742024], dtype=float32), 'info': {'arrival': 0.74202400340377}}\n",
      "new state: [0.71730995]\n",
      "old state: [0.742024]\n",
      "{'iter': 0, 'episode': 39, 'step': 3, 'oldState': array([0.742024], dtype=float32), 'action': array([0.64166355], dtype=float32), 'reward': -0.08182491362094879, 'newState': array([0.71730995], dtype=float32), 'info': {'arrival': 0.7173099655638561}}\n",
      "new state: [0.8532226]\n",
      "old state: [0.71730995]\n",
      "{'iter': 0, 'episode': 39, 'step': 4, 'oldState': array([0.71730995], dtype=float32), 'action': array([0.13985172], dtype=float32), 'reward': -0.6793927550315857, 'newState': array([0.8532226], dtype=float32), 'info': {'arrival': 0.8532225968023669}}\n",
      "new state: [0.875471]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 40, 'step': 0, 'oldState': array([0.]), 'action': array([0.78790736], dtype=float32), 'reward': -0.2626495659351349, 'newState': array([0.875471], dtype=float32), 'info': {'arrival': 0.8754710204710323}}\n",
      "new state: [0.5857066]\n",
      "old state: [0.875471]\n",
      "{'iter': 0, 'episode': 40, 'step': 1, 'oldState': array([0.875471], dtype=float32), 'action': array([0.7263442], dtype=float32), 'reward': -0.14275991916656494, 'newState': array([0.5857066], dtype=float32), 'info': {'arrival': 0.5857066150850823}}\n",
      "new state: [0.5072658]\n",
      "old state: [0.5857066]\n",
      "{'iter': 0, 'episode': 40, 'step': 2, 'oldState': array([0.5857066], dtype=float32), 'action': array([0.6308266], dtype=float32), 'reward': -0.10395058989524841, 'newState': array([0.5072658], dtype=float32), 'info': {'arrival': 0.5072658047534414}}\n",
      "new state: [0.54113567]\n",
      "old state: [0.5072658]\n",
      "{'iter': 0, 'episode': 40, 'step': 3, 'oldState': array([0.5072658], dtype=float32), 'action': array([0.5724183], dtype=float32), 'reward': -0.03975006937980652, 'newState': array([0.54113567], dtype=float32), 'info': {'arrival': 0.5411356975971607}}\n",
      "new state: [0.84082603]\n",
      "old state: [0.54113567]\n",
      "{'iter': 0, 'episode': 40, 'step': 4, 'oldState': array([0.54113567], dtype=float32), 'action': array([0.70038044], dtype=float32), 'reward': -0.14514538645744324, 'newState': array([0.84082603], dtype=float32), 'info': {'arrival': 0.8408260184005825}}\n",
      "new state: [0.4208136]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 41, 'step': 0, 'oldState': array([0.]), 'action': array([0.65273863], dtype=float32), 'reward': -0.3371284380555153, 'newState': array([0.4208136], dtype=float32), 'info': {'arrival': 0.42081359371476496}}\n",
      "new state: [0.80786306]\n",
      "old state: [0.4208136]\n",
      "{'iter': 0, 'episode': 41, 'step': 1, 'oldState': array([0.4208136], dtype=float32), 'action': array([0.87908876], dtype=float32), 'reward': -0.16798806935548782, 'newState': array([0.80786306], dtype=float32), 'info': {'arrival': 0.8078630666157436}}\n",
      "new state: [0.7967566]\n",
      "old state: [0.80786306]\n",
      "{'iter': 0, 'episode': 41, 'step': 2, 'oldState': array([0.80786306], dtype=float32), 'action': array([0.55922484], dtype=float32), 'reward': -0.24030838906764984, 'newState': array([0.7967566], dtype=float32), 'info': {'arrival': 0.796756614472939}}\n",
      "new state: [0.80820286]\n",
      "old state: [0.7967566]\n",
      "{'iter': 0, 'episode': 41, 'step': 3, 'oldState': array([0.7967566], dtype=float32), 'action': array([0.6267725], dtype=float32), 'reward': -0.1785687804222107, 'newState': array([0.80820286], dtype=float32), 'info': {'arrival': 0.8082028615019131}}\n",
      "new state: [0.79714465]\n",
      "old state: [0.80820286]\n",
      "{'iter': 0, 'episode': 41, 'step': 4, 'oldState': array([0.80820286], dtype=float32), 'action': array([0.99250156], dtype=float32), 'reward': -0.19259235262870789, 'newState': array([0.79714465], dtype=float32), 'info': {'arrival': 0.7971446320047666}}\n",
      "new state: [0.8071989]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 42, 'step': 0, 'oldState': array([0.]), 'action': array([0.8887244], dtype=float32), 'reward': -0.2833252251148224, 'newState': array([0.8071989], dtype=float32), 'info': {'arrival': 0.8071988737509993}}\n",
      "new state: [0.91193235]\n",
      "old state: [0.8071989]\n",
      "{'iter': 0, 'episode': 42, 'step': 1, 'oldState': array([0.8071989], dtype=float32), 'action': array([0.41222376], dtype=float32), 'reward': -0.4735252261161804, 'newState': array([0.91193235], dtype=float32), 'info': {'arrival': 0.9119323267536174}}\n",
      "new state: [0.6202463]\n",
      "old state: [0.91193235]\n",
      "{'iter': 0, 'episode': 42, 'step': 2, 'oldState': array([0.91193235], dtype=float32), 'action': array([0.05691859], dtype=float32), 'reward': -0.6362492442131042, 'newState': array([0.6202463], dtype=float32), 'info': {'arrival': 0.6202462711159542}}\n",
      "new state: [0.6441291]\n",
      "old state: [0.6202463]\n",
      "{'iter': 0, 'episode': 42, 'step': 3, 'oldState': array([0.6202463], dtype=float32), 'action': array([0.5437063], dtype=float32), 'reward': -0.09445209801197052, 'newState': array([0.6441291], dtype=float32), 'info': {'arrival': 0.6441290786437216}}\n",
      "new state: [0.53433055]\n",
      "old state: [0.6441291]\n",
      "{'iter': 0, 'episode': 42, 'step': 4, 'oldState': array([0.6441291], dtype=float32), 'action': array([0.7978715], dtype=float32), 'reward': -0.23609128594398499, 'newState': array([0.53433055], dtype=float32), 'info': {'arrival': 0.5343305209453314}}\n",
      "new state: [0.76545]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 43, 'step': 0, 'oldState': array([0.]), 'action': array([0.55591524], dtype=float32), 'reward': -0.29612988233566284, 'newState': array([0.76545], dtype=float32), 'info': {'arrival': 0.7654500196099028}}\n",
      "new state: [0.8913085]\n",
      "old state: [0.76545]\n",
      "{'iter': 0, 'episode': 43, 'step': 1, 'oldState': array([0.76545], dtype=float32), 'action': array([0.1601923], dtype=float32), 'reward': -0.6996515542268753, 'newState': array([0.8913085], dtype=float32), 'info': {'arrival': 0.8913084748783624}}\n",
      "new state: [0.6971924]\n",
      "old state: [0.8913085]\n",
      "{'iter': 0, 'episode': 43, 'step': 2, 'oldState': array([0.8913085], dtype=float32), 'action': array([0.25337207], dtype=float32), 'reward': -0.4923493266105652, 'newState': array([0.6971924], dtype=float32), 'info': {'arrival': 0.6971923505985197}}\n",
      "new state: [0.7643508]\n",
      "old state: [0.6971924]\n",
      "{'iter': 0, 'episode': 43, 'step': 3, 'oldState': array([0.6971924], dtype=float32), 'action': array([0.44519898], dtype=float32), 'reward': -0.30236218869686127, 'newState': array([0.7643508], dtype=float32), 'info': {'arrival': 0.7643507431351398}}\n",
      "new state: [0.37414727]\n",
      "old state: [0.7643508]\n",
      "{'iter': 0, 'episode': 43, 'step': 4, 'oldState': array([0.7643508], dtype=float32), 'action': array([0.88985956], dtype=float32), 'reward': -0.41816139221191406, 'newState': array([0.37414727], dtype=float32), 'info': {'arrival': 0.37414727531244946}}\n",
      "new state: [0.84749866]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 44, 'step': 0, 'oldState': array([0.]), 'action': array([0.40466422], dtype=float32), 'reward': -0.43329188227653503, 'newState': array([0.84749866], dtype=float32), 'info': {'arrival': 0.8474986531442412}}\n",
      "new state: [0.8565733]\n",
      "old state: [0.84749866]\n",
      "{'iter': 0, 'episode': 44, 'step': 1, 'oldState': array([0.84749866], dtype=float32), 'action': array([0.3953168], dtype=float32), 'reward': -0.4589878171682358, 'newState': array([0.8565733], dtype=float32), 'info': {'arrival': 0.8565733037804191}}\n",
      "new state: [0.7107014]\n",
      "old state: [0.8565733]\n",
      "{'iter': 0, 'episode': 44, 'step': 2, 'oldState': array([0.8565733], dtype=float32), 'action': array([0.7196782], dtype=float32), 'reward': -0.04095637798309326, 'newState': array([0.7107014], dtype=float32), 'info': {'arrival': 0.7107013886846953}}\n",
      "new state: [0.82528055]\n",
      "old state: [0.7107014]\n",
      "{'iter': 0, 'episode': 44, 'step': 3, 'oldState': array([0.7107014], dtype=float32), 'action': array([0.10729512], dtype=float32), 'reward': -0.68934066593647, 'newState': array([0.82528055], dtype=float32), 'info': {'arrival': 0.8252805447851961}}\n",
      "new state: [0.634006]\n",
      "old state: [0.82528055]\n",
      "{'iter': 0, 'episode': 44, 'step': 4, 'oldState': array([0.82528055], dtype=float32), 'action': array([0.70041084], dtype=float32), 'reward': -0.08102104067802429, 'newState': array([0.634006], dtype=float32), 'info': {'arrival': 0.6340060084943376}}\n",
      "new state: [0.8214873]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 45, 'step': 0, 'oldState': array([0.]), 'action': array([0.33297876], dtype=float32), 'reward': -0.4496261030435562, 'newState': array([0.8214873], dtype=float32), 'info': {'arrival': 0.82148733084387}}\n",
      "new state: [0.66455936]\n",
      "old state: [0.8214873]\n",
      "{'iter': 0, 'episode': 45, 'step': 1, 'oldState': array([0.8214873], dtype=float32), 'action': array([0.43344826], dtype=float32), 'reward': -0.2703430950641632, 'newState': array([0.66455936], dtype=float32), 'info': {'arrival': 0.6645593824360657}}\n",
      "new state: [0.57994854]\n",
      "old state: [0.66455936]\n",
      "{'iter': 0, 'episode': 45, 'step': 2, 'oldState': array([0.66455936], dtype=float32), 'action': array([0.9467331], dtype=float32), 'reward': -0.345631867647171, 'newState': array([0.57994854], dtype=float32), 'info': {'arrival': 0.5799485734140578}}\n",
      "new state: [0.66356224]\n",
      "old state: [0.57994854]\n",
      "{'iter': 0, 'episode': 45, 'step': 3, 'oldState': array([0.57994854], dtype=float32), 'action': array([0.31502885], dtype=float32), 'reward': -0.3276299685239792, 'newState': array([0.66356224], dtype=float32), 'info': {'arrival': 0.6635622439502252}}\n",
      "new state: [0.7632147]\n",
      "old state: [0.66356224]\n",
      "{'iter': 0, 'episode': 45, 'step': 4, 'oldState': array([0.66356224], dtype=float32), 'action': array([0.47653472], dtype=float32), 'reward': -0.26176686584949493, 'newState': array([0.7632147], dtype=float32), 'info': {'arrival': 0.7632147004639858}}\n",
      "new state: [0.47565573]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 46, 'step': 0, 'oldState': array([0.]), 'action': array([0.1286653], dtype=float32), 'reward': -0.29240915179252625, 'newState': array([0.47565573], dtype=float32), 'info': {'arrival': 0.47565573060407795}}\n",
      "new state: [0.5563779]\n",
      "old state: [0.47565573]\n",
      "{'iter': 0, 'episode': 46, 'step': 1, 'oldState': array([0.47565573], dtype=float32), 'action': array([0.8968809], dtype=float32), 'reward': -0.3606835752725601, 'newState': array([0.5563779], dtype=float32), 'info': {'arrival': 0.556377901059167}}\n",
      "new state: [0.83991593]\n",
      "old state: [0.5563779]\n",
      "{'iter': 0, 'episode': 46, 'step': 2, 'oldState': array([0.5563779], dtype=float32), 'action': array([0.6074841], dtype=float32), 'reward': -0.18710042536258698, 'newState': array([0.83991593], dtype=float32), 'info': {'arrival': 0.8399159470470965}}\n",
      "new state: [0.4664013]\n",
      "old state: [0.83991593]\n",
      "{'iter': 0, 'episode': 46, 'step': 3, 'oldState': array([0.83991593], dtype=float32), 'action': array([0.36415517], dtype=float32), 'reward': -0.19562479108572006, 'newState': array([0.4664013], dtype=float32), 'info': {'arrival': 0.4664013024325603}}\n",
      "new state: [0.8298789]\n",
      "old state: [0.4664013]\n",
      "{'iter': 0, 'episode': 46, 'step': 4, 'oldState': array([0.4664013], dtype=float32), 'action': array([0.2475021], dtype=float32), 'reward': -0.4915074296295643, 'newState': array([0.8298789], dtype=float32), 'info': {'arrival': 0.8298789019194694}}\n",
      "new state: [0.9301245]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 47, 'step': 0, 'oldState': array([0.]), 'action': array([0.6435908], dtype=float32), 'reward': -0.37579798698425293, 'newState': array([0.9301245], dtype=float32), 'info': {'arrival': 0.9301245209773018}}\n",
      "new state: [0.79559636]\n",
      "old state: [0.9301245]\n",
      "{'iter': 0, 'episode': 47, 'step': 1, 'oldState': array([0.9301245], dtype=float32), 'action': array([0.9688653], dtype=float32), 'reward': -0.13963687419891357, 'newState': array([0.79559636], dtype=float32), 'info': {'arrival': 0.7955963669209796}}\n",
      "new state: [0.9620733]\n",
      "old state: [0.79559636]\n",
      "{'iter': 0, 'episode': 47, 'step': 2, 'oldState': array([0.79559636], dtype=float32), 'action': array([0.01068246], dtype=float32), 'reward': -0.9097716212272644, 'newState': array([0.9620733], dtype=float32), 'info': {'arrival': 0.9620733414977437}}\n",
      "new state: [0.6427149]\n",
      "old state: [0.9620733]\n",
      "{'iter': 0, 'episode': 47, 'step': 3, 'oldState': array([0.9620733], dtype=float32), 'action': array([0.58607435], dtype=float32), 'reward': -0.1364801675081253, 'newState': array([0.6427149], dtype=float32), 'info': {'arrival': 0.6427149172777372}}\n",
      "new state: [0.6354383]\n",
      "old state: [0.6427149]\n",
      "{'iter': 0, 'episode': 47, 'step': 4, 'oldState': array([0.6427149], dtype=float32), 'action': array([0.672893], dtype=float32), 'reward': -0.03563551604747772, 'newState': array([0.6354383], dtype=float32), 'info': {'arrival': 0.6354383019225627}}\n",
      "new state: [0.7332879]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 48, 'step': 0, 'oldState': array([0.]), 'action': array([0.00717907], dtype=float32), 'reward': -0.5463763586012647, 'newState': array([0.7332879], dtype=float32), 'info': {'arrival': 0.7332878995775329}}\n",
      "new state: [0.42903727]\n",
      "old state: [0.7332879]\n",
      "{'iter': 0, 'episode': 48, 'step': 1, 'oldState': array([0.7332879], dtype=float32), 'action': array([0.21063508], dtype=float32), 'reward': -0.2944648452103138, 'newState': array([0.42903727], dtype=float32), 'info': {'arrival': 0.42903727749685394}}\n",
      "new state: [0.7959581]\n",
      "old state: [0.42903727]\n",
      "{'iter': 0, 'episode': 48, 'step': 2, 'oldState': array([0.42903727], dtype=float32), 'action': array([0.54412895], dtype=float32), 'reward': -0.21764478087425232, 'newState': array([0.7959581], dtype=float32), 'info': {'arrival': 0.795958113872428}}\n",
      "new state: [0.44777304]\n",
      "old state: [0.7959581]\n",
      "{'iter': 0, 'episode': 48, 'step': 3, 'oldState': array([0.7959581], dtype=float32), 'action': array([0.17095056], dtype=float32), 'reward': -0.36386873573064804, 'newState': array([0.44777304], dtype=float32), 'info': {'arrival': 0.4477730297948325}}\n",
      "new state: [0.93775713]\n",
      "old state: [0.44777304]\n",
      "{'iter': 0, 'episode': 48, 'step': 4, 'oldState': array([0.44777304], dtype=float32), 'action': array([0.44972908], dtype=float32), 'reward': -0.3665100485086441, 'newState': array([0.93775713], dtype=float32), 'info': {'arrival': 0.9377571507319524}}\n",
      "new state: [0.6841057]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 49, 'step': 0, 'oldState': array([0.]), 'action': array([0.5518917], dtype=float32), 'reward': -0.2371334284543991, 'newState': array([0.6841057], dtype=float32), 'info': {'arrival': 0.6841057073960813}}\n",
      "new state: [0.9105113]\n",
      "old state: [0.6841057]\n",
      "{'iter': 0, 'episode': 49, 'step': 1, 'oldState': array([0.6841057], dtype=float32), 'action': array([0.9801819], dtype=float32), 'reward': -0.12627196311950684, 'newState': array([0.9105113], dtype=float32), 'info': {'arrival': 0.9105112957306783}}\n",
      "new state: [0.6883233]\n",
      "old state: [0.9105113]\n",
      "{'iter': 0, 'episode': 49, 'step': 2, 'oldState': array([0.9105113], dtype=float32), 'action': array([0.26833], dtype=float32), 'reward': -0.47554030269384384, 'newState': array([0.6883233], dtype=float32), 'info': {'arrival': 0.6883233452711954}}\n",
      "new state: [0.70293415]\n",
      "old state: [0.6883233]\n",
      "{'iter': 0, 'episode': 49, 'step': 3, 'oldState': array([0.6883233], dtype=float32), 'action': array([0.7479789], dtype=float32), 'reward': -0.04869748651981354, 'newState': array([0.70293415], dtype=float32), 'info': {'arrival': 0.7029341495482215}}\n",
      "new state: [0.87237614]\n",
      "old state: [0.70293415]\n",
      "{'iter': 0, 'episode': 49, 'step': 4, 'oldState': array([0.70293415], dtype=float32), 'action': array([0.6249099], dtype=float32), 'reward': -0.2051057666540146, 'newState': array([0.87237614], dtype=float32), 'info': {'arrival': 0.8723761681800952}}\n",
      "new state: [0.76403505]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 50, 'step': 0, 'oldState': array([0.]), 'action': array([0.70973164], dtype=float32), 'reward': -0.2181604653596878, 'newState': array([0.76403505], dtype=float32), 'info': {'arrival': 0.7640350456788186}}\n",
      "new state: [0.83999276]\n",
      "old state: [0.76403505]\n",
      "{'iter': 0, 'episode': 50, 'step': 1, 'oldState': array([0.76403505], dtype=float32), 'action': array([0.4884417], dtype=float32), 'reward': -0.3325616270303726, 'newState': array([0.83999276], dtype=float32), 'info': {'arrival': 0.8399927346637375}}\n",
      "new state: [0.75047576]\n",
      "old state: [0.83999276]\n",
      "{'iter': 0, 'episode': 50, 'step': 2, 'oldState': array([0.83999276], dtype=float32), 'action': array([0.3849735], dtype=float32), 'reward': -0.3878815174102783, 'newState': array([0.75047576], dtype=float32), 'info': {'arrival': 0.7504757835347051}}\n",
      "new state: [0.92237645]\n",
      "old state: [0.75047576]\n",
      "{'iter': 0, 'episode': 50, 'step': 3, 'oldState': array([0.75047576], dtype=float32), 'action': array([0.6396205], dtype=float32), 'reward': -0.23978079855442047, 'newState': array([0.92237645], dtype=float32), 'info': {'arrival': 0.922376457203993}}\n",
      "new state: [0.6844785]\n",
      "old state: [0.92237645]\n",
      "{'iter': 0, 'episode': 50, 'step': 4, 'oldState': array([0.92237645], dtype=float32), 'action': array([0.49168122], dtype=float32), 'reward': -0.25227178633213043, 'newState': array([0.6844785], dtype=float32), 'info': {'arrival': 0.6844785433079856}}\n",
      "new state: [0.8395237]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 51, 'step': 0, 'oldState': array([0.]), 'action': array([0.94863826], dtype=float32), 'reward': -0.31899550557136536, 'newState': array([0.8395237], dtype=float32), 'info': {'arrival': 0.8395236703768766}}\n",
      "new state: [0.92150015]\n",
      "old state: [0.8395237]\n",
      "{'iter': 0, 'episode': 51, 'step': 1, 'oldState': array([0.8395237], dtype=float32), 'action': array([0.47429094], dtype=float32), 'reward': -0.42671509087085724, 'newState': array([0.92150015], dtype=float32), 'info': {'arrival': 0.9215001366833842}}\n",
      "new state: [0.9299618]\n",
      "old state: [0.92150015]\n",
      "{'iter': 0, 'episode': 51, 'step': 2, 'oldState': array([0.92150015], dtype=float32), 'action': array([0.05406155], dtype=float32), 'reward': -0.8737848550081253, 'newState': array([0.9299618], dtype=float32), 'info': {'arrival': 0.9299618001325833}}\n",
      "new state: [0.68234766]\n",
      "old state: [0.9299618]\n",
      "{'iter': 0, 'episode': 51, 'step': 3, 'oldState': array([0.9299618], dtype=float32), 'action': array([0.5593885], dtype=float32), 'reward': -0.1848626732826233, 'newState': array([0.68234766], dtype=float32), 'info': {'arrival': 0.6823476450289192}}\n",
      "new state: [0.7114239]\n",
      "old state: [0.68234766]\n",
      "{'iter': 0, 'episode': 51, 'step': 4, 'oldState': array([0.68234766], dtype=float32), 'action': array([0.5528996], dtype=float32), 'reward': -0.15125522017478943, 'newState': array([0.7114239], dtype=float32), 'info': {'arrival': 0.7114238769689507}}\n",
      "new state: [0.61422133]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 52, 'step': 0, 'oldState': array([0.]), 'action': array([0.51335275], dtype=float32), 'reward': -0.20398962497711182, 'newState': array([0.61422133], dtype=float32), 'info': {'arrival': 0.6142213636775617}}\n",
      "new state: [0.8910688]\n",
      "old state: [0.61422133]\n",
      "{'iter': 0, 'episode': 52, 'step': 1, 'oldState': array([0.61422133], dtype=float32), 'action': array([0.1078392], dtype=float32), 'reward': -0.7140177190303802, 'newState': array([0.8910688], dtype=float32), 'info': {'arrival': 0.8910687949734698}}\n",
      "new state: [0.6957385]\n",
      "old state: [0.8910688]\n",
      "{'iter': 0, 'episode': 52, 'step': 2, 'oldState': array([0.8910688], dtype=float32), 'action': array([0.7202979], dtype=float32), 'reward': -0.06111226975917816, 'newState': array([0.6957385], dtype=float32), 'info': {'arrival': 0.6957384818410569}}\n",
      "new state: [0.7891366]\n",
      "old state: [0.6957385]\n",
      "{'iter': 0, 'episode': 52, 'step': 3, 'oldState': array([0.6957385], dtype=float32), 'action': array([0.6580229], dtype=float32), 'reward': -0.10776418447494507, 'newState': array([0.7891366], dtype=float32), 'info': {'arrival': 0.7891365727244731}}\n",
      "new state: [0.9611684]\n",
      "old state: [0.7891366]\n",
      "{'iter': 0, 'episode': 52, 'step': 4, 'oldState': array([0.7891366], dtype=float32), 'action': array([0.63583004], dtype=float32), 'reward': -0.2823304086923599, 'newState': array([0.9611684], dtype=float32), 'info': {'arrival': 0.9611684217296833}}\n",
      "new state: [0.6002621]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 53, 'step': 0, 'oldState': array([0.]), 'action': array([0.74836624], dtype=float32), 'reward': -0.29816965758800507, 'newState': array([0.6002621], dtype=float32), 'info': {'arrival': 0.6002621017226061}}\n",
      "new state: [0.66523075]\n",
      "old state: [0.6002621]\n",
      "{'iter': 0, 'episode': 53, 'step': 1, 'oldState': array([0.6002621], dtype=float32), 'action': array([0.30698523], dtype=float32), 'reward': -0.34200336039066315, 'newState': array([0.66523075], dtype=float32), 'info': {'arrival': 0.665230777290616}}\n",
      "new state: [0.7969127]\n",
      "old state: [0.66523075]\n",
      "{'iter': 0, 'episode': 53, 'step': 2, 'oldState': array([0.66523075], dtype=float32), 'action': array([0.6763523], dtype=float32), 'reward': -0.0932006984949112, 'newState': array([0.7969127], dtype=float32), 'info': {'arrival': 0.7969127258010065}}\n",
      "new state: [0.6341784]\n",
      "old state: [0.7969127]\n",
      "{'iter': 0, 'episode': 53, 'step': 3, 'oldState': array([0.7969127], dtype=float32), 'action': array([0.14717078], dtype=float32), 'reward': -0.527691200375557, 'newState': array([0.6341784], dtype=float32), 'info': {'arrival': 0.634178389266672}}\n",
      "new state: [0.982104]\n",
      "old state: [0.6341784]\n",
      "{'iter': 0, 'episode': 53, 'step': 4, 'oldState': array([0.6341784], dtype=float32), 'action': array([0.7877814], dtype=float32), 'reward': -0.18414269387722015, 'newState': array([0.982104], dtype=float32), 'info': {'arrival': 0.9821039964462415}}\n",
      "new state: [0.7536776]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 54, 'step': 0, 'oldState': array([0.]), 'action': array([0.95420074], dtype=float32), 'reward': -0.38894253969192505, 'newState': array([0.7536776], dtype=float32), 'info': {'arrival': 0.7536775785090499}}\n",
      "new state: [0.75056416]\n",
      "old state: [0.7536776]\n",
      "{'iter': 0, 'episode': 54, 'step': 1, 'oldState': array([0.7536776], dtype=float32), 'action': array([0.30111727], dtype=float32), 'reward': -0.45022524893283844, 'newState': array([0.75056416], dtype=float32), 'info': {'arrival': 0.7505641692146947}}\n",
      "new state: [0.5473951]\n",
      "old state: [0.75056416]\n",
      "{'iter': 0, 'episode': 54, 'step': 2, 'oldState': array([0.75056416], dtype=float32), 'action': array([0.4605874], dtype=float32), 'reward': -0.13759995996952057, 'newState': array([0.5473951], dtype=float32), 'info': {'arrival': 0.5473951021487384}}\n",
      "new state: [0.9533247]\n",
      "old state: [0.5473951]\n",
      "{'iter': 0, 'episode': 54, 'step': 3, 'oldState': array([0.5473951], dtype=float32), 'action': array([0.4902236], dtype=float32), 'reward': -0.36161869764328003, 'newState': array([0.9533247], dtype=float32), 'info': {'arrival': 0.9533247047082883}}\n",
      "new state: [0.62081355]\n",
      "old state: [0.9533247]\n",
      "{'iter': 0, 'episode': 54, 'step': 4, 'oldState': array([0.9533247], dtype=float32), 'action': array([0.13773985], dtype=float32), 'reward': -0.5662014931440353, 'newState': array([0.62081355], dtype=float32), 'info': {'arrival': 0.6208135488721899}}\n",
      "new state: [0.95295525]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 55, 'step': 0, 'oldState': array([0.]), 'action': array([0.5554718], dtype=float32), 'reward': -0.43698054552078247, 'newState': array([0.95295525], dtype=float32), 'info': {'arrival': 0.9529552317213027}}\n",
      "new state: [0.64880615]\n",
      "old state: [0.95295525]\n",
      "{'iter': 0, 'episode': 55, 'step': 1, 'oldState': array([0.95295525], dtype=float32), 'action': array([0.7913947], dtype=float32), 'reward': -0.14733155071735382, 'newState': array([0.64880615], dtype=float32), 'info': {'arrival': 0.6488061261212221}}\n",
      "new state: [0.6825128]\n",
      "old state: [0.64880615]\n",
      "{'iter': 0, 'episode': 55, 'step': 2, 'oldState': array([0.64880615], dtype=float32), 'action': array([0.15553536], dtype=float32), 'reward': -0.5185508131980896, 'newState': array([0.6825128], dtype=float32), 'info': {'arrival': 0.6825128280172217}}\n",
      "new state: [0.82647717]\n",
      "old state: [0.6825128]\n",
      "{'iter': 0, 'episode': 55, 'step': 3, 'oldState': array([0.6825128], dtype=float32), 'action': array([0.36665303], dtype=float32), 'reward': -0.42383305728435516, 'newState': array([0.82647717], dtype=float32), 'info': {'arrival': 0.8264771902119059}}\n",
      "new state: [0.5161449]\n",
      "old state: [0.82647717]\n",
      "{'iter': 0, 'episode': 55, 'step': 4, 'oldState': array([0.82647717], dtype=float32), 'action': array([0.97639835], dtype=float32), 'reward': -0.38267040252685547, 'newState': array([0.5161449], dtype=float32), 'info': {'arrival': 0.5161448860311683}}\n",
      "new state: [0.30838874]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 56, 'step': 0, 'oldState': array([0.]), 'action': array([0.093559], dtype=float32), 'reward': -0.18451205641031265, 'newState': array([0.30838874], dtype=float32), 'info': {'arrival': 0.30838873441167636}}\n",
      "new state: [0.9641228]\n",
      "old state: [0.30838874]\n",
      "{'iter': 0, 'episode': 56, 'step': 1, 'oldState': array([0.30838874], dtype=float32), 'action': array([0.9465566], dtype=float32), 'reward': -0.17271657288074493, 'newState': array([0.9641228], dtype=float32), 'info': {'arrival': 0.96412275695959}}\n",
      "new state: [0.9438796]\n",
      "old state: [0.9641228]\n",
      "{'iter': 0, 'episode': 56, 'step': 2, 'oldState': array([0.9641228], dtype=float32), 'action': array([0.7417429], dtype=float32), 'reward': -0.20719748735427856, 'newState': array([0.9438796], dtype=float32), 'info': {'arrival': 0.9438796265500603}}\n",
      "new state: [0.30519372]\n",
      "old state: [0.9438796]\n",
      "{'iter': 0, 'episode': 56, 'step': 3, 'oldState': array([0.9438796], dtype=float32), 'action': array([0.68475443], dtype=float32), 'reward': -0.34945182502269745, 'newState': array([0.30519372], dtype=float32), 'info': {'arrival': 0.30519373162571783}}\n",
      "new state: [0.93845016]\n",
      "old state: [0.30519372]\n",
      "{'iter': 0, 'episode': 56, 'step': 4, 'oldState': array([0.30519372], dtype=float32), 'action': array([0.8420972], dtype=float32), 'reward': -0.20649057626724243, 'newState': array([0.93845016], dtype=float32), 'info': {'arrival': 0.9384501783082037}}\n",
      "new state: [0.5367887]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 57, 'step': 0, 'oldState': array([0.]), 'action': array([0.8860846], dtype=float32), 'reward': -0.4834930896759033, 'newState': array([0.5367887], dtype=float32), 'info': {'arrival': 0.536788711376367}}\n",
      "new state: [0.80248505]\n",
      "old state: [0.5367887]\n",
      "{'iter': 0, 'episode': 57, 'step': 1, 'oldState': array([0.5367887], dtype=float32), 'action': array([0.49624005], dtype=float32), 'reward': -0.2398209124803543, 'newState': array([0.80248505], dtype=float32), 'info': {'arrival': 0.8024850508043279}}\n",
      "new state: [0.7893686]\n",
      "old state: [0.80248505]\n",
      "{'iter': 0, 'episode': 57, 'step': 2, 'oldState': array([0.80248505], dtype=float32), 'action': array([0.39885098], dtype=float32), 'reward': -0.39379675686359406, 'newState': array([0.7893686], dtype=float32), 'info': {'arrival': 0.7893686567859667}}\n",
      "new state: [0.8214076]\n",
      "old state: [0.7893686]\n",
      "{'iter': 0, 'episode': 57, 'step': 3, 'oldState': array([0.7893686], dtype=float32), 'action': array([0.55873275], dtype=float32), 'reward': -0.2546651214361191, 'newState': array([0.8214076], dtype=float32), 'info': {'arrival': 0.8214076068720908}}\n",
      "new state: [0.7924381]\n",
      "old state: [0.8214076]\n",
      "{'iter': 0, 'episode': 57, 'step': 4, 'oldState': array([0.8214076], dtype=float32), 'action': array([0.79703647], dtype=float32), 'reward': -0.009541571140289307, 'newState': array([0.7924381], dtype=float32), 'info': {'arrival': 0.7924381099986211}}\n",
      "new state: [0.39894792]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 58, 'step': 0, 'oldState': array([0.]), 'action': array([0.4186553], dtype=float32), 'reward': -0.1194443628191948, 'newState': array([0.39894792], dtype=float32), 'info': {'arrival': 0.39894792166223847}}\n",
      "new state: [0.7630529]\n",
      "old state: [0.39894792]\n",
      "{'iter': 0, 'episode': 58, 'step': 1, 'oldState': array([0.39894792], dtype=float32), 'action': array([0.9510282], dtype=float32), 'reward': -0.2790015786886215, 'newState': array([0.7630529], dtype=float32), 'info': {'arrival': 0.7630528571182542}}\n",
      "new state: [0.7422218]\n",
      "old state: [0.7630529]\n",
      "{'iter': 0, 'episode': 58, 'step': 2, 'oldState': array([0.7630529], dtype=float32), 'action': array([0.35878706], dtype=float32), 'reward': -0.38864248991012573, 'newState': array([0.7422218], dtype=float32), 'info': {'arrival': 0.7422217678616029}}\n",
      "new state: [0.5122982]\n",
      "old state: [0.7422218]\n",
      "{'iter': 0, 'episode': 58, 'step': 3, 'oldState': array([0.7422218], dtype=float32), 'action': array([0.08489739], dtype=float32), 'reward': -0.4848817139863968, 'newState': array([0.5122982], dtype=float32), 'info': {'arrival': 0.5122982488789858}}\n",
      "new state: [0.7303945]\n",
      "old state: [0.5122982]\n",
      "{'iter': 0, 'episode': 58, 'step': 4, 'oldState': array([0.5122982], dtype=float32), 'action': array([0.22178513], dtype=float32), 'reward': -0.4540852904319763, 'newState': array([0.7303945], dtype=float32), 'info': {'arrival': 0.7303944888040963}}\n",
      "new state: [0.5285126]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 59, 'step': 0, 'oldState': array([0.]), 'action': array([0.07626472], dtype=float32), 'reward': -0.35825207456946373, 'newState': array([0.5285126], dtype=float32), 'info': {'arrival': 0.5285126001823446}}\n",
      "new state: [0.7825438]\n",
      "old state: [0.5285126]\n",
      "{'iter': 0, 'episode': 59, 'step': 1, 'oldState': array([0.5285126], dtype=float32), 'action': array([0.6771933], dtype=float32), 'reward': -0.11618304252624512, 'newState': array([0.7825438], dtype=float32), 'info': {'arrival': 0.78254375735801}}\n",
      "new state: [0.51932985]\n",
      "old state: [0.7825438]\n",
      "{'iter': 0, 'episode': 59, 'step': 2, 'oldState': array([0.7825438], dtype=float32), 'action': array([0.5275234], dtype=float32), 'reward': -0.0699002593755722, 'newState': array([0.51932985], dtype=float32), 'info': {'arrival': 0.5193298461153353}}\n",
      "new state: [0.78430057]\n",
      "old state: [0.51932985]\n",
      "{'iter': 0, 'episode': 59, 'step': 3, 'oldState': array([0.51932985], dtype=float32), 'action': array([0.18680403], dtype=float32), 'reward': -0.5312538370490074, 'newState': array([0.78430057], dtype=float32), 'info': {'arrival': 0.7843005449649643}}\n",
      "new state: [0.82763165]\n",
      "old state: [0.78430057]\n",
      "{'iter': 0, 'episode': 59, 'step': 4, 'oldState': array([0.78430057], dtype=float32), 'action': array([0.04847081], dtype=float32), 'reward': -0.7683280855417252, 'newState': array([0.82763165], dtype=float32), 'info': {'arrival': 0.8276316455043388}}\n",
      "new state: [0.9409347]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 60, 'step': 0, 'oldState': array([0.]), 'action': array([0.3425681], dtype=float32), 'reward': -0.534416988492012, 'newState': array([0.9409347], dtype=float32), 'info': {'arrival': 0.9409347336373934}}\n",
      "new state: [0.8160239]\n",
      "old state: [0.9409347]\n",
      "{'iter': 0, 'episode': 60, 'step': 1, 'oldState': array([0.9409347], dtype=float32), 'action': array([0.9608666], dtype=float32), 'reward': -0.11361497640609741, 'newState': array([0.8160239], dtype=float32), 'info': {'arrival': 0.8160238954805253}}\n",
      "new state: [0.76417357]\n",
      "old state: [0.8160239]\n",
      "{'iter': 0, 'episode': 60, 'step': 2, 'oldState': array([0.8160239], dtype=float32), 'action': array([0.12923105], dtype=float32), 'reward': -0.6479051113128662, 'newState': array([0.76417357], dtype=float32), 'info': {'arrival': 0.764173569273353}}\n",
      "new state: [0.9746939]\n",
      "old state: [0.76417357]\n",
      "{'iter': 0, 'episode': 60, 'step': 3, 'oldState': array([0.76417357], dtype=float32), 'action': array([0.25975946], dtype=float32), 'reward': -0.6623043715953827, 'newState': array([0.9746939], dtype=float32), 'info': {'arrival': 0.9746938714340718}}\n",
      "new state: [0.8541017]\n",
      "old state: [0.9746939]\n",
      "{'iter': 0, 'episode': 60, 'step': 4, 'oldState': array([0.9746939], dtype=float32), 'action': array([0.4524078], dtype=float32), 'reward': -0.4318419471383095, 'newState': array([0.8541017], dtype=float32), 'info': {'arrival': 0.8541017463873022}}\n",
      "new state: [0.71991754]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 61, 'step': 0, 'oldState': array([0.]), 'action': array([0.2946578], dtype=float32), 'reward': -0.39260925352573395, 'newState': array([0.71991754], dtype=float32), 'info': {'arrival': 0.7199175414583922}}\n",
      "new state: [0.7945372]\n",
      "old state: [0.71991754]\n",
      "{'iter': 0, 'episode': 61, 'step': 1, 'oldState': array([0.71991754], dtype=float32), 'action': array([0.92278486], dtype=float32), 'reward': -0.14690259099006653, 'newState': array([0.7945372], dtype=float32), 'info': {'arrival': 0.794537212107032}}\n",
      "new state: [0.76531965]\n",
      "old state: [0.7945372]\n",
      "{'iter': 0, 'episode': 61, 'step': 2, 'oldState': array([0.7945372], dtype=float32), 'action': array([0.62238383], dtype=float32), 'reward': -0.1502401977777481, 'newState': array([0.76531965], dtype=float32), 'info': {'arrival': 0.7653196673046467}}\n",
      "new state: [0.5520182]\n",
      "old state: [0.76531965]\n",
      "{'iter': 0, 'episode': 61, 'step': 3, 'oldState': array([0.76531965], dtype=float32), 'action': array([0.46622524], dtype=float32), 'reward': -0.13911834359169006, 'newState': array([0.5520182], dtype=float32), 'info': {'arrival': 0.5520182492494627}}\n",
      "new state: [0.82074195]\n",
      "old state: [0.5520182]\n",
      "{'iter': 0, 'episode': 61, 'step': 4, 'oldState': array([0.5520182], dtype=float32), 'action': array([0.943579], dtype=float32), 'reward': -0.19001799821853638, 'newState': array([0.82074195], dtype=float32), 'info': {'arrival': 0.820741932220253}}\n",
      "new state: [0.57506394]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 62, 'step': 0, 'oldState': array([0.]), 'action': array([0.5421249], dtype=float32), 'reward': -0.16023549437522888, 'newState': array([0.57506394], dtype=float32), 'info': {'arrival': 0.5750639490609591}}\n",
      "new state: [0.8129124]\n",
      "old state: [0.57506394]\n",
      "{'iter': 0, 'episode': 62, 'step': 1, 'oldState': array([0.57506394], dtype=float32), 'action': array([0.72396594], dtype=float32), 'reward': -0.1039353460073471, 'newState': array([0.8129124], dtype=float32), 'info': {'arrival': 0.8129124029860741}}\n",
      "new state: [0.49943727]\n",
      "old state: [0.8129124]\n",
      "{'iter': 0, 'episode': 62, 'step': 2, 'oldState': array([0.8129124], dtype=float32), 'action': array([0.9367134], dtype=float32), 'reward': -0.3589073419570923, 'newState': array([0.49943727], dtype=float32), 'info': {'arrival': 0.4994372690223718}}\n",
      "new state: [0.6696225]\n",
      "old state: [0.49943727]\n",
      "{'iter': 0, 'episode': 62, 'step': 3, 'oldState': array([0.49943727], dtype=float32), 'action': array([0.54375124], dtype=float32), 'reward': -0.10548192262649536, 'newState': array([0.6696225], dtype=float32), 'info': {'arrival': 0.6696224605165714}}\n",
      "new state: [0.550857]\n",
      "old state: [0.6696225]\n",
      "{'iter': 0, 'episode': 62, 'step': 4, 'oldState': array([0.6696225], dtype=float32), 'action': array([0.66708094], dtype=float32), 'reward': -0.08780333399772644, 'newState': array([0.550857], dtype=float32), 'info': {'arrival': 0.5508570014460784}}\n",
      "new state: [0.68669945]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 63, 'step': 0, 'oldState': array([0.]), 'action': array([0.2329731], dtype=float32), 'reward': -0.3985380381345749, 'newState': array([0.68669945], dtype=float32), 'info': {'arrival': 0.6866994546219423}}\n",
      "new state: [0.77775407]\n",
      "old state: [0.68669945]\n",
      "{'iter': 0, 'episode': 63, 'step': 1, 'oldState': array([0.68669945], dtype=float32), 'action': array([0.01253363], dtype=float32), 'reward': -0.7424568086862564, 'newState': array([0.77775407], dtype=float32), 'info': {'arrival': 0.7777540925757552}}\n",
      "new state: [0.6769808]\n",
      "old state: [0.77775407]\n",
      "{'iter': 0, 'episode': 63, 'step': 2, 'oldState': array([0.77775407], dtype=float32), 'action': array([0.8423374], dtype=float32), 'reward': -0.14016331732273102, 'newState': array([0.6769808], dtype=float32), 'info': {'arrival': 0.6769807895558733}}\n",
      "new state: [0.7899459]\n",
      "old state: [0.6769808]\n",
      "{'iter': 0, 'episode': 63, 'step': 3, 'oldState': array([0.6769808], dtype=float32), 'action': array([0.7906052], dtype=float32), 'reward': -0.028900563716888428, 'newState': array([0.7899459], dtype=float32), 'info': {'arrival': 0.789945919738097}}\n",
      "new state: [0.45384064]\n",
      "old state: [0.7899459]\n",
      "{'iter': 0, 'episode': 63, 'step': 4, 'oldState': array([0.7899459], dtype=float32), 'action': array([0.76246935], dtype=float32), 'reward': -0.23834066838026047, 'newState': array([0.45384064], dtype=float32), 'info': {'arrival': 0.4538406364301616}}\n",
      "new state: [0.7348286]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 64, 'step': 0, 'oldState': array([0.]), 'action': array([0.9380066], dtype=float32), 'reward': -0.3868851363658905, 'newState': array([0.7348286], dtype=float32), 'info': {'arrival': 0.7348286163574101}}\n",
      "new state: [0.7985074]\n",
      "old state: [0.7348286]\n",
      "{'iter': 0, 'episode': 64, 'step': 1, 'oldState': array([0.7348286], dtype=float32), 'action': array([0.04453292], dtype=float32), 'reward': -0.7380547970533371, 'newState': array([0.7985074], dtype=float32), 'info': {'arrival': 0.7985073767673707}}\n",
      "new state: [0.6325392]\n",
      "old state: [0.7985074]\n",
      "{'iter': 0, 'episode': 64, 'step': 2, 'oldState': array([0.7985074], dtype=float32), 'action': array([0.18053275], dtype=float32), 'reward': -0.4934985041618347, 'newState': array([0.6325392], dtype=float32), 'info': {'arrival': 0.6325391973894774}}\n",
      "new state: [0.6977539]\n",
      "old state: [0.6325392]\n",
      "{'iter': 0, 'episode': 64, 'step': 3, 'oldState': array([0.6325392], dtype=float32), 'action': array([0.37057972], dtype=float32), 'reward': -0.3108705133199692, 'newState': array([0.6977539], dtype=float32), 'info': {'arrival': 0.6977538917369689}}\n",
      "new state: [0.88777286]\n",
      "old state: [0.6977539]\n",
      "{'iter': 0, 'episode': 64, 'step': 4, 'oldState': array([0.6977539], dtype=float32), 'action': array([0.06917831], dtype=float32), 'reward': -0.7710898220539093, 'newState': array([0.88777286], dtype=float32), 'info': {'arrival': 0.8877728780967145}}\n",
      "new state: [0.8364689]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 65, 'step': 0, 'oldState': array([0.]), 'action': array([0.5958276], dtype=float32), 'reward': -0.32943786680698395, 'newState': array([0.8364689], dtype=float32), 'info': {'arrival': 0.8364688494995344}}\n",
      "new state: [0.89284915]\n",
      "old state: [0.8364689]\n",
      "{'iter': 0, 'episode': 65, 'step': 1, 'oldState': array([0.8364689], dtype=float32), 'action': array([0.6406677], dtype=float32), 'reward': -0.23808640241622925, 'newState': array([0.89284915], dtype=float32), 'info': {'arrival': 0.8928491739851526}}\n",
      "new state: [0.57629466]\n",
      "old state: [0.89284915]\n",
      "{'iter': 0, 'episode': 65, 'step': 2, 'oldState': array([0.89284915], dtype=float32), 'action': array([0.9546071], dtype=float32), 'reward': -0.29917384684085846, 'newState': array([0.57629466], dtype=float32), 'info': {'arrival': 0.5762946369184231}}\n",
      "new state: [0.76515406]\n",
      "old state: [0.57629466]\n",
      "{'iter': 0, 'episode': 65, 'step': 3, 'oldState': array([0.57629466], dtype=float32), 'action': array([0.9344462], dtype=float32), 'reward': -0.21650700271129608, 'newState': array([0.76515406], dtype=float32), 'info': {'arrival': 0.7651540503158188}}\n",
      "new state: [0.9149203]\n",
      "old state: [0.76515406]\n",
      "{'iter': 0, 'episode': 65, 'step': 4, 'oldState': array([0.76515406], dtype=float32), 'action': array([0.9799818], dtype=float32), 'reward': -0.10250306129455566, 'newState': array([0.9149203], dtype=float32), 'info': {'arrival': 0.9149202411119476}}\n",
      "new state: [0.51739943]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 66, 'step': 0, 'oldState': array([0.]), 'action': array([0.97788423], dtype=float32), 'reward': -0.5898346602916718, 'newState': array([0.51739943], dtype=float32), 'info': {'arrival': 0.5173994203618518}}\n",
      "new state: [0.7902491]\n",
      "old state: [0.51739943]\n",
      "{'iter': 0, 'episode': 66, 'step': 1, 'oldState': array([0.51739943], dtype=float32), 'action': array([0.32514638], dtype=float32), 'reward': -0.3968903124332428, 'newState': array([0.7902491], dtype=float32), 'info': {'arrival': 0.7902491250116424}}\n",
      "new state: [0.8377475]\n",
      "old state: [0.7902491]\n",
      "{'iter': 0, 'episode': 66, 'step': 2, 'oldState': array([0.7902491], dtype=float32), 'action': array([0.13916105], dtype=float32), 'reward': -0.6867118626832962, 'newState': array([0.8377475], dtype=float32), 'info': {'arrival': 0.8377474943797376}}\n",
      "new state: [0.78852576]\n",
      "old state: [0.8377475]\n",
      "{'iter': 0, 'episode': 66, 'step': 3, 'oldState': array([0.8377475], dtype=float32), 'action': array([0.13244595], dtype=float32), 'reward': -0.6683852672576904, 'newState': array([0.78852576], dtype=float32), 'info': {'arrival': 0.7885257652880858}}\n",
      "new state: [0.72617495]\n",
      "old state: [0.78852576]\n",
      "{'iter': 0, 'episode': 66, 'step': 4, 'oldState': array([0.78852576], dtype=float32), 'action': array([0.03476222], dtype=float32), 'reward': -0.7070004492998123, 'newState': array([0.72617495], dtype=float32), 'info': {'arrival': 0.726174957996835}}\n",
      "new state: [0.58137715]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 67, 'step': 0, 'oldState': array([0.]), 'action': array([0.10103215], dtype=float32), 'reward': -0.385516794398427, 'newState': array([0.58137715], dtype=float32), 'info': {'arrival': 0.5813771487458415}}\n",
      "new state: [0.6720593]\n",
      "old state: [0.58137715]\n",
      "{'iter': 0, 'episode': 67, 'step': 1, 'oldState': array([0.58137715], dtype=float32), 'action': array([0.77319634], dtype=float32), 'reward': -0.12380757927894592, 'newState': array([0.6720593], dtype=float32), 'info': {'arrival': 0.6720592785470278}}\n",
      "new state: [0.8270696]\n",
      "old state: [0.6720593]\n",
      "{'iter': 0, 'episode': 67, 'step': 2, 'oldState': array([0.6720593], dtype=float32), 'action': array([0.29070225], dtype=float32), 'reward': -0.4976147338747978, 'newState': array([0.8270696], dtype=float32), 'info': {'arrival': 0.8270695932855731}}\n",
      "new state: [0.9433466]\n",
      "old state: [0.8270696]\n",
      "{'iter': 0, 'episode': 67, 'step': 3, 'oldState': array([0.8270696], dtype=float32), 'action': array([0.9735769], dtype=float32), 'reward': -0.059299543499946594, 'newState': array([0.9433466], dtype=float32), 'info': {'arrival': 0.9433465902954307}}\n",
      "new state: [0.85189396]\n",
      "old state: [0.9433466]\n",
      "{'iter': 0, 'episode': 67, 'step': 4, 'oldState': array([0.9433466], dtype=float32), 'action': array([0.8664779], dtype=float32), 'reward': -0.030155137181282043, 'newState': array([0.85189396], dtype=float32), 'info': {'arrival': 0.8518939679744303}}\n",
      "new state: [0.777024]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 68, 'step': 0, 'oldState': array([0.]), 'action': array([0.81218463], dtype=float32), 'reward': -0.2294166535139084, 'newState': array([0.777024], dtype=float32), 'info': {'arrival': 0.7770240004445643}}\n",
      "new state: [0.3214222]\n",
      "old state: [0.777024]\n",
      "{'iter': 0, 'episode': 68, 'step': 1, 'oldState': array([0.777024], dtype=float32), 'action': array([0.19774844], dtype=float32), 'reward': -0.23757420107722282, 'newState': array([0.3214222], dtype=float32), 'info': {'arrival': 0.3214222035924756}}\n",
      "new state: [0.5258238]\n",
      "old state: [0.3214222]\n",
      "{'iter': 0, 'episode': 68, 'step': 2, 'oldState': array([0.3214222], dtype=float32), 'action': array([0.10813888], dtype=float32), 'reward': -0.36658448725938797, 'newState': array([0.5258238], dtype=float32), 'info': {'arrival': 0.5258237718919158}}\n",
      "new state: [0.89484066]\n",
      "old state: [0.5258238]\n",
      "{'iter': 0, 'episode': 68, 'step': 3, 'oldState': array([0.5258238], dtype=float32), 'action': array([0.6698087], dtype=float32), 'reward': -0.20477020740509033, 'newState': array([0.89484066], dtype=float32), 'info': {'arrival': 0.8948406382071875}}\n",
      "new state: [0.6403628]\n",
      "old state: [0.89484066]\n",
      "{'iter': 0, 'episode': 68, 'step': 4, 'oldState': array([0.89484066], dtype=float32), 'action': array([0.6612509], dtype=float32), 'reward': -0.0740635097026825, 'newState': array([0.6403628], dtype=float32), 'info': {'arrival': 0.6403628035050702}}\n",
      "new state: [0.7456623]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 69, 'step': 0, 'oldState': array([0.]), 'action': array([0.67464966], dtype=float32), 'reward': -0.2219218760728836, 'newState': array([0.7456623], dtype=float32), 'info': {'arrival': 0.7456622552252891}}\n",
      "new state: [0.80440253]\n",
      "old state: [0.7456623]\n",
      "{'iter': 0, 'episode': 69, 'step': 1, 'oldState': array([0.7456623], dtype=float32), 'action': array([0.8152462], dtype=float32), 'reward': -0.025528758764266968, 'newState': array([0.80440253], dtype=float32), 'info': {'arrival': 0.8044025316956415}}\n",
      "new state: [0.7083278]\n",
      "old state: [0.80440253]\n",
      "{'iter': 0, 'episode': 69, 'step': 2, 'oldState': array([0.80440253], dtype=float32), 'action': array([0.7111211], dtype=float32), 'reward': -0.025415346026420593, 'newState': array([0.7083278], dtype=float32), 'info': {'arrival': 0.7083277977745258}}\n",
      "new state: [0.6908126]\n",
      "old state: [0.7083278]\n",
      "{'iter': 0, 'episode': 69, 'step': 3, 'oldState': array([0.7083278], dtype=float32), 'action': array([0.4852275], dtype=float32), 'reward': -0.20996388792991638, 'newState': array([0.6908126], dtype=float32), 'info': {'arrival': 0.6908125953097698}}\n",
      "new state: [0.7143122]\n",
      "old state: [0.6908126]\n",
      "{'iter': 0, 'episode': 69, 'step': 4, 'oldState': array([0.6908126], dtype=float32), 'action': array([0.0383028], dtype=float32), 'reward': -0.6701345145702362, 'newState': array([0.7143122], dtype=float32), 'info': {'arrival': 0.7143121990614221}}\n",
      "new state: [0.74331504]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 70, 'step': 0, 'oldState': array([0.]), 'action': array([0.8548038], dtype=float32), 'reward': -0.2973175197839737, 'newState': array([0.74331504], dtype=float32), 'info': {'arrival': 0.7433150373741683}}\n",
      "new state: [0.4942687]\n",
      "old state: [0.74331504]\n",
      "{'iter': 0, 'episode': 70, 'step': 1, 'oldState': array([0.74331504], dtype=float32), 'action': array([0.27342424], dtype=float32), 'reward': -0.2831060364842415, 'newState': array([0.4942687], dtype=float32), 'info': {'arrival': 0.49426869081101316}}\n",
      "new state: [0.47342643]\n",
      "old state: [0.4942687]\n",
      "{'iter': 0, 'episode': 70, 'step': 2, 'oldState': array([0.4942687], dtype=float32), 'action': array([0.85787934], dtype=float32), 'reward': -0.37924234569072723, 'newState': array([0.47342643], dtype=float32), 'info': {'arrival': 0.47342641943627084}}\n",
      "new state: [0.66859925]\n",
      "old state: [0.47342643]\n",
      "{'iter': 0, 'episode': 70, 'step': 3, 'oldState': array([0.47342643], dtype=float32), 'action': array([0.8640447], dtype=float32), 'reward': -0.24423868209123611, 'newState': array([0.66859925], dtype=float32), 'info': {'arrival': 0.668599252637797}}\n",
      "new state: [0.648243]\n",
      "old state: [0.66859925]\n",
      "{'iter': 0, 'episode': 70, 'step': 4, 'oldState': array([0.66859925], dtype=float32), 'action': array([0.65684193], dtype=float32), 'reward': -0.009388521313667297, 'newState': array([0.648243], dtype=float32), 'info': {'arrival': 0.6482430368575168}}\n",
      "new state: [0.5571935]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 71, 'step': 0, 'oldState': array([0.]), 'action': array([0.63811475], dtype=float32), 'reward': -0.22021961212158203, 'newState': array([0.5571935], dtype=float32), 'info': {'arrival': 0.5571935372155038}}\n",
      "new state: [0.7531541]\n",
      "old state: [0.5571935]\n",
      "{'iter': 0, 'episode': 71, 'step': 1, 'oldState': array([0.5571935], dtype=float32), 'action': array([0.4900543], dtype=float32), 'reward': -0.2141096442937851, 'newState': array([0.7531541], dtype=float32), 'info': {'arrival': 0.7531540707543828}}\n",
      "new state: [0.9377732]\n",
      "old state: [0.7531541]\n",
      "{'iter': 0, 'episode': 71, 'step': 2, 'oldState': array([0.7531541], dtype=float32), 'action': array([0.85960287], dtype=float32), 'reward': -0.0852399617433548, 'newState': array([0.9377732], dtype=float32), 'info': {'arrival': 0.9377732101515662}}\n",
      "new state: [0.82148856]\n",
      "old state: [0.9377732]\n",
      "{'iter': 0, 'episode': 71, 'step': 3, 'oldState': array([0.9377732], dtype=float32), 'action': array([0.8360593], dtype=float32), 'reward': -0.036356523633003235, 'newState': array([0.82148856], dtype=float32), 'info': {'arrival': 0.8214885554572785}}\n",
      "new state: [0.6693404]\n",
      "old state: [0.82148856]\n",
      "{'iter': 0, 'episode': 71, 'step': 4, 'oldState': array([0.82148856], dtype=float32), 'action': array([0.0867425], dtype=float32), 'reward': -0.6206348985433578, 'newState': array([0.6693404], dtype=float32), 'info': {'arrival': 0.6693403624087106}}\n",
      "new state: [0.71411985]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 72, 'step': 0, 'oldState': array([0.]), 'action': array([0.23510376], dtype=float32), 'reward': -0.418038010597229, 'newState': array([0.71411985], dtype=float32), 'info': {'arrival': 0.7141198325443793}}\n",
      "new state: [0.36101767]\n",
      "old state: [0.71411985]\n",
      "{'iter': 0, 'episode': 72, 'step': 1, 'oldState': array([0.71411985], dtype=float32), 'action': array([0.18954769], dtype=float32), 'reward': -0.2597455233335495, 'newState': array([0.36101767], dtype=float32), 'info': {'arrival': 0.36101768018302227}}\n",
      "new state: [0.6241622]\n",
      "old state: [0.36101767]\n",
      "{'iter': 0, 'episode': 72, 'step': 2, 'oldState': array([0.36101767], dtype=float32), 'action': array([0.39230224], dtype=float32), 'reward': -0.18171610683202744, 'newState': array([0.6241622], dtype=float32), 'info': {'arrival': 0.6241621817911855}}\n",
      "new state: [0.64479214]\n",
      "old state: [0.6241622]\n",
      "{'iter': 0, 'episode': 72, 'step': 3, 'oldState': array([0.6241622], dtype=float32), 'action': array([0.11625247], dtype=float32), 'reward': -0.5233821719884872, 'newState': array([0.64479214], dtype=float32), 'info': {'arrival': 0.6447921524009946}}\n",
      "new state: [0.592558]\n",
      "old state: [0.64479214]\n",
      "{'iter': 0, 'episode': 72, 'step': 4, 'oldState': array([0.64479214], dtype=float32), 'action': array([0.08711432], dtype=float32), 'reward': -0.5185022205114365, 'newState': array([0.592558], dtype=float32), 'info': {'arrival': 0.5925580153451021}}\n",
      "new state: [0.5468152]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 73, 'step': 0, 'oldState': array([0.]), 'action': array([0.7990808], dtype=float32), 'reward': -0.38896937668323517, 'newState': array([0.5468152], dtype=float32), 'info': {'arrival': 0.5468152000118791}}\n",
      "new state: [0.72500265]\n",
      "old state: [0.5468152]\n",
      "{'iter': 0, 'episode': 73, 'step': 1, 'oldState': array([0.5468152], dtype=float32), 'action': array([0.31721616], dtype=float32), 'reward': -0.3632396310567856, 'newState': array([0.72500265], dtype=float32), 'info': {'arrival': 0.7250026279037325}}\n",
      "new state: [0.7854812]\n",
      "old state: [0.72500265]\n",
      "{'iter': 0, 'episode': 73, 'step': 2, 'oldState': array([0.72500265], dtype=float32), 'action': array([0.15259624], dtype=float32), 'reward': -0.617765337228775, 'newState': array([0.7854812], dtype=float32), 'info': {'arrival': 0.7854811966709262}}\n",
      "new state: [0.9429784]\n",
      "old state: [0.7854812]\n",
      "{'iter': 0, 'episode': 73, 'step': 3, 'oldState': array([0.7854812], dtype=float32), 'action': array([0.27831343], dtype=float32), 'reward': -0.6252906918525696, 'newState': array([0.9429784], dtype=float32), 'info': {'arrival': 0.9429783876319696}}\n",
      "new state: [0.40035945]\n",
      "old state: [0.9429784]\n",
      "{'iter': 0, 'episode': 73, 'step': 4, 'oldState': array([0.9429784], dtype=float32), 'action': array([0.2860485], dtype=float32), 'reward': -0.24996567517518997, 'newState': array([0.40035945], dtype=float32), 'info': {'arrival': 0.4003594575974754}}\n",
      "new state: [0.9150442]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 74, 'step': 0, 'oldState': array([0.]), 'action': array([0.43365532], dtype=float32), 'reward': -0.4694554805755615, 'newState': array([0.9150442], dtype=float32), 'info': {'arrival': 0.9150441996592176}}\n",
      "new state: [0.78882444]\n",
      "old state: [0.9150442]\n",
      "{'iter': 0, 'episode': 74, 'step': 1, 'oldState': array([0.9150442], dtype=float32), 'action': array([0.5670899], dtype=float32), 'reward': -0.25328946113586426, 'newState': array([0.78882444], dtype=float32), 'info': {'arrival': 0.7888244167243201}}\n",
      "new state: [0.78676605]\n",
      "old state: [0.78882444]\n",
      "{'iter': 0, 'episode': 74, 'step': 2, 'oldState': array([0.78882444], dtype=float32), 'action': array([0.37380916], dtype=float32), 'reward': -0.4134714901447296, 'newState': array([0.78676605], dtype=float32), 'info': {'arrival': 0.7867660653305667}}\n",
      "new state: [0.8087346]\n",
      "old state: [0.78676605]\n",
      "{'iter': 0, 'episode': 74, 'step': 3, 'oldState': array([0.78676605], dtype=float32), 'action': array([0.70318305], dtype=float32), 'reward': -0.1000594049692154, 'newState': array([0.8087346], dtype=float32), 'info': {'arrival': 0.8087345811879333}}\n",
      "new state: [0.6842341]\n",
      "old state: [0.8087346]\n",
      "{'iter': 0, 'episode': 74, 'step': 4, 'oldState': array([0.8087346], dtype=float32), 'action': array([0.9281343], dtype=float32), 'reward': -0.2127751111984253, 'newState': array([0.6842341], dtype=float32), 'info': {'arrival': 0.6842340750434995}}\n",
      "new state: [0.49946052]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 75, 'step': 0, 'oldState': array([0.]), 'action': array([0.23578526], dtype=float32), 'reward': -0.2567027695477009, 'newState': array([0.49946052], dtype=float32), 'info': {'arrival': 0.49946051249779494}}\n",
      "new state: [0.4934828]\n",
      "old state: [0.49946052]\n",
      "{'iter': 0, 'episode': 75, 'step': 1, 'oldState': array([0.49946052], dtype=float32), 'action': array([0.05879749], dtype=float32), 'reward': -0.4361797273159027, 'newState': array([0.4934828], dtype=float32), 'info': {'arrival': 0.4934827990344383}}\n",
      "new state: [0.96843505]\n",
      "old state: [0.4934828]\n",
      "{'iter': 0, 'episode': 75, 'step': 2, 'oldState': array([0.4934828], dtype=float32), 'action': array([0.15321945], dtype=float32), 'reward': -0.6964775323867798, 'newState': array([0.96843505], dtype=float32), 'info': {'arrival': 0.9684350428490366}}\n",
      "new state: [0.8622722]\n",
      "old state: [0.96843505]\n",
      "{'iter': 0, 'episode': 75, 'step': 3, 'oldState': array([0.96843505], dtype=float32), 'action': array([0.75946164], dtype=float32), 'reward': -0.12935127317905426, 'newState': array([0.8622722], dtype=float32), 'info': {'arrival': 0.8622721742823163}}\n",
      "new state: [0.94781715]\n",
      "old state: [0.8622722]\n",
      "{'iter': 0, 'episode': 75, 'step': 4, 'oldState': array([0.8622722], dtype=float32), 'action': array([0.4307218], dtype=float32), 'reward': -0.4957090988755226, 'newState': array([0.94781715], dtype=float32), 'info': {'arrival': 0.9478171458665169}}\n",
      "new state: [0.9348187]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 76, 'step': 0, 'oldState': array([0.]), 'action': array([0.43662605], dtype=float32), 'reward': -0.48280099034309387, 'newState': array([0.9348187], dtype=float32), 'info': {'arrival': 0.9348187038971566}}\n",
      "new state: [0.7429716]\n",
      "old state: [0.9348187]\n",
      "{'iter': 0, 'episode': 76, 'step': 1, 'oldState': array([0.9348187], dtype=float32), 'action': array([0.8663579], dtype=float32), 'reward': -0.10965493321418762, 'newState': array([0.7429716], dtype=float32), 'info': {'arrival': 0.7429715803265481}}\n",
      "new state: [0.5725135]\n",
      "old state: [0.7429716]\n",
      "{'iter': 0, 'episode': 76, 'step': 2, 'oldState': array([0.7429716], dtype=float32), 'action': array([0.8150544], dtype=float32), 'reward': -0.19992637634277344, 'newState': array([0.5725135], dtype=float32), 'info': {'arrival': 0.5725135251275749}}\n",
      "new state: [0.66782606]\n",
      "old state: [0.5725135]\n",
      "{'iter': 0, 'episode': 76, 'step': 3, 'oldState': array([0.5725135], dtype=float32), 'action': array([0.06656423], dtype=float32), 'reward': -0.577433705329895, 'newState': array([0.66782606], dtype=float32), 'info': {'arrival': 0.6678260693270854}}\n",
      "new state: [0.46783718]\n",
      "old state: [0.66782606]\n",
      "{'iter': 0, 'episode': 76, 'step': 4, 'oldState': array([0.66782606], dtype=float32), 'action': array([0.15173954], dtype=float32), 'reward': -0.3660948649048805, 'newState': array([0.46783718], dtype=float32), 'info': {'arrival': 0.4678371865695226}}\n",
      "new state: [0.7828447]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 77, 'step': 0, 'oldState': array([0.]), 'action': array([0.1459708], dtype=float32), 'reward': -0.5141481272876263, 'newState': array([0.7828447], dtype=float32), 'info': {'arrival': 0.7828446996496927}}\n",
      "new state: [0.82475996]\n",
      "old state: [0.7828447]\n",
      "{'iter': 0, 'episode': 77, 'step': 1, 'oldState': array([0.7828447], dtype=float32), 'action': array([0.9617896], dtype=float32), 'reward': -0.14750845730304718, 'newState': array([0.82475996], dtype=float32), 'info': {'arrival': 0.8247599495039052}}\n",
      "new state: [0.58057934]\n",
      "old state: [0.82475996]\n",
      "{'iter': 0, 'episode': 77, 'step': 2, 'oldState': array([0.82475996], dtype=float32), 'action': array([0.2654063], dtype=float32), 'reward': -0.37621818482875824, 'newState': array([0.58057934], dtype=float32), 'info': {'arrival': 0.5805793626332646}}\n",
      "new state: [0.77490014]\n",
      "old state: [0.58057934]\n",
      "{'iter': 0, 'episode': 77, 'step': 3, 'oldState': array([0.58057934], dtype=float32), 'action': array([0.5968437], dtype=float32), 'reward': -0.13760840892791748, 'newState': array([0.77490014], dtype=float32), 'info': {'arrival': 0.7749001117585003}}\n",
      "new state: [0.9257245]\n",
      "old state: [0.77490014]\n",
      "{'iter': 0, 'episode': 77, 'step': 4, 'oldState': array([0.77490014], dtype=float32), 'action': array([0.02527317], dtype=float32), 'reward': -0.8627452254295349, 'newState': array([0.9257245], dtype=float32), 'info': {'arrival': 0.92572448545161}}\n",
      "new state: [0.62684184]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 78, 'step': 0, 'oldState': array([0.]), 'action': array([0.03158473], dtype=float32), 'reward': -0.45433900970965624, 'newState': array([0.62684184], dtype=float32), 'info': {'arrival': 0.6268418345156479}}\n",
      "new state: [0.7838929]\n",
      "old state: [0.62684184]\n",
      "{'iter': 0, 'episode': 78, 'step': 1, 'oldState': array([0.62684184], dtype=float32), 'action': array([0.71774447], dtype=float32), 'reward': -0.07233700156211853, 'newState': array([0.7838929], dtype=float32), 'info': {'arrival': 0.7838929420600358}}\n",
      "new state: [0.6645933]\n",
      "old state: [0.7838929]\n",
      "{'iter': 0, 'episode': 78, 'step': 2, 'oldState': array([0.7838929], dtype=float32), 'action': array([0.54521185], dtype=float32), 'reward': -0.14920634031295776, 'newState': array([0.6645933], dtype=float32), 'info': {'arrival': 0.6645932933725874}}\n",
      "new state: [0.46270058]\n",
      "old state: [0.6645933]\n",
      "{'iter': 0, 'episode': 78, 'step': 3, 'oldState': array([0.6645933], dtype=float32), 'action': array([0.63452065], dtype=float32), 'reward': -0.13638321310281754, 'newState': array([0.46270058], dtype=float32), 'info': {'arrival': 0.4627005736315093}}\n",
      "new state: [0.83686525]\n",
      "old state: [0.46270058]\n",
      "{'iter': 0, 'episode': 78, 'step': 4, 'oldState': array([0.46270058], dtype=float32), 'action': array([0.9627482], dtype=float32), 'reward': -0.21942415833473206, 'newState': array([0.83686525], dtype=float32), 'info': {'arrival': 0.8368652482521912}}\n",
      "new state: [0.324246]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 79, 'step': 0, 'oldState': array([0.]), 'action': array([0.22438571], dtype=float32), 'reward': -0.1309916377067566, 'newState': array([0.324246], dtype=float32), 'info': {'arrival': 0.3242459879409803}}\n",
      "new state: [0.5398882]\n",
      "old state: [0.324246]\n",
      "{'iter': 0, 'episode': 79, 'step': 1, 'oldState': array([0.324246], dtype=float32), 'action': array([0.0084311], dtype=float32), 'reward': -0.4775465652346611, 'newState': array([0.5398882], dtype=float32), 'info': {'arrival': 0.5398882286517563}}\n",
      "new state: [0.7796992]\n",
      "old state: [0.5398882]\n",
      "{'iter': 0, 'episode': 79, 'step': 2, 'oldState': array([0.5398882], dtype=float32), 'action': array([0.5559118], dtype=float32), 'reward': -0.17184646427631378, 'newState': array([0.7796992], dtype=float32), 'info': {'arrival': 0.7796991779685407}}\n",
      "new state: [0.8191982]\n",
      "old state: [0.7796992]\n",
      "{'iter': 0, 'episode': 79, 'step': 3, 'oldState': array([0.7796992], dtype=float32), 'action': array([0.08800372], dtype=float32), 'reward': -0.7213197499513626, 'newState': array([0.8191982], dtype=float32), 'info': {'arrival': 0.8191981925067457}}\n",
      "new state: [0.75914013]\n",
      "old state: [0.8191982]\n",
      "{'iter': 0, 'episode': 79, 'step': 4, 'oldState': array([0.8191982], dtype=float32), 'action': array([0.28665343], dtype=float32), 'reward': -0.48750121146440506, 'newState': array([0.75914013], dtype=float32), 'info': {'arrival': 0.7591401122241908}}\n",
      "new state: [0.09629539]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 80, 'step': 0, 'oldState': array([0.]), 'action': array([0.13030085], dtype=float32), 'reward': -0.0580793097615242, 'newState': array([0.09629539], dtype=float32), 'info': {'arrival': 0.09629538439131806}}\n",
      "new state: [0.85594475]\n",
      "old state: [0.09629539]\n",
      "{'iter': 0, 'episode': 80, 'step': 1, 'oldState': array([0.09629539], dtype=float32), 'action': array([0.17728579], dtype=float32), 'reward': -0.5292418226599693, 'newState': array([0.85594475], dtype=float32), 'info': {'arrival': 0.8559447822180756}}\n",
      "new state: [0.64530396]\n",
      "old state: [0.85594475]\n",
      "{'iter': 0, 'episode': 80, 'step': 2, 'oldState': array([0.85594475], dtype=float32), 'action': array([0.42280805], dtype=float32), 'reward': -0.2751561105251312, 'newState': array([0.64530396], dtype=float32), 'info': {'arrival': 0.6453039662716374}}\n",
      "new state: [0.47270688]\n",
      "old state: [0.64530396]\n",
      "{'iter': 0, 'episode': 80, 'step': 3, 'oldState': array([0.64530396], dtype=float32), 'action': array([0.10447172], dtype=float32), 'reward': -0.4113844335079193, 'newState': array([0.47270688], dtype=float32), 'info': {'arrival': 0.4727068937677536}}\n",
      "new state: [0.60063213]\n",
      "old state: [0.47270688]\n",
      "{'iter': 0, 'episode': 80, 'step': 4, 'oldState': array([0.47270688], dtype=float32), 'action': array([0.39352015], dtype=float32), 'reward': -0.1751306727528572, 'newState': array([0.60063213], dtype=float32), 'info': {'arrival': 0.6006321230708583}}\n",
      "new state: [0.56383616]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 81, 'step': 0, 'oldState': array([0.]), 'action': array([0.34008867], dtype=float32), 'reward': -0.2528327852487564, 'newState': array([0.56383616], dtype=float32), 'info': {'arrival': 0.5638361849033232}}\n",
      "new state: [0.66741455]\n",
      "old state: [0.56383616]\n",
      "{'iter': 0, 'episode': 81, 'step': 1, 'oldState': array([0.56383616], dtype=float32), 'action': array([0.32251477], dtype=float32), 'reward': -0.31900517642498016, 'newState': array([0.66741455], dtype=float32), 'info': {'arrival': 0.6674145393141453}}\n",
      "new state: [0.95814985]\n",
      "old state: [0.66741455]\n",
      "{'iter': 0, 'episode': 81, 'step': 2, 'oldState': array([0.66741455], dtype=float32), 'action': array([0.5830227], dtype=float32), 'reward': -0.3024433106184006, 'newState': array([0.95814985], dtype=float32), 'info': {'arrival': 0.9581498570662992}}\n",
      "new state: [0.7406182]\n",
      "old state: [0.95814985]\n",
      "{'iter': 0, 'episode': 81, 'step': 3, 'oldState': array([0.95814985], dtype=float32), 'action': array([0.031573], dtype=float32), 'reward': -0.7634281367063522, 'newState': array([0.7406182], dtype=float32), 'info': {'arrival': 0.7406182093194253}}\n",
      "new state: [0.48082915]\n",
      "old state: [0.7406182]\n",
      "{'iter': 0, 'episode': 81, 'step': 4, 'oldState': array([0.7406182], dtype=float32), 'action': array([0.653217], dtype=float32), 'reward': -0.1511412039399147, 'newState': array([0.48082915], dtype=float32), 'info': {'arrival': 0.48082913785860915}}\n",
      "new state: [0.62907857]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 82, 'step': 0, 'oldState': array([0.]), 'action': array([0.68947095], dtype=float32), 'reward': -0.2176620215177536, 'newState': array([0.62907857], dtype=float32), 'info': {'arrival': 0.6290785683159082}}\n",
      "new state: [0.91150457]\n",
      "old state: [0.62907857]\n",
      "{'iter': 0, 'episode': 82, 'step': 1, 'oldState': array([0.62907857], dtype=float32), 'action': array([0.1168726], dtype=float32), 'reward': -0.7240254580974579, 'newState': array([0.91150457], dtype=float32), 'info': {'arrival': 0.9115045638121254}}\n",
      "new state: [0.8212236]\n",
      "old state: [0.91150457]\n",
      "{'iter': 0, 'episode': 82, 'step': 2, 'oldState': array([0.91150457], dtype=float32), 'action': array([0.706825], dtype=float32), 'reward': -0.13696883618831635, 'newState': array([0.8212236], dtype=float32), 'info': {'arrival': 0.8212236456735903}}\n",
      "new state: [0.7997115]\n",
      "old state: [0.8212236]\n",
      "{'iter': 0, 'episode': 82, 'step': 3, 'oldState': array([0.8212236], dtype=float32), 'action': array([0.7913219], dtype=float32), 'reward': -0.013767674565315247, 'newState': array([0.7997115], dtype=float32), 'info': {'arrival': 0.7997115467257923}}\n",
      "new state: [0.96387064]\n",
      "old state: [0.7997115]\n",
      "{'iter': 0, 'episode': 82, 'step': 4, 'oldState': array([0.7997115], dtype=float32), 'action': array([0.59886736], dtype=float32), 'reward': -0.3239635080099106, 'newState': array([0.96387064], dtype=float32), 'info': {'arrival': 0.9638706724289829}}\n",
      "new state: [0.63452995]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 83, 'step': 0, 'oldState': array([0.]), 'action': array([0.17224722], dtype=float32), 'reward': -0.3897738419473171, 'newState': array([0.63452995], dtype=float32), 'info': {'arrival': 0.6345299402570899}}\n",
      "new state: [0.60282344]\n",
      "old state: [0.63452995]\n",
      "{'iter': 0, 'episode': 83, 'step': 1, 'oldState': array([0.63452995], dtype=float32), 'action': array([0.43579108], dtype=float32), 'reward': -0.1749589890241623, 'newState': array([0.60282344], dtype=float32), 'info': {'arrival': 0.6028234374293154}}\n",
      "new state: [0.8050821]\n",
      "old state: [0.60282344]\n",
      "{'iter': 0, 'episode': 83, 'step': 2, 'oldState': array([0.60282344], dtype=float32), 'action': array([0.34539405], dtype=float32), 'reward': -0.40912337601184845, 'newState': array([0.8050821], dtype=float32), 'info': {'arrival': 0.8050820715470987}}\n",
      "new state: [0.9256663]\n",
      "old state: [0.8050821]\n",
      "{'iter': 0, 'episode': 83, 'step': 3, 'oldState': array([0.8050821], dtype=float32), 'action': array([0.5768088], dtype=float32), 'reward': -0.31871141493320465, 'newState': array([0.9256663], dtype=float32), 'info': {'arrival': 0.9256662717081925}}\n",
      "new state: [0.73043394]\n",
      "old state: [0.9256663]\n",
      "{'iter': 0, 'episode': 83, 'step': 4, 'oldState': array([0.9256663], dtype=float32), 'action': array([0.91605556], dtype=float32), 'reward': -0.14161889255046844, 'newState': array([0.73043394], dtype=float32), 'info': {'arrival': 0.7304339197500335}}\n",
      "new state: [0.65568745]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 84, 'step': 0, 'oldState': array([0.]), 'action': array([0.42437467], dtype=float32), 'reward': -0.2795782536268234, 'newState': array([0.65568745], dtype=float32), 'info': {'arrival': 0.65568747170472}}\n",
      "new state: [0.87575567]\n",
      "old state: [0.65568745]\n",
      "{'iter': 0, 'episode': 84, 'step': 1, 'oldState': array([0.65568745], dtype=float32), 'action': array([0.31787267], dtype=float32), 'reward': -0.5028659626841545, 'newState': array([0.87575567], dtype=float32), 'info': {'arrival': 0.8757556719666431}}\n",
      "new state: [0.6547974]\n",
      "old state: [0.87575567]\n",
      "{'iter': 0, 'episode': 84, 'step': 2, 'oldState': array([0.87575567], dtype=float32), 'action': array([0.36896598], dtype=float32), 'reward': -0.3410709649324417, 'newState': array([0.6547974], dtype=float32), 'info': {'arrival': 0.6547973928715123}}\n",
      "new state: [0.7071265]\n",
      "old state: [0.6547974]\n",
      "{'iter': 0, 'episode': 84, 'step': 3, 'oldState': array([0.6547974], dtype=float32), 'action': array([0.90694684], dtype=float32), 'reward': -0.21290262043476105, 'newState': array([0.7071265], dtype=float32), 'info': {'arrival': 0.7071264747586061}}\n",
      "new state: [0.7365039]\n",
      "old state: [0.7071265]\n",
      "{'iter': 0, 'episode': 84, 'step': 4, 'oldState': array([0.7071265], dtype=float32), 'action': array([0.5010108], dtype=float32), 'reward': -0.22814877331256866, 'newState': array([0.7365039], dtype=float32), 'info': {'arrival': 0.7365039083942263}}\n",
      "new state: [0.80077493]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 85, 'step': 0, 'oldState': array([0.]), 'action': array([0.33117703], dtype=float32), 'reward': -0.4349926859140396, 'newState': array([0.80077493], dtype=float32), 'info': {'arrival': 0.8007749087389159}}\n",
      "new state: [0.8279594]\n",
      "old state: [0.80077493]\n",
      "{'iter': 0, 'episode': 85, 'step': 1, 'oldState': array([0.80077493], dtype=float32), 'action': array([0.65058434], dtype=float32), 'reward': -0.1705789566040039, 'newState': array([0.8279594], dtype=float32), 'info': {'arrival': 0.8279594011820167}}\n",
      "new state: [0.78717417]\n",
      "old state: [0.8279594]\n",
      "{'iter': 0, 'episode': 85, 'step': 2, 'oldState': array([0.8279594], dtype=float32), 'action': array([0.11439036], dtype=float32), 'reward': -0.6829801052808762, 'newState': array([0.78717417], dtype=float32), 'info': {'arrival': 0.787174154748341}}\n",
      "new state: [0.9578524]\n",
      "old state: [0.78717417]\n",
      "{'iter': 0, 'episode': 85, 'step': 3, 'oldState': array([0.78717417], dtype=float32), 'action': array([0.819688], dtype=float32), 'reward': -0.11175176501274109, 'newState': array([0.9578524], dtype=float32), 'info': {'arrival': 0.9578524488652018}}\n",
      "new state: [0.42943543]\n",
      "old state: [0.9578524]\n",
      "{'iter': 0, 'episode': 85, 'step': 4, 'oldState': array([0.9578524], dtype=float32), 'action': array([0.87776035], dtype=float32), 'reward': -0.35626670718193054, 'newState': array([0.42943543], dtype=float32), 'info': {'arrival': 0.42943543715842447}}\n",
      "new state: [0.64658093]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 86, 'step': 0, 'oldState': array([0.]), 'action': array([0.52176607], dtype=float32), 'reward': -0.22405266761779785, 'newState': array([0.64658093], dtype=float32), 'info': {'arrival': 0.646580941956345}}\n",
      "new state: [0.9447215]\n",
      "old state: [0.64658093]\n",
      "{'iter': 0, 'episode': 86, 'step': 1, 'oldState': array([0.64658093], dtype=float32), 'action': array([0.19266298], dtype=float32), 'reward': -0.6775233671069145, 'newState': array([0.9447215], dtype=float32), 'info': {'arrival': 0.9447215072468748}}\n",
      "new state: [0.71258795]\n",
      "old state: [0.9447215]\n",
      "{'iter': 0, 'episode': 86, 'step': 2, 'oldState': array([0.9447215], dtype=float32), 'action': array([0.9531033], dtype=float32), 'reward': -0.18248195946216583, 'newState': array([0.71258795], dtype=float32), 'info': {'arrival': 0.7125879742200252}}\n",
      "new state: [0.9883577]\n",
      "old state: [0.71258795]\n",
      "{'iter': 0, 'episode': 86, 'step': 3, 'oldState': array([0.71258795], dtype=float32), 'action': array([0.584809], dtype=float32), 'reward': -0.33460627496242523, 'newState': array([0.9883577], dtype=float32), 'info': {'arrival': 0.988357729867725}}\n",
      "new state: [0.72767603]\n",
      "old state: [0.9883577]\n",
      "{'iter': 0, 'episode': 86, 'step': 4, 'oldState': array([0.9883577], dtype=float32), 'action': array([0.64299184], dtype=float32), 'reward': -0.1498546153306961, 'newState': array([0.72767603], dtype=float32), 'info': {'arrival': 0.7276760522066898}}\n",
      "new state: [0.7559243]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 87, 'step': 0, 'oldState': array([0.]), 'action': array([0.74462265], dtype=float32), 'reward': -0.194631889462471, 'newState': array([0.7559243], dtype=float32), 'info': {'arrival': 0.7559242955327913}}\n",
      "new state: [0.40245855]\n",
      "old state: [0.7559243]\n",
      "{'iter': 0, 'episode': 87, 'step': 1, 'oldState': array([0.7559243], dtype=float32), 'action': array([0.9454647], dtype=float32), 'reward': -0.4546396881341934, 'newState': array([0.40245855], dtype=float32), 'info': {'arrival': 0.4024585614319001}}\n",
      "new state: [0.76349556]\n",
      "old state: [0.40245855]\n",
      "{'iter': 0, 'episode': 87, 'step': 2, 'oldState': array([0.40245855], dtype=float32), 'action': array([0.6724556], dtype=float32), 'reward': -0.1357792317867279, 'newState': array([0.76349556], dtype=float32), 'info': {'arrival': 0.7634955915124941}}\n",
      "new state: [0.60238016]\n",
      "old state: [0.76349556]\n",
      "{'iter': 0, 'episode': 87, 'step': 3, 'oldState': array([0.76349556], dtype=float32), 'action': array([0.66420156], dtype=float32), 'reward': -0.07118955254554749, 'newState': array([0.60238016], dtype=float32), 'info': {'arrival': 0.6023801525937064}}\n",
      "new state: [0.90298265]\n",
      "old state: [0.60238016]\n",
      "{'iter': 0, 'episode': 87, 'step': 4, 'oldState': array([0.60238016], dtype=float32), 'action': array([0.14552297], dtype=float32), 'reward': -0.6823090761899948, 'newState': array([0.90298265], dtype=float32), 'info': {'arrival': 0.9029826693455333}}\n",
      "new state: [0.86977494]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 88, 'step': 0, 'oldState': array([0.]), 'action': array([0.5765599], dtype=float32), 'reward': -0.3640512526035309, 'newState': array([0.86977494], dtype=float32), 'info': {'arrival': 0.8697749634130889}}\n",
      "new state: [0.8574382]\n",
      "old state: [0.86977494]\n",
      "{'iter': 0, 'episode': 88, 'step': 1, 'oldState': array([0.86977494], dtype=float32), 'action': array([0.81896853], dtype=float32), 'reward': -0.04155385494232178, 'newState': array([0.8574382], dtype=float32), 'info': {'arrival': 0.8574382166057573}}\n",
      "new state: [0.91894966]\n",
      "old state: [0.8574382]\n",
      "{'iter': 0, 'episode': 88, 'step': 2, 'oldState': array([0.8574382], dtype=float32), 'action': array([0.84644634], dtype=float32), 'reward': -0.05712546408176422, 'newState': array([0.91894966], dtype=float32), 'info': {'arrival': 0.9189496621798107}}\n",
      "new state: [0.45628944]\n",
      "old state: [0.91894966]\n",
      "{'iter': 0, 'episode': 88, 'step': 3, 'oldState': array([0.91894966], dtype=float32), 'action': array([0.59961164], dtype=float32), 'reward': -0.18732615560293198, 'newState': array([0.45628944], dtype=float32), 'info': {'arrival': 0.456289454358934}}\n",
      "new state: [0.84609395]\n",
      "old state: [0.45628944]\n",
      "{'iter': 0, 'episode': 88, 'step': 4, 'oldState': array([0.45628944], dtype=float32), 'action': array([0.80739856], dtype=float32), 'reward': -0.11679882556200027, 'newState': array([0.84609395], dtype=float32), 'info': {'arrival': 0.8460939510385999}}\n",
      "new state: [0.6449891]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 89, 'step': 0, 'oldState': array([0.]), 'action': array([0.9933097], dtype=float32), 'reward': -0.5095678716897964, 'newState': array([0.6449891], dtype=float32), 'info': {'arrival': 0.6449891015239271}}\n",
      "new state: [0.4785376]\n",
      "old state: [0.6449891]\n",
      "{'iter': 0, 'episode': 89, 'step': 1, 'oldState': array([0.6449891], dtype=float32), 'action': array([0.53200084], dtype=float32), 'reward': -0.06834449619054794, 'newState': array([0.4785376], dtype=float32), 'info': {'arrival': 0.47853758076507286}}\n",
      "new state: [0.81164116]\n",
      "old state: [0.4785376]\n",
      "{'iter': 0, 'episode': 89, 'step': 2, 'oldState': array([0.4785376], dtype=float32), 'action': array([0.2439148], dtype=float32), 'reward': -0.48445047810673714, 'newState': array([0.81164116], dtype=float32), 'info': {'arrival': 0.8116411744599401}}\n",
      "new state: [0.7459699]\n",
      "old state: [0.81164116]\n",
      "{'iter': 0, 'episode': 89, 'step': 3, 'oldState': array([0.81164116], dtype=float32), 'action': array([0.93823993], dtype=float32), 'reward': -0.1758522242307663, 'newState': array([0.7459699], dtype=float32), 'info': {'arrival': 0.7459698793040006}}\n",
      "new state: [0.82333696]\n",
      "old state: [0.7459699]\n",
      "{'iter': 0, 'episode': 89, 'step': 4, 'oldState': array([0.7459699], dtype=float32), 'action': array([0.5893508], dtype=float32), 'reward': -0.21464437246322632, 'newState': array([0.82333696], dtype=float32), 'info': {'arrival': 0.823336936164625}}\n",
      "new state: [0.48569053]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 90, 'step': 0, 'oldState': array([0.]), 'action': array([0.81350106], dtype=float32), 'reward': -0.44923315942287445, 'newState': array([0.48569053], dtype=float32), 'info': {'arrival': 0.4856905427246251}}\n",
      "new state: [0.9030945]\n",
      "old state: [0.48569053]\n",
      "{'iter': 0, 'episode': 90, 'step': 1, 'oldState': array([0.48569053], dtype=float32), 'action': array([0.20440325], dtype=float32), 'reward': -0.5943402573466301, 'newState': array([0.9030945], dtype=float32), 'info': {'arrival': 0.9030944894769206}}\n",
      "new state: [0.8594299]\n",
      "old state: [0.9030945]\n",
      "{'iter': 0, 'episode': 90, 'step': 2, 'oldState': array([0.9030945], dtype=float32), 'action': array([0.40882102], dtype=float32), 'reward': -0.461525022983551, 'newState': array([0.8594299], dtype=float32), 'info': {'arrival': 0.85942987110349}}\n",
      "new state: [0.8906064]\n",
      "old state: [0.8594299]\n",
      "{'iter': 0, 'episode': 90, 'step': 3, 'oldState': array([0.8594299], dtype=float32), 'action': array([0.16434099], dtype=float32), 'reward': -0.7184713035821915, 'newState': array([0.8906064], dtype=float32), 'info': {'arrival': 0.8906063988829952}}\n",
      "new state: [0.91144633]\n",
      "old state: [0.8906064]\n",
      "{'iter': 0, 'episode': 90, 'step': 4, 'oldState': array([0.8906064], dtype=float32), 'action': array([0.261358], dtype=float32), 'reward': -0.6448783278465271, 'newState': array([0.91144633], dtype=float32), 'info': {'arrival': 0.911446346466435}}\n",
      "new state: [0.7652441]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 91, 'step': 0, 'oldState': array([0.]), 'action': array([0.24065173], dtype=float32), 'reward': -0.4536072313785553, 'newState': array([0.7652441], dtype=float32), 'info': {'arrival': 0.7652441526036784}}\n",
      "new state: [0.39659563]\n",
      "old state: [0.7652441]\n",
      "{'iter': 0, 'episode': 91, 'step': 1, 'oldState': array([0.7652441], dtype=float32), 'action': array([0.34728506], dtype=float32), 'reward': -0.141472689807415, 'newState': array([0.39659563], dtype=float32), 'info': {'arrival': 0.39659562477553273}}\n",
      "new state: [0.6545505]\n",
      "old state: [0.39659563]\n",
      "{'iter': 0, 'episode': 91, 'step': 2, 'oldState': array([0.39659563], dtype=float32), 'action': array([0.588227], dtype=float32), 'reward': -0.09765047580003738, 'newState': array([0.6545505], dtype=float32), 'info': {'arrival': 0.6545505085010573}}\n",
      "new state: [0.8459936]\n",
      "old state: [0.6545505]\n",
      "{'iter': 0, 'episode': 91, 'step': 3, 'oldState': array([0.6545505], dtype=float32), 'action': array([0.09441082], dtype=float32), 'reward': -0.7037219703197479, 'newState': array([0.8459936], dtype=float32), 'info': {'arrival': 0.8459935870002983}}\n",
      "new state: [0.21569307]\n",
      "old state: [0.8459936]\n",
      "{'iter': 0, 'episode': 91, 'step': 4, 'oldState': array([0.8459936], dtype=float32), 'action': array([0.999253], dtype=float32), 'reward': -0.625984787940979, 'newState': array([0.21569307], dtype=float32), 'info': {'arrival': 0.21569307423018955}}\n",
      "new state: [0.851706]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 92, 'step': 0, 'oldState': array([0.]), 'action': array([0.19266643], dtype=float32), 'reward': -0.542446319013834, 'newState': array([0.851706], dtype=float32), 'info': {'arrival': 0.8517060433957078}}\n",
      "new state: [0.9544134]\n",
      "old state: [0.851706]\n",
      "{'iter': 0, 'episode': 92, 'step': 1, 'oldState': array([0.851706], dtype=float32), 'action': array([0.28171077], dtype=float32), 'reward': -0.6470258235931396, 'newState': array([0.9544134], dtype=float32), 'info': {'arrival': 0.9544134002239988}}\n",
      "new state: [0.46968845]\n",
      "old state: [0.9544134]\n",
      "{'iter': 0, 'episode': 92, 'step': 2, 'oldState': array([0.9544134], dtype=float32), 'action': array([0.4126938], dtype=float32), 'reward': -0.1781758889555931, 'newState': array([0.46968845], dtype=float32), 'info': {'arrival': 0.46968844004035176}}\n",
      "new state: [0.45058042]\n",
      "old state: [0.46968845]\n",
      "{'iter': 0, 'episode': 92, 'step': 3, 'oldState': array([0.46968845], dtype=float32), 'action': array([0.9641762], dtype=float32), 'reward': -0.5088187530636787, 'newState': array([0.45058042], dtype=float32), 'info': {'arrival': 0.45058041208287614}}\n",
      "new state: [0.31645674]\n",
      "old state: [0.45058042]\n",
      "{'iter': 0, 'episode': 92, 'step': 4, 'oldState': array([0.45058042], dtype=float32), 'action': array([0.00541472], dtype=float32), 'reward': -0.34457293152809143, 'newState': array([0.31645674], dtype=float32), 'info': {'arrival': 0.31645674496238363}}\n",
      "new state: [0.87732106]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 93, 'step': 0, 'oldState': array([0.]), 'action': array([0.6640081], dtype=float32), 'reward': -0.32598675787448883, 'newState': array([0.87732106], dtype=float32), 'info': {'arrival': 0.8773210394292972}}\n",
      "new state: [0.9472015]\n",
      "old state: [0.87732106]\n",
      "{'iter': 0, 'episode': 93, 'step': 1, 'oldState': array([0.87732106], dtype=float32), 'action': array([0.77227175], dtype=float32), 'reward': -0.15745963156223297, 'newState': array([0.9472015], dtype=float32), 'info': {'arrival': 0.9472014977319408}}\n",
      "new state: [0.67330194]\n",
      "old state: [0.9472015]\n",
      "{'iter': 0, 'episode': 93, 'step': 2, 'oldState': array([0.9472015], dtype=float32), 'action': array([0.5903939], dtype=float32), 'reward': -0.1513829231262207, 'newState': array([0.67330194], dtype=float32), 'info': {'arrival': 0.673301921056075}}\n",
      "new state: [0.31224194]\n",
      "old state: [0.67330194]\n",
      "{'iter': 0, 'episode': 93, 'step': 3, 'oldState': array([0.67330194], dtype=float32), 'action': array([0.78978974], dtype=float32), 'reward': -0.3872827962040901, 'newState': array([0.31224194], dtype=float32), 'info': {'arrival': 0.31224193049670307}}\n",
      "new state: [0.9728608]\n",
      "old state: [0.31224194]\n",
      "{'iter': 0, 'episode': 93, 'step': 4, 'oldState': array([0.31224194], dtype=float32), 'action': array([0.41090614], dtype=float32), 'reward': -0.446132056415081, 'newState': array([0.9728608], dtype=float32), 'info': {'arrival': 0.9728608026061923}}\n",
      "new state: [0.80394113]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 94, 'step': 0, 'oldState': array([0.]), 'action': array([0.28983182], dtype=float32), 'reward': -0.45803993940353394, 'newState': array([0.80394113], dtype=float32), 'info': {'arrival': 0.8039411133611866}}\n",
      "new state: [0.80742437]\n",
      "old state: [0.80394113]\n",
      "{'iter': 0, 'episode': 94, 'step': 1, 'oldState': array([0.80394113], dtype=float32), 'action': array([0.19335856], dtype=float32), 'reward': -0.6131950169801712, 'newState': array([0.80742437], dtype=float32), 'info': {'arrival': 0.8074243777321352}}\n",
      "new state: [0.43951312]\n",
      "old state: [0.80742437]\n",
      "{'iter': 0, 'episode': 94, 'step': 2, 'oldState': array([0.80742437], dtype=float32), 'action': array([0.91845006], dtype=float32), 'reward': -0.38695912808179855, 'newState': array([0.43951312], dtype=float32), 'info': {'arrival': 0.4395131288061764}}\n",
      "new state: [0.8316875]\n",
      "old state: [0.43951312]\n",
      "{'iter': 0, 'episode': 94, 'step': 3, 'oldState': array([0.43951312], dtype=float32), 'action': array([0.6643094], dtype=float32), 'reward': -0.1817326620221138, 'newState': array([0.8316875], dtype=float32), 'info': {'arrival': 0.8316875102265381}}\n",
      "new state: [0.87864816]\n",
      "old state: [0.8316875]\n",
      "{'iter': 0, 'episode': 94, 'step': 4, 'oldState': array([0.8316875], dtype=float32), 'action': array([0.6278986], dtype=float32), 'reward': -0.23900942504405975, 'newState': array([0.87864816], dtype=float32), 'info': {'arrival': 0.8786481713097322}}\n",
      "new state: [0.6515678]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 95, 'step': 0, 'oldState': array([0.]), 'action': array([0.8040659], dtype=float32), 'reward': -0.315390020608902, 'newState': array([0.6515678], dtype=float32), 'info': {'arrival': 0.6515678182812267}}\n",
      "new state: [0.5219254]\n",
      "old state: [0.6515678]\n",
      "{'iter': 0, 'episode': 95, 'step': 1, 'oldState': array([0.6515678], dtype=float32), 'action': array([0.17966838], dtype=float32), 'reward': -0.37466762959957123, 'newState': array([0.5219254], dtype=float32), 'info': {'arrival': 0.5219253756049773}}\n",
      "new state: [0.8098784]\n",
      "old state: [0.5219254]\n",
      "{'iter': 0, 'episode': 95, 'step': 2, 'oldState': array([0.5219254], dtype=float32), 'action': array([0.24239057], dtype=float32), 'reward': -0.4954995810985565, 'newState': array([0.8098784], dtype=float32), 'info': {'arrival': 0.8098784165310127}}\n",
      "new state: [0.58864355]\n",
      "old state: [0.8098784]\n",
      "{'iter': 0, 'episode': 95, 'step': 3, 'oldState': array([0.8098784], dtype=float32), 'action': array([0.04464973], dtype=float32), 'reward': -0.5993025451898575, 'newState': array([0.58864355], dtype=float32), 'info': {'arrival': 0.5886435631202395}}\n",
      "new state: [0.87287956]\n",
      "old state: [0.58864355]\n",
      "{'iter': 0, 'episode': 95, 'step': 4, 'oldState': array([0.58864355], dtype=float32), 'action': array([0.5291852], dtype=float32), 'reward': -0.2726353853940964, 'newState': array([0.87287956], dtype=float32), 'info': {'arrival': 0.8728795700483496}}\n",
      "new state: [0.84397143]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 96, 'step': 0, 'oldState': array([0.]), 'action': array([0.5396401], dtype=float32), 'reward': -0.3631585091352463, 'newState': array([0.84397143], dtype=float32), 'info': {'arrival': 0.8439714395028521}}\n",
      "new state: [0.9141679]\n",
      "old state: [0.84397143]\n",
      "{'iter': 0, 'episode': 96, 'step': 1, 'oldState': array([0.84397143], dtype=float32), 'action': array([0.35332903], dtype=float32), 'reward': -0.5432897135615349, 'newState': array([0.9141679], dtype=float32), 'info': {'arrival': 0.9141678748549997}}\n",
      "new state: [0.61170125]\n",
      "old state: [0.9141679]\n",
      "{'iter': 0, 'episode': 96, 'step': 2, 'oldState': array([0.9141679], dtype=float32), 'action': array([0.98645854], dtype=float32), 'reward': -0.2991406321525574, 'newState': array([0.61170125], dtype=float32), 'info': {'arrival': 0.6117012294438788}}\n",
      "new state: [0.7468012]\n",
      "old state: [0.61170125]\n",
      "{'iter': 0, 'episode': 96, 'step': 3, 'oldState': array([0.61170125], dtype=float32), 'action': array([0.76437515], dtype=float32), 'reward': -0.051348939538002014, 'newState': array([0.7468012], dtype=float32), 'info': {'arrival': 0.7468012128897948}}\n",
      "new state: [0.7214539]\n",
      "old state: [0.7468012]\n",
      "{'iter': 0, 'episode': 96, 'step': 4, 'oldState': array([0.7468012], dtype=float32), 'action': array([0.7024815], dtype=float32), 'reward': -0.02530921995639801, 'newState': array([0.7214539], dtype=float32), 'info': {'arrival': 0.7214539313706213}}\n",
      "new state: [0.7125265]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 97, 'step': 0, 'oldState': array([0.]), 'action': array([0.8650219], dtype=float32), 'reward': -0.3306270092725754, 'newState': array([0.7125265], dtype=float32), 'info': {'arrival': 0.7125265156146682}}\n",
      "new state: [0.40272576]\n",
      "old state: [0.7125265]\n",
      "{'iter': 0, 'episode': 97, 'step': 1, 'oldState': array([0.7125265], dtype=float32), 'action': array([0.38813302], dtype=float32), 'reward': -0.09204292297363281, 'newState': array([0.40272576], dtype=float32), 'info': {'arrival': 0.4027257442147572}}\n",
      "new state: [0.87560403]\n",
      "old state: [0.40272576]\n",
      "{'iter': 0, 'episode': 97, 'step': 2, 'oldState': array([0.40272576], dtype=float32), 'action': array([0.90582633], dtype=float32), 'reward': -0.1484418660402298, 'newState': array([0.87560403], dtype=float32), 'info': {'arrival': 0.8756040420082821}}\n",
      "new state: [0.8389097]\n",
      "old state: [0.87560403]\n",
      "{'iter': 0, 'episode': 97, 'step': 3, 'oldState': array([0.87560403], dtype=float32), 'action': array([0.8925679], dtype=float32), 'reward': -0.04448460042476654, 'newState': array([0.8389097], dtype=float32), 'info': {'arrival': 0.8389097087512657}}\n",
      "new state: [0.75640506]\n",
      "old state: [0.8389097]\n",
      "{'iter': 0, 'episode': 97, 'step': 4, 'oldState': array([0.8389097], dtype=float32), 'action': array([0.10889867], dtype=float32), 'reward': -0.6681325137615204, 'newState': array([0.75640506], dtype=float32), 'info': {'arrival': 0.7564050722009273}}\n",
      "new state: [0.5849168]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 98, 'step': 0, 'oldState': array([0.]), 'action': array([0.90111387], dtype=float32), 'reward': -0.4624262899160385, 'newState': array([0.5849168], dtype=float32), 'info': {'arrival': 0.5849167999541622}}\n",
      "new state: [0.6557113]\n",
      "old state: [0.5849168]\n",
      "{'iter': 0, 'episode': 98, 'step': 1, 'oldState': array([0.5849168], dtype=float32), 'action': array([0.15708904], dtype=float32), 'reward': -0.4809236079454422, 'newState': array([0.6557113], dtype=float32), 'info': {'arrival': 0.6557113225997965}}\n",
      "new state: [0.5693284]\n",
      "old state: [0.6557113]\n",
      "{'iter': 0, 'episode': 98, 'step': 2, 'oldState': array([0.6557113], dtype=float32), 'action': array([0.03996503], dtype=float32), 'reward': -0.5509591102600098, 'newState': array([0.5693284], dtype=float32), 'info': {'arrival': 0.5693284443671055}}\n",
      "new state: [0.94884294]\n",
      "old state: [0.5693284]\n",
      "{'iter': 0, 'episode': 98, 'step': 3, 'oldState': array([0.5693284], dtype=float32), 'action': array([0.62563014], dtype=float32), 'reward': -0.2564850300550461, 'newState': array([0.94884294], dtype=float32), 'info': {'arrival': 0.9488429459475232}}\n",
      "new state: [0.3709941]\n",
      "old state: [0.94884294]\n",
      "{'iter': 0, 'episode': 98, 'step': 4, 'oldState': array([0.94884294], dtype=float32), 'action': array([0.46816123], dtype=float32), 'reward': -0.19304578006267548, 'newState': array([0.3709941], dtype=float32), 'info': {'arrival': 0.3709940937066646}}\n",
      "new state: [0.9424045]\n",
      "old state: [0.]\n",
      "{'iter': 0, 'episode': 99, 'step': 0, 'oldState': array([0.]), 'action': array([0.5741279], dtype=float32), 'reward': -0.41973942518234253, 'newState': array([0.9424045], dtype=float32), 'info': {'arrival': 0.942404528229974}}\n",
      "new state: [0.73469627]\n",
      "old state: [0.9424045]\n",
      "{'iter': 0, 'episode': 99, 'step': 1, 'oldState': array([0.9424045], dtype=float32), 'action': array([0.7185424], dtype=float32), 'reward': -0.06808093190193176, 'newState': array([0.73469627], dtype=float32), 'info': {'arrival': 0.7346962833449846}}\n",
      "new state: [0.5795525]\n",
      "old state: [0.73469627]\n",
      "{'iter': 0, 'episode': 99, 'step': 2, 'oldState': array([0.73469627], dtype=float32), 'action': array([0.24703464], dtype=float32), 'reward': -0.3713037818670273, 'newState': array([0.5795525], dtype=float32), 'info': {'arrival': 0.5795524831021501}}\n",
      "new state: [0.6992954]\n",
      "old state: [0.5795525]\n",
      "{'iter': 0, 'episode': 99, 'step': 3, 'oldState': array([0.5795525], dtype=float32), 'action': array([0.1883685], dtype=float32), 'reward': -0.4809911698102951, 'newState': array([0.6992954], dtype=float32), 'info': {'arrival': 0.6992954225080518}}\n",
      "new state: [0.8101275]\n",
      "old state: [0.6992954]\n",
      "{'iter': 0, 'episode': 99, 'step': 4, 'oldState': array([0.6992954], dtype=float32), 'action': array([0.4382486], dtype=float32), 'reward': -0.34417086839675903, 'newState': array([0.8101275], dtype=float32), 'info': {'arrival': 0.8101274914553863}}\n",
      "new state: [0.700912]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 0, 'step': 0, 'oldState': array([0.]), 'action': array([0.17657389], dtype=float32), 'reward': -0.4373970665037632, 'newState': array([0.700912], dtype=float32), 'info': {'arrival': 0.700911995251569}}\n",
      "new state: [0.6863297]\n",
      "old state: [0.700912]\n",
      "{'iter': 1, 'episode': 0, 'step': 1, 'oldState': array([0.700912], dtype=float32), 'action': array([0.16551895], dtype=float32), 'reward': -0.5244563519954681, 'newState': array([0.6863297], dtype=float32), 'info': {'arrival': 0.6863297440889948}}\n",
      "new state: [0.8946724]\n",
      "old state: [0.6863297]\n",
      "{'iter': 1, 'episode': 0, 'step': 2, 'oldState': array([0.6863297], dtype=float32), 'action': array([0.12274748], dtype=float32), 'reward': -0.7198392450809479, 'newState': array([0.8946724], dtype=float32), 'info': {'arrival': 0.8946723830639239}}\n",
      "new state: [0.6127531]\n",
      "old state: [0.8946724]\n",
      "{'iter': 1, 'episode': 0, 'step': 3, 'oldState': array([0.8946724], dtype=float32), 'action': array([0.68339133], dtype=float32), 'reward': -0.10579894483089447, 'newState': array([0.6127531], dtype=float32), 'info': {'arrival': 0.6127530673838564}}\n",
      "new state: [0.6777517]\n",
      "old state: [0.6127531]\n",
      "{'iter': 1, 'episode': 0, 'step': 4, 'oldState': array([0.6127531], dtype=float32), 'action': array([0.95932955], dtype=float32), 'reward': -0.29782748222351074, 'newState': array([0.6777517], dtype=float32), 'info': {'arrival': 0.6777517241802903}}\n",
      "new state: [0.657883]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 1, 'step': 0, 'oldState': array([0.]), 'action': array([0.34889764], dtype=float32), 'reward': -0.318963423371315, 'newState': array([0.657883], dtype=float32), 'info': {'arrival': 0.6578829895086237}}\n",
      "new state: [0.80336094]\n",
      "old state: [0.657883]\n",
      "{'iter': 1, 'episode': 1, 'step': 1, 'oldState': array([0.657883], dtype=float32), 'action': array([0.8136435], dtype=float32), 'reward': -0.046652063727378845, 'newState': array([0.80336094], dtype=float32), 'info': {'arrival': 0.8033609194456726}}\n",
      "new state: [0.8188644]\n",
      "old state: [0.80336094]\n",
      "{'iter': 1, 'episode': 1, 'step': 2, 'oldState': array([0.80336094], dtype=float32), 'action': array([0.8166404], dtype=float32), 'reward': -0.00498788058757782, 'newState': array([0.8188644], dtype=float32), 'info': {'arrival': 0.8188643982922508}}\n",
      "new state: [0.59845084]\n",
      "old state: [0.8188644]\n",
      "{'iter': 1, 'episode': 1, 'step': 3, 'oldState': array([0.8188644], dtype=float32), 'action': array([0.7641855], dtype=float32), 'reward': -0.1379707157611847, 'newState': array([0.59845084], dtype=float32), 'info': {'arrival': 0.5984508447796465}}\n",
      "new state: [0.75797904]\n",
      "old state: [0.59845084]\n",
      "{'iter': 1, 'episode': 1, 'step': 4, 'oldState': array([0.59845084], dtype=float32), 'action': array([0.7164739], dtype=float32), 'reward': -0.06063462793827057, 'newState': array([0.75797904], dtype=float32), 'info': {'arrival': 0.7579790394033419}}\n",
      "new state: [0.5764426]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 2, 'step': 0, 'oldState': array([0.]), 'action': array([0.35091677], dtype=float32), 'reward': -0.25687356293201447, 'newState': array([0.5764426], dtype=float32), 'info': {'arrival': 0.5764425881377363}}\n",
      "new state: [0.69755363]\n",
      "old state: [0.5764426]\n",
      "{'iter': 1, 'episode': 2, 'step': 1, 'oldState': array([0.5764426], dtype=float32), 'action': array([0.7504516], dtype=float32), 'reward': -0.08317574858665466, 'newState': array([0.69755363], dtype=float32), 'info': {'arrival': 0.6975536619466508}}\n",
      "new state: [0.9126641]\n",
      "old state: [0.69755363]\n",
      "{'iter': 1, 'episode': 2, 'step': 2, 'oldState': array([0.69755363], dtype=float32), 'action': array([0.6291111], dtype=float32), 'reward': -0.22977538406848907, 'newState': array([0.9126641], dtype=float32), 'info': {'arrival': 0.9126641372060237}}\n",
      "new state: [0.3251295]\n",
      "old state: [0.9126641]\n",
      "{'iter': 1, 'episode': 2, 'step': 3, 'oldState': array([0.9126641], dtype=float32), 'action': array([0.35684776], dtype=float32), 'reward': -0.16274277865886688, 'newState': array([0.3251295], dtype=float32), 'info': {'arrival': 0.32512952041128024}}\n",
      "new state: [0.8058028]\n",
      "old state: [0.3251295]\n",
      "{'iter': 1, 'episode': 2, 'step': 4, 'oldState': array([0.3251295], dtype=float32), 'action': array([0.6928667], dtype=float32), 'reward': -0.17663639783859253, 'newState': array([0.8058028], dtype=float32), 'info': {'arrival': 0.8058028111117601}}\n",
      "new state: [0.5278648]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 3, 'step': 0, 'oldState': array([0.]), 'action': array([0.6622894], dtype=float32), 'reward': -0.26639077067375183, 'newState': array([0.5278648], dtype=float32), 'info': {'arrival': 0.527864785362071}}\n",
      "new state: [0.86357147]\n",
      "old state: [0.5278648]\n",
      "{'iter': 1, 'episode': 3, 'step': 1, 'oldState': array([0.5278648], dtype=float32), 'action': array([0.12321708], dtype=float32), 'reward': -0.6564277037978172, 'newState': array([0.86357147], dtype=float32), 'info': {'arrival': 0.8635714885904994}}\n",
      "new state: [0.8351051]\n",
      "old state: [0.86357147]\n",
      "{'iter': 1, 'episode': 3, 'step': 2, 'oldState': array([0.86357147], dtype=float32), 'action': array([0.53040004], dtype=float32), 'reward': -0.31182166934013367, 'newState': array([0.8351051], dtype=float32), 'info': {'arrival': 0.8351051478258961}}\n",
      "new state: [0.8611902]\n",
      "old state: [0.8351051]\n",
      "{'iter': 1, 'episode': 3, 'step': 3, 'oldState': array([0.8351051], dtype=float32), 'action': array([0.1345978], dtype=float32), 'reward': -0.7200711518526077, 'newState': array([0.8611902], dtype=float32), 'info': {'arrival': 0.8611902112546311}}\n",
      "new state: [0.51659447]\n",
      "old state: [0.8611902]\n",
      "{'iter': 1, 'episode': 3, 'step': 4, 'oldState': array([0.8611902], dtype=float32), 'action': array([0.3036393], dtype=float32), 'reward': -0.29910410940647125, 'newState': array([0.51659447], dtype=float32), 'info': {'arrival': 0.5165944986244387}}\n",
      "new state: [0.6392035]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 4, 'step': 0, 'oldState': array([0.]), 'action': array([0.7952546], dtype=float32), 'reward': -0.31585197150707245, 'newState': array([0.6392035], dtype=float32), 'info': {'arrival': 0.6392035153536391}}\n",
      "new state: [0.8893452]\n",
      "old state: [0.6392035]\n",
      "{'iter': 1, 'episode': 4, 'step': 1, 'oldState': array([0.6392035], dtype=float32), 'action': array([0.36132944], dtype=float32), 'reward': -0.46548035740852356, 'newState': array([0.8893452], dtype=float32), 'info': {'arrival': 0.8893452395632827}}\n",
      "new state: [0.6142532]\n",
      "old state: [0.8893452]\n",
      "{'iter': 1, 'episode': 4, 'step': 2, 'oldState': array([0.8893452], dtype=float32), 'action': array([0.50116706], dtype=float32), 'reward': -0.18185916543006897, 'newState': array([0.6142532], dtype=float32), 'info': {'arrival': 0.6142532236178326}}\n",
      "new state: [0.64309734]\n",
      "old state: [0.6142532]\n",
      "{'iter': 1, 'episode': 4, 'step': 3, 'oldState': array([0.6142532], dtype=float32), 'action': array([0.24910818], dtype=float32), 'reward': -0.3867781162261963, 'newState': array([0.64309734], dtype=float32), 'info': {'arrival': 0.6430973208710086}}\n",
      "new state: [0.87305176]\n",
      "old state: [0.64309734]\n",
      "{'iter': 1, 'episode': 4, 'step': 4, 'oldState': array([0.64309734], dtype=float32), 'action': array([0.16590172], dtype=float32), 'reward': -0.6496614366769791, 'newState': array([0.87305176], dtype=float32), 'info': {'arrival': 0.8730517845496826}}\n",
      "new state: [0.7658436]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 5, 'step': 0, 'oldState': array([0.]), 'action': array([0.95548034], dtype=float32), 'reward': -0.3810976594686508, 'newState': array([0.7658436], dtype=float32), 'info': {'arrival': 0.765843554504613}}\n",
      "new state: [0.74171776]\n",
      "old state: [0.7658436]\n",
      "{'iter': 1, 'episode': 5, 'step': 1, 'oldState': array([0.7658436], dtype=float32), 'action': array([0.506236], dtype=float32), 'reward': -0.241513192653656, 'newState': array([0.74171776], dtype=float32), 'info': {'arrival': 0.7417177351517451}}\n",
      "new state: [0.5280162]\n",
      "old state: [0.74171776]\n",
      "{'iter': 1, 'episode': 5, 'step': 2, 'oldState': array([0.74171776], dtype=float32), 'action': array([0.96841425], dtype=float32), 'reward': -0.38697265088558197, 'newState': array([0.5280162], dtype=float32), 'info': {'arrival': 0.5280162320728524}}\n",
      "new state: [0.81869555]\n",
      "old state: [0.5280162]\n",
      "{'iter': 1, 'episode': 5, 'step': 3, 'oldState': array([0.5280162], dtype=float32), 'action': array([0.7424338], dtype=float32), 'reward': -0.11080071330070496, 'newState': array([0.81869555], dtype=float32), 'info': {'arrival': 0.8186955495273947}}\n",
      "new state: [0.6655588]\n",
      "old state: [0.81869555]\n",
      "{'iter': 1, 'episode': 5, 'step': 4, 'oldState': array([0.81869555], dtype=float32), 'action': array([0.28926346], dtype=float32), 'reward': -0.41457953304052353, 'newState': array([0.6655588], dtype=float32), 'info': {'arrival': 0.6655588033904783}}\n",
      "new state: [0.9786515]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 6, 'step': 0, 'oldState': array([0.]), 'action': array([0.64789635], dtype=float32), 'reward': -0.4100404679775238, 'newState': array([0.9786515], dtype=float32), 'info': {'arrival': 0.9786515066162405}}\n",
      "new state: [0.7547751]\n",
      "old state: [0.9786515]\n",
      "{'iter': 1, 'episode': 6, 'step': 1, 'oldState': array([0.9786515], dtype=float32), 'action': array([0.25004512], dtype=float32), 'reward': -0.5606990903615952, 'newState': array([0.7547751], dtype=float32), 'info': {'arrival': 0.7547751290408428}}\n",
      "new state: [0.6208276]\n",
      "old state: [0.7547751]\n",
      "{'iter': 1, 'episode': 6, 'step': 2, 'oldState': array([0.7547751], dtype=float32), 'action': array([0.7468926], dtype=float32), 'reward': -0.0965193510055542, 'newState': array([0.6208276], dtype=float32), 'info': {'arrival': 0.6208275984587658}}\n",
      "new state: [0.86192745]\n",
      "old state: [0.6208276]\n",
      "{'iter': 1, 'episode': 6, 'step': 3, 'oldState': array([0.6208276], dtype=float32), 'action': array([0.32593516], dtype=float32), 'reward': -0.47571731358766556, 'newState': array([0.86192745], dtype=float32), 'info': {'arrival': 0.8619274243085766}}\n",
      "new state: [0.567163]\n",
      "old state: [0.86192745]\n",
      "{'iter': 1, 'episode': 6, 'step': 4, 'oldState': array([0.86192745], dtype=float32), 'action': array([0.05940171], dtype=float32), 'reward': -0.581452414393425, 'newState': array([0.567163], dtype=float32), 'info': {'arrival': 0.5671630063580682}}\n",
      "new state: [0.95742327]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 7, 'step': 0, 'oldState': array([0.]), 'action': array([0.02671511], dtype=float32), 'reward': -0.7047099061310291, 'newState': array([0.95742327], dtype=float32), 'info': {'arrival': 0.9574232660263835}}\n",
      "new state: [0.6546405]\n",
      "old state: [0.95742327]\n",
      "{'iter': 1, 'episode': 7, 'step': 1, 'oldState': array([0.95742327], dtype=float32), 'action': array([0.9156518], dtype=float32), 'reward': -0.20620134472846985, 'newState': array([0.6546405], dtype=float32), 'info': {'arrival': 0.6546404964610284}}\n",
      "new state: [0.7895241]\n",
      "old state: [0.6546405]\n",
      "{'iter': 1, 'episode': 7, 'step': 2, 'oldState': array([0.6546405], dtype=float32), 'action': array([0.9332874], dtype=float32), 'reward': -0.1774841994047165, 'newState': array([0.7895241], dtype=float32), 'info': {'arrival': 0.789524069173483}}\n",
      "new state: [0.31970027]\n",
      "old state: [0.7895241]\n",
      "{'iter': 1, 'episode': 7, 'step': 3, 'oldState': array([0.7895241], dtype=float32), 'action': array([0.6695889], dtype=float32), 'reward': -0.2924002781510353, 'newState': array([0.31970027], dtype=float32), 'info': {'arrival': 0.31970027339357476}}\n",
      "new state: [0.83846897]\n",
      "old state: [0.31970027]\n",
      "{'iter': 1, 'episode': 7, 'step': 4, 'oldState': array([0.31970027], dtype=float32), 'action': array([0.15459122], dtype=float32), 'reward': -0.5541855879127979, 'newState': array([0.83846897], dtype=float32), 'info': {'arrival': 0.8384689978290658}}\n",
      "new state: [0.6179497]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 8, 'step': 0, 'oldState': array([0.]), 'action': array([0.5257514], dtype=float32), 'reward': -0.20058658719062805, 'newState': array([0.6179497], dtype=float32), 'info': {'arrival': 0.6179497204205567}}\n",
      "new state: [0.93563956]\n",
      "old state: [0.6179497]\n",
      "{'iter': 1, 'episode': 8, 'step': 1, 'oldState': array([0.6179497], dtype=float32), 'action': array([0.1632452], dtype=float32), 'reward': -0.6929719001054764, 'newState': array([0.93563956], dtype=float32), 'info': {'arrival': 0.9356395607198589}}\n",
      "new state: [0.7908757]\n",
      "old state: [0.93563956]\n",
      "{'iter': 1, 'episode': 8, 'step': 2, 'oldState': array([0.93563956], dtype=float32), 'action': array([0.7023455], dtype=float32), 'reward': -0.12472115457057953, 'newState': array([0.7908757], dtype=float32), 'info': {'arrival': 0.7908756957611772}}\n",
      "new state: [0.8588787]\n",
      "old state: [0.7908757]\n",
      "{'iter': 1, 'episode': 8, 'step': 3, 'oldState': array([0.7908757], dtype=float32), 'action': array([0.9653809], dtype=float32), 'reward': -0.12350298464298248, 'newState': array([0.8588787], dtype=float32), 'info': {'arrival': 0.8588786467425578}}\n",
      "new state: [0.65745467]\n",
      "old state: [0.8588787]\n",
      "{'iter': 1, 'episode': 8, 'step': 4, 'oldState': array([0.8588787], dtype=float32), 'action': array([0.89455354], dtype=float32), 'reward': -0.1867428719997406, 'newState': array([0.65745467], dtype=float32), 'info': {'arrival': 0.657454652869883}}\n",
      "new state: [0.77804345]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 9, 'step': 0, 'oldState': array([0.]), 'action': array([0.03746794], dtype=float32), 'reward': -0.5647986046969891, 'newState': array([0.77804345], dtype=float32), 'info': {'arrival': 0.7780434590582694}}\n",
      "new state: [0.9666249]\n",
      "old state: [0.77804345]\n",
      "{'iter': 1, 'episode': 9, 'step': 1, 'oldState': array([0.77804345], dtype=float32), 'action': array([0.6833704], dtype=float32), 'reward': -0.23610913753509521, 'newState': array([0.9666249], dtype=float32), 'info': {'arrival': 0.9666249356383833}}\n",
      "new state: [0.71778077]\n",
      "old state: [0.9666249]\n",
      "{'iter': 1, 'episode': 9, 'step': 2, 'oldState': array([0.9666249], dtype=float32), 'action': array([0.59675497], dtype=float32), 'reward': -0.18323683738708496, 'newState': array([0.71778077], dtype=float32), 'info': {'arrival': 0.7177807604137943}}\n",
      "new state: [0.48551488]\n",
      "old state: [0.71778077]\n",
      "{'iter': 1, 'episode': 9, 'step': 3, 'oldState': array([0.71778077], dtype=float32), 'action': array([0.55365723], dtype=float32), 'reward': -0.0921376496553421, 'newState': array([0.48551488], dtype=float32), 'info': {'arrival': 0.4855148669459091}}\n",
      "new state: [0.6993805]\n",
      "old state: [0.48551488]\n",
      "{'iter': 1, 'episode': 9, 'step': 4, 'oldState': array([0.48551488], dtype=float32), 'action': array([0.5635104], dtype=float32), 'reward': -0.12140145897865295, 'newState': array([0.6993805], dtype=float32), 'info': {'arrival': 0.6993805298925497}}\n",
      "new state: [0.48286855]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 10, 'step': 0, 'oldState': array([0.]), 'action': array([0.16458324], dtype=float32), 'reward': -0.27985979616642, 'newState': array([0.48286855], dtype=float32), 'info': {'arrival': 0.4828685443664288}}\n",
      "new state: [0.57356286]\n",
      "old state: [0.48286855]\n",
      "{'iter': 1, 'episode': 10, 'step': 1, 'oldState': array([0.48286855], dtype=float32), 'action': array([0.21362504], dtype=float32), 'reward': -0.3372642397880554, 'newState': array([0.57356286], dtype=float32), 'info': {'arrival': 0.5735628411976696}}\n",
      "new state: [0.6772171]\n",
      "old state: [0.57356286]\n",
      "{'iter': 1, 'episode': 10, 'step': 2, 'oldState': array([0.57356286], dtype=float32), 'action': array([0.15919164], dtype=float32), 'reward': -0.4921119436621666, 'newState': array([0.6772171], dtype=float32), 'info': {'arrival': 0.6772171296268304}}\n",
      "new state: [0.5056927]\n",
      "old state: [0.6772171]\n",
      "{'iter': 1, 'episode': 10, 'step': 3, 'oldState': array([0.6772171], dtype=float32), 'action': array([0.6256728], dtype=float32), 'reward': -0.10287114977836609, 'newState': array([0.5056927], dtype=float32), 'info': {'arrival': 0.5056927348317894}}\n",
      "new state: [0.8364652]\n",
      "old state: [0.5056927]\n",
      "{'iter': 1, 'episode': 10, 'step': 4, 'oldState': array([0.5056927], dtype=float32), 'action': array([0.18395215], dtype=float32), 'reward': -0.569819912314415, 'newState': array([0.8364652], dtype=float32), 'info': {'arrival': 0.8364651941791661}}\n",
      "new state: [0.78054583]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 11, 'step': 0, 'oldState': array([0.]), 'action': array([0.70761055], dtype=float32), 'reward': -0.23160409927368164, 'newState': array([0.78054583], dtype=float32), 'info': {'arrival': 0.780545847582004}}\n",
      "new state: [0.8680714]\n",
      "old state: [0.78054583]\n",
      "{'iter': 1, 'episode': 11, 'step': 1, 'oldState': array([0.78054583], dtype=float32), 'action': array([0.5472333], dtype=float32), 'reward': -0.2989567071199417, 'newState': array([0.8680714], dtype=float32), 'info': {'arrival': 0.8680714069189748}}\n",
      "new state: [0.8416897]\n",
      "old state: [0.8680714]\n",
      "{'iter': 1, 'episode': 11, 'step': 2, 'oldState': array([0.8680714], dtype=float32), 'action': array([0.07565893], dtype=float32), 'reward': -0.772626206278801, 'newState': array([0.8416897], dtype=float32), 'info': {'arrival': 0.8416897024077541}}\n",
      "new state: [0.48384368]\n",
      "old state: [0.8416897]\n",
      "{'iter': 1, 'episode': 11, 'step': 3, 'oldState': array([0.8416897], dtype=float32), 'action': array([0.56758386], dtype=float32), 'reward': -0.13133159279823303, 'newState': array([0.48384368], dtype=float32), 'info': {'arrival': 0.4838436767841012}}\n",
      "new state: [0.55491716]\n",
      "old state: [0.48384368]\n",
      "{'iter': 1, 'episode': 11, 'step': 4, 'oldState': array([0.48384368], dtype=float32), 'action': array([0.26587385], dtype=float32), 'reward': -0.27127493917942047, 'newState': array([0.55491716], dtype=float32), 'info': {'arrival': 0.5549171458725067}}\n",
      "new state: [0.7253113]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 12, 'step': 0, 'oldState': array([0.]), 'action': array([0.42278895], dtype=float32), 'reward': -0.3325889855623245, 'newState': array([0.7253113], dtype=float32), 'info': {'arrival': 0.7253112984636849}}\n",
      "new state: [0.73115087]\n",
      "old state: [0.7253113]\n",
      "{'iter': 1, 'episode': 12, 'step': 1, 'oldState': array([0.7253113], dtype=float32), 'action': array([0.13316435], dtype=float32), 'reward': -0.5965266227722168, 'newState': array([0.73115087], dtype=float32), 'info': {'arrival': 0.7311508459232111}}\n",
      "new state: [0.6295536]\n",
      "old state: [0.73115087]\n",
      "{'iter': 1, 'episode': 12, 'step': 2, 'oldState': array([0.73115087], dtype=float32), 'action': array([0.6949066], dtype=float32), 'reward': -0.05807580053806305, 'newState': array([0.6295536], dtype=float32), 'info': {'arrival': 0.6295535944717731}}\n",
      "new state: [0.6888298]\n",
      "old state: [0.6295536]\n",
      "{'iter': 1, 'episode': 12, 'step': 3, 'oldState': array([0.6295536], dtype=float32), 'action': array([0.7167151], dtype=float32), 'reward': -0.04270435869693756, 'newState': array([0.6888298], dtype=float32), 'info': {'arrival': 0.6888297911044501}}\n",
      "new state: [0.5864409]\n",
      "old state: [0.6888298]\n",
      "{'iter': 1, 'episode': 12, 'step': 4, 'oldState': array([0.6888298], dtype=float32), 'action': array([0.22255349], dtype=float32), 'reward': -0.3894846439361572, 'newState': array([0.5864409], dtype=float32), 'info': {'arrival': 0.58644093409291}}\n",
      "new state: [0.7414545]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 13, 'step': 0, 'oldState': array([0.]), 'action': array([0.6034897], dtype=float32), 'reward': -0.25434601306915283, 'newState': array([0.7414545], dtype=float32), 'info': {'arrival': 0.7414544565639177}}\n",
      "new state: [0.5488512]\n",
      "old state: [0.7414545]\n",
      "{'iter': 1, 'episode': 13, 'step': 1, 'oldState': array([0.7414545], dtype=float32), 'action': array([0.9494883], dtype=float32), 'reward': -0.3524862676858902, 'newState': array([0.5488512], dtype=float32), 'info': {'arrival': 0.5488511683802834}}\n",
      "new state: [0.41724974]\n",
      "old state: [0.5488512]\n",
      "{'iter': 1, 'episode': 13, 'step': 2, 'oldState': array([0.5488512], dtype=float32), 'action': array([0.94749033], dtype=float32), 'reward': -0.49734023213386536, 'newState': array([0.41724974], dtype=float32), 'info': {'arrival': 0.4172497368498294}}\n",
      "new state: [0.9541619]\n",
      "old state: [0.41724974]\n",
      "{'iter': 1, 'episode': 13, 'step': 3, 'oldState': array([0.41724974], dtype=float32), 'action': array([0.32188755], dtype=float32), 'reward': -0.49804629385471344, 'newState': array([0.9541619], dtype=float32), 'info': {'arrival': 0.954161860279744}}\n",
      "new state: [0.63646245]\n",
      "old state: [0.9541619]\n",
      "{'iter': 1, 'episode': 13, 'step': 4, 'oldState': array([0.9541619], dtype=float32), 'action': array([0.9835925], dtype=float32), 'reward': -0.26770520210266113, 'newState': array([0.63646245], dtype=float32), 'info': {'arrival': 0.6364624450296702}}\n",
      "new state: [0.7218067]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 14, 'step': 0, 'oldState': array([0.]), 'action': array([0.3008872], dtype=float32), 'reward': -0.39091143012046814, 'newState': array([0.7218067], dtype=float32), 'info': {'arrival': 0.7218067161739529}}\n",
      "new state: [0.8765889]\n",
      "old state: [0.7218067]\n",
      "{'iter': 1, 'episode': 14, 'step': 1, 'oldState': array([0.7218067], dtype=float32), 'action': array([0.43828732], dtype=float32), 'reward': -0.39960601925849915, 'newState': array([0.8765889], dtype=float32), 'info': {'arrival': 0.8765888647555418}}\n",
      "new state: [0.413619]\n",
      "old state: [0.8765889]\n",
      "{'iter': 1, 'episode': 14, 'step': 2, 'oldState': array([0.8765889], dtype=float32), 'action': array([0.5110425], dtype=float32), 'reward': -0.16445419937372208, 'newState': array([0.413619], dtype=float32), 'info': {'arrival': 0.4136190149520402}}\n",
      "new state: [0.904933]\n",
      "old state: [0.413619]\n",
      "{'iter': 1, 'episode': 14, 'step': 3, 'oldState': array([0.413619], dtype=float32), 'action': array([0.03743232], dtype=float32), 'reward': -0.7446721717715263, 'newState': array([0.904933], dtype=float32), 'info': {'arrival': 0.9049330006694467}}\n",
      "new state: [0.590688]\n",
      "old state: [0.904933]\n",
      "{'iter': 1, 'episode': 14, 'step': 4, 'oldState': array([0.904933], dtype=float32), 'action': array([0.5504192], dtype=float32), 'reward': -0.11883002519607544, 'newState': array([0.590688], dtype=float32), 'info': {'arrival': 0.5906879618185401}}\n",
      "new state: [0.9339709]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 15, 'step': 0, 'oldState': array([0.]), 'action': array([0.5719284], dtype=float32), 'reward': -0.4145140051841736, 'newState': array([0.9339709], dtype=float32), 'info': {'arrival': 0.9339709424497843}}\n",
      "new state: [0.5877721]\n",
      "old state: [0.9339709]\n",
      "{'iter': 1, 'episode': 15, 'step': 1, 'oldState': array([0.9339709], dtype=float32), 'action': array([0.26342174], dtype=float32), 'reward': -0.4109000340104103, 'newState': array([0.5877721], dtype=float32), 'info': {'arrival': 0.587772088211261}}\n",
      "new state: [0.5244119]\n",
      "old state: [0.5877721]\n",
      "{'iter': 1, 'episode': 15, 'step': 2, 'oldState': array([0.5877721], dtype=float32), 'action': array([0.563378], dtype=float32), 'reward': -0.035323068499565125, 'newState': array([0.5244119], dtype=float32), 'info': {'arrival': 0.524411890403071}}\n",
      "new state: [0.850773]\n",
      "old state: [0.5244119]\n",
      "{'iter': 1, 'episode': 15, 'step': 3, 'oldState': array([0.5244119], dtype=float32), 'action': array([0.17358029], dtype=float32), 'reward': -0.595602422952652, 'newState': array([0.850773], dtype=float32), 'info': {'arrival': 0.8507729939518375}}\n",
      "new state: [0.7516848]\n",
      "old state: [0.850773]\n",
      "{'iter': 1, 'episode': 15, 'step': 4, 'oldState': array([0.850773], dtype=float32), 'action': array([0.4097655], dtype=float32), 'reward': -0.36669132113456726, 'newState': array([0.7516848], dtype=float32), 'info': {'arrival': 0.7516848104668666}}\n",
      "new state: [0.8885054]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 16, 'step': 0, 'oldState': array([0.]), 'action': array([0.46460375], dtype=float32), 'reward': -0.4340771734714508, 'newState': array([0.8885054], dtype=float32), 'info': {'arrival': 0.8885054175630361}}\n",
      "new state: [0.4213826]\n",
      "old state: [0.8885054]\n",
      "{'iter': 1, 'episode': 16, 'step': 1, 'oldState': array([0.8885054], dtype=float32), 'action': array([0.25711846], dtype=float32), 'reward': -0.2810448408126831, 'newState': array([0.4213826], dtype=float32), 'info': {'arrival': 0.4213825934540013}}\n",
      "new state: [0.84259206]\n",
      "old state: [0.4213826]\n",
      "{'iter': 1, 'episode': 16, 'step': 2, 'oldState': array([0.4213826], dtype=float32), 'action': array([0.6054063], dtype=float32), 'reward': -0.22389525175094604, 'newState': array([0.84259206], dtype=float32), 'info': {'arrival': 0.8425920351855082}}\n",
      "new state: [0.80393034]\n",
      "old state: [0.84259206]\n",
      "{'iter': 1, 'episode': 16, 'step': 3, 'oldState': array([0.84259206], dtype=float32), 'action': array([0.9621576], dtype=float32), 'reward': -0.14856183528900146, 'newState': array([0.80393034], dtype=float32), 'info': {'arrival': 0.803930347128035}}\n",
      "new state: [0.7189548]\n",
      "old state: [0.80393034]\n",
      "{'iter': 1, 'episode': 16, 'step': 4, 'oldState': array([0.80393034], dtype=float32), 'action': array([0.9644349], dtype=float32), 'reward': -0.22423623502254486, 'newState': array([0.7189548], dtype=float32), 'info': {'arrival': 0.7189547903125264}}\n",
      "new state: [0.6669926]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 17, 'step': 0, 'oldState': array([0.]), 'action': array([0.4141379], dtype=float32), 'reward': -0.29317550361156464, 'newState': array([0.6669926], dtype=float32), 'info': {'arrival': 0.6669925890891685}}\n",
      "new state: [0.7868426]\n",
      "old state: [0.6669926]\n",
      "{'iter': 1, 'episode': 17, 'step': 1, 'oldState': array([0.6669926], dtype=float32), 'action': array([0.8745354], dtype=float32), 'reward': -0.11765529215335846, 'newState': array([0.7868426], dtype=float32), 'info': {'arrival': 0.7868426030960529}}\n",
      "new state: [0.77668]\n",
      "old state: [0.7868426]\n",
      "{'iter': 1, 'episode': 17, 'step': 2, 'oldState': array([0.7868426], dtype=float32), 'action': array([0.36656538], dtype=float32), 'reward': -0.4126552641391754, 'newState': array([0.77668], dtype=float32), 'info': {'arrival': 0.7766799672914535}}\n",
      "new state: [0.49302247]\n",
      "old state: [0.77668]\n",
      "{'iter': 1, 'episode': 17, 'step': 3, 'oldState': array([0.77668], dtype=float32), 'action': array([0.9661342], dtype=float32), 'reward': -0.40219733864068985, 'newState': array([0.49302247], dtype=float32), 'info': {'arrival': 0.493022461964648}}\n",
      "new state: [0.92332834]\n",
      "old state: [0.49302247]\n",
      "{'iter': 1, 'episode': 17, 'step': 4, 'oldState': array([0.49302247], dtype=float32), 'action': array([0.4984957], dtype=float32), 'reward': -0.3199927881360054, 'newState': array([0.92332834], dtype=float32), 'info': {'arrival': 0.9233283328522064}}\n",
      "new state: [0.6680735]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 18, 'step': 0, 'oldState': array([0.]), 'action': array([0.48866463], dtype=float32), 'reward': -0.2567227929830551, 'newState': array([0.6680735], dtype=float32), 'info': {'arrival': 0.66807346977391}}\n",
      "new state: [0.6130009]\n",
      "old state: [0.6680735]\n",
      "{'iter': 1, 'episode': 18, 'step': 1, 'oldState': array([0.6680735], dtype=float32), 'action': array([0.47661197], dtype=float32), 'reward': -0.15015709400177002, 'newState': array([0.6130009], dtype=float32), 'info': {'arrival': 0.6130009510290387}}\n",
      "new state: [0.9011333]\n",
      "old state: [0.6130009]\n",
      "{'iter': 1, 'episode': 18, 'step': 2, 'oldState': array([0.6130009], dtype=float32), 'action': array([0.00580459], dtype=float32), 'reward': -0.8232956081628799, 'newState': array([0.9011333], dtype=float32), 'info': {'arrival': 0.9011332837078896}}\n",
      "new state: [0.58480763]\n",
      "old state: [0.9011333]\n",
      "{'iter': 1, 'episode': 18, 'step': 3, 'oldState': array([0.9011333], dtype=float32), 'action': array([0.71407306], dtype=float32), 'reward': -0.14371412992477417, 'newState': array([0.58480763], dtype=float32), 'info': {'arrival': 0.5848076464028457}}\n",
      "new state: [0.691873]\n",
      "old state: [0.58480763]\n",
      "{'iter': 1, 'episode': 18, 'step': 4, 'oldState': array([0.58480763], dtype=float32), 'action': array([0.25268707], dtype=float32), 'reward': -0.4124196022748947, 'newState': array([0.691873], dtype=float32), 'info': {'arrival': 0.6918729915393561}}\n",
      "new state: [0.74347126]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 19, 'step': 0, 'oldState': array([0.]), 'action': array([0.05243704], dtype=float32), 'reward': -0.5313849095255136, 'newState': array([0.74347126], dtype=float32), 'info': {'arrival': 0.74347124220399}}\n",
      "new state: [0.9023449]\n",
      "old state: [0.74347126]\n",
      "{'iter': 1, 'episode': 19, 'step': 1, 'oldState': array([0.74347126], dtype=float32), 'action': array([0.80763954], dtype=float32), 'reward': -0.08707107603549957, 'newState': array([0.9023449], dtype=float32), 'info': {'arrival': 0.9023449120508564}}\n",
      "new state: [0.891208]\n",
      "old state: [0.9023449]\n",
      "{'iter': 1, 'episode': 19, 'step': 2, 'oldState': array([0.9023449], dtype=float32), 'action': array([0.11829284], dtype=float32), 'reward': -0.7756993472576141, 'newState': array([0.891208], dtype=float32), 'info': {'arrival': 0.8912079788019918}}\n",
      "new state: [0.50600886]\n",
      "old state: [0.891208]\n",
      "{'iter': 1, 'episode': 19, 'step': 3, 'oldState': array([0.891208], dtype=float32), 'action': array([0.64273506], dtype=float32), 'reward': -0.16466288268566132, 'newState': array([0.50600886], dtype=float32), 'info': {'arrival': 0.5060088771678076}}\n",
      "new state: [0.72149837]\n",
      "old state: [0.50600886]\n",
      "{'iter': 1, 'episode': 19, 'step': 4, 'oldState': array([0.50600886], dtype=float32), 'action': array([0.4361562], dtype=float32), 'reward': -0.2314697802066803, 'newState': array([0.72149837], dtype=float32), 'info': {'arrival': 0.721498377375344}}\n",
      "new state: [0.7831831]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 20, 'step': 0, 'oldState': array([0.]), 'action': array([0.00526438], dtype=float32), 'reward': -0.5847551180049777, 'newState': array([0.7831831], dtype=float32), 'info': {'arrival': 0.7831830796856173}}\n",
      "new state: [0.7238166]\n",
      "old state: [0.7831831]\n",
      "{'iter': 1, 'episode': 20, 'step': 1, 'oldState': array([0.7831831], dtype=float32), 'action': array([0.07626608], dtype=float32), 'reward': -0.6623921096324921, 'newState': array([0.7238166], dtype=float32), 'info': {'arrival': 0.7238165568479706}}\n",
      "new state: [0.9041121]\n",
      "old state: [0.7238166]\n",
      "{'iter': 1, 'episode': 20, 'step': 2, 'oldState': array([0.7238166], dtype=float32), 'action': array([0.7004114], dtype=float32), 'reward': -0.15862683951854706, 'newState': array([0.9041121], dtype=float32), 'info': {'arrival': 0.9041120738344027}}\n",
      "new state: [0.7853668]\n",
      "old state: [0.9041121]\n",
      "{'iter': 1, 'episode': 20, 'step': 3, 'oldState': array([0.9041121], dtype=float32), 'action': array([0.07548935], dtype=float32), 'reward': -0.7395637631416321, 'newState': array([0.7853668], dtype=float32), 'info': {'arrival': 0.7853667665132471}}\n",
      "new state: [0.88624567]\n",
      "old state: [0.7853668]\n",
      "{'iter': 1, 'episode': 20, 'step': 4, 'oldState': array([0.7853668], dtype=float32), 'action': array([0.49432033], dtype=float32), 'reward': -0.36670561134815216, 'newState': array([0.88624567], dtype=float32), 'info': {'arrival': 0.8862456781738209}}\n",
      "new state: [0.683884]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 21, 'step': 0, 'oldState': array([0.]), 'action': array([0.40214872], dtype=float32), 'reward': -0.31183865666389465, 'newState': array([0.683884], dtype=float32), 'info': {'arrival': 0.6838840333217016}}\n",
      "new state: [0.8579307]\n",
      "old state: [0.683884]\n",
      "{'iter': 1, 'episode': 21, 'step': 1, 'oldState': array([0.683884], dtype=float32), 'action': array([0.89831364], dtype=float32), 'reward': -0.08389459550380707, 'newState': array([0.8579307], dtype=float32), 'info': {'arrival': 0.857930716845268}}\n",
      "new state: [0.8489715]\n",
      "old state: [0.8579307]\n",
      "{'iter': 1, 'episode': 21, 'step': 2, 'oldState': array([0.8579307], dtype=float32), 'action': array([0.23538674], dtype=float32), 'reward': -0.6158245652914047, 'newState': array([0.8489715], dtype=float32), 'info': {'arrival': 0.848971468206575}}\n",
      "new state: [0.9285393]\n",
      "old state: [0.8489715]\n",
      "{'iter': 1, 'episode': 21, 'step': 3, 'oldState': array([0.8489715], dtype=float32), 'action': array([0.15241994], dtype=float32), 'reward': -0.7562274038791656, 'newState': array([0.9285393], dtype=float32), 'info': {'arrival': 0.9285392953880727}}\n",
      "new state: [0.40006918]\n",
      "old state: [0.9285393]\n",
      "{'iter': 1, 'episode': 21, 'step': 4, 'oldState': array([0.9285393], dtype=float32), 'action': array([0.40314415], dtype=float32), 'reward': -0.13365501910448074, 'newState': array([0.40006918], dtype=float32), 'info': {'arrival': 0.4000691825211393}}\n",
      "new state: [0.8716149]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 22, 'step': 0, 'oldState': array([0.]), 'action': array([0.06087608], dtype=float32), 'reward': -0.6232731202617288, 'newState': array([0.8716149], dtype=float32), 'info': {'arrival': 0.8716148865689561}}\n",
      "new state: [0.7915378]\n",
      "old state: [0.8716149]\n",
      "{'iter': 1, 'episode': 22, 'step': 1, 'oldState': array([0.8716149], dtype=float32), 'action': array([0.11334548], dtype=float32), 'reward': -0.6982115805149078, 'newState': array([0.7915378], dtype=float32), 'info': {'arrival': 0.7915378039555784}}\n",
      "new state: [0.62045443]\n",
      "old state: [0.7915378]\n",
      "{'iter': 1, 'episode': 22, 'step': 2, 'oldState': array([0.7915378], dtype=float32), 'action': array([0.63618606], dtype=float32), 'reward': -0.050636664032936096, 'newState': array([0.62045443], dtype=float32), 'info': {'arrival': 0.6204544062800459}}\n",
      "new state: [0.46581945]\n",
      "old state: [0.62045443]\n",
      "{'iter': 1, 'episode': 22, 'step': 3, 'oldState': array([0.62045443], dtype=float32), 'action': array([0.46224436], dtype=float32), 'reward': -0.04223383218050003, 'newState': array([0.46581945], dtype=float32), 'info': {'arrival': 0.46581943494756256}}\n",
      "new state: [0.9049793]\n",
      "old state: [0.46581945]\n",
      "{'iter': 1, 'episode': 22, 'step': 4, 'oldState': array([0.46581945], dtype=float32), 'action': array([0.5434246], dtype=float32), 'reward': -0.2905673012137413, 'newState': array([0.9049793], dtype=float32), 'info': {'arrival': 0.904979304905348}}\n",
      "new state: [0.70881873]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 23, 'step': 0, 'oldState': array([0.]), 'action': array([0.39850503], dtype=float32), 'reward': -0.33236153423786163, 'newState': array([0.70881873], dtype=float32), 'info': {'arrival': 0.7088187270602972}}\n",
      "new state: [0.7568017]\n",
      "old state: [0.70881873]\n",
      "{'iter': 1, 'episode': 23, 'step': 1, 'oldState': array([0.70881873], dtype=float32), 'action': array([0.8519151], dtype=float32), 'reward': -0.10710914433002472, 'newState': array([0.7568017], dtype=float32), 'info': {'arrival': 0.7568017238412028}}\n",
      "new state: [0.69450104]\n",
      "old state: [0.7568017]\n",
      "{'iter': 1, 'episode': 23, 'step': 2, 'oldState': array([0.7568017], dtype=float32), 'action': array([0.26531667], dtype=float32), 'reward': -0.4447595477104187, 'newState': array([0.69450104], dtype=float32), 'info': {'arrival': 0.6945010289170737}}\n",
      "new state: [0.7087337]\n",
      "old state: [0.69450104]\n",
      "{'iter': 1, 'episode': 23, 'step': 3, 'oldState': array([0.69450104], dtype=float32), 'action': array([0.12964258], dtype=float32), 'reward': -0.5755329132080078, 'newState': array([0.7087337], dtype=float32), 'info': {'arrival': 0.7087336524772532}}\n",
      "new state: [0.829447]\n",
      "old state: [0.7087337]\n",
      "{'iter': 1, 'episode': 23, 'step': 4, 'oldState': array([0.7087337], dtype=float32), 'action': array([0.08674933], dtype=float32), 'reward': -0.7125193327665329, 'newState': array([0.829447], dtype=float32), 'info': {'arrival': 0.8294469676547116}}\n",
      "new state: [0.47348407]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 24, 'step': 0, 'oldState': array([0.]), 'action': array([0.47091624], dtype=float32), 'reward': -0.11965493112802505, 'newState': array([0.47348407], dtype=float32), 'info': {'arrival': 0.47348405960558293}}\n",
      "new state: [0.87713444]\n",
      "old state: [0.47348407]\n",
      "{'iter': 1, 'episode': 24, 'step': 1, 'oldState': array([0.47348407], dtype=float32), 'action': array([0.30267647], dtype=float32), 'reward': -0.4735454022884369, 'newState': array([0.87713444], dtype=float32), 'info': {'arrival': 0.8771344506116047}}\n",
      "new state: [0.8398137]\n",
      "old state: [0.87713444]\n",
      "{'iter': 1, 'episode': 24, 'step': 2, 'oldState': array([0.87713444], dtype=float32), 'action': array([0.35807055], dtype=float32), 'reward': -0.491073340177536, 'newState': array([0.8398137], dtype=float32), 'info': {'arrival': 0.8398136926977756}}\n",
      "new state: [0.669645]\n",
      "old state: [0.8398137]\n",
      "{'iter': 1, 'episode': 24, 'step': 3, 'oldState': array([0.8398137], dtype=float32), 'action': array([0.15686476], dtype=float32), 'reward': -0.5553224235773087, 'newState': array([0.669645], dtype=float32), 'info': {'arrival': 0.6696450288796454}}\n",
      "new state: [0.27308863]\n",
      "old state: [0.669645]\n",
      "{'iter': 1, 'episode': 24, 'step': 4, 'oldState': array([0.669645], dtype=float32), 'action': array([0.53910667], dtype=float32), 'reward': -0.23214811086654663, 'newState': array([0.27308863], dtype=float32), 'info': {'arrival': 0.2730886307686134}}\n",
      "new state: [0.6519653]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 25, 'step': 0, 'oldState': array([0.]), 'action': array([0.5350467], dtype=float32), 'reward': -0.22145064175128937, 'newState': array([0.6519653], dtype=float32), 'info': {'arrival': 0.651965315180267}}\n",
      "new state: [0.88546383]\n",
      "old state: [0.6519653]\n",
      "{'iter': 1, 'episode': 25, 'step': 1, 'oldState': array([0.6519653], dtype=float32), 'action': array([0.6605663], dtype=float32), 'reward': -0.17082341015338898, 'newState': array([0.88546383], dtype=float32), 'info': {'arrival': 0.8854638287511809}}\n",
      "new state: [0.730939]\n",
      "old state: [0.88546383]\n",
      "{'iter': 1, 'episode': 25, 'step': 2, 'oldState': array([0.88546383], dtype=float32), 'action': array([0.6682864], dtype=float32), 'reward': -0.10128380358219147, 'newState': array([0.730939], dtype=float32), 'info': {'arrival': 0.7309389827626667}}\n",
      "new state: [0.8298844]\n",
      "old state: [0.730939]\n",
      "{'iter': 1, 'episode': 25, 'step': 3, 'oldState': array([0.730939], dtype=float32), 'action': array([0.58985835], dtype=float32), 'reward': -0.21528969705104828, 'newState': array([0.8298844], dtype=float32), 'info': {'arrival': 0.8298844290170683}}\n",
      "new state: [0.8009457]\n",
      "old state: [0.8298844]\n",
      "{'iter': 1, 'episode': 25, 'step': 4, 'oldState': array([0.8298844], dtype=float32), 'action': array([0.49760863], dtype=float32), 'reward': -0.31057174503803253, 'newState': array([0.8009457], dtype=float32), 'info': {'arrival': 0.8009456940915285}}\n",
      "new state: [0.74433583]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 26, 'step': 0, 'oldState': array([0.]), 'action': array([0.04112234], dtype=float32), 'reward': -0.5376907186582685, 'newState': array([0.74433583], dtype=float32), 'info': {'arrival': 0.7443358369844476}}\n",
      "new state: [0.80014324]\n",
      "old state: [0.74433583]\n",
      "{'iter': 1, 'episode': 26, 'step': 1, 'oldState': array([0.74433583], dtype=float32), 'action': array([0.12057135], dtype=float32), 'reward': -0.6656200140714645, 'newState': array([0.80014324], dtype=float32), 'info': {'arrival': 0.8001432272570745}}\n",
      "new state: [0.9091463]\n",
      "old state: [0.80014324]\n",
      "{'iter': 1, 'episode': 26, 'step': 2, 'oldState': array([0.80014324], dtype=float32), 'action': array([0.13207544], dtype=float32), 'reward': -0.7498201131820679, 'newState': array([0.9091463], dtype=float32), 'info': {'arrival': 0.9091463291927372}}\n",
      "new state: [0.8240511]\n",
      "old state: [0.9091463]\n",
      "{'iter': 1, 'episode': 26, 'step': 3, 'oldState': array([0.9091463], dtype=float32), 'action': array([0.67959887], dtype=float32), 'reward': -0.16572602093219757, 'newState': array([0.8240511], dtype=float32), 'info': {'arrival': 0.8240510950386757}}\n",
      "new state: [0.91600823]\n",
      "old state: [0.8240511]\n",
      "{'iter': 1, 'episode': 26, 'step': 4, 'oldState': array([0.8240511], dtype=float32), 'action': array([0.02345451], dtype=float32), 'reward': -0.8695644587278366, 'newState': array([0.91600823], dtype=float32), 'info': {'arrival': 0.9160082220375395}}\n",
      "new state: [0.863377]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 27, 'step': 0, 'oldState': array([0.]), 'action': array([0.24496312], dtype=float32), 'reward': -0.5250511802732944, 'newState': array([0.863377], dtype=float32), 'info': {'arrival': 0.8633769606637638}}\n",
      "new state: [0.52440685]\n",
      "old state: [0.863377]\n",
      "{'iter': 1, 'episode': 27, 'step': 1, 'oldState': array([0.863377], dtype=float32), 'action': array([0.26526082], dtype=float32), 'reward': -0.3438885658979416, 'newState': array([0.52440685], dtype=float32), 'info': {'arrival': 0.5244068763907147}}\n",
      "new state: [0.81953454]\n",
      "old state: [0.52440685]\n",
      "{'iter': 1, 'episode': 27, 'step': 2, 'oldState': array([0.52440685], dtype=float32), 'action': array([0.56077176], dtype=float32), 'reward': -0.20316331088542938, 'newState': array([0.81953454], dtype=float32), 'info': {'arrival': 0.8195345652695233}}\n",
      "new state: [0.66142356]\n",
      "old state: [0.81953454]\n",
      "{'iter': 1, 'episode': 27, 'step': 3, 'oldState': array([0.81953454], dtype=float32), 'action': array([0.08249559], dtype=float32), 'reward': -0.6184557378292084, 'newState': array([0.66142356], dtype=float32), 'info': {'arrival': 0.661423585757726}}\n",
      "new state: [0.6383231]\n",
      "old state: [0.66142356]\n",
      "{'iter': 1, 'episode': 27, 'step': 4, 'oldState': array([0.66142356], dtype=float32), 'action': array([0.30055907], dtype=float32), 'reward': -0.34353916347026825, 'newState': array([0.6383231], dtype=float32), 'info': {'arrival': 0.6383231004655056}}\n",
      "new state: [0.9359216]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 28, 'step': 0, 'oldState': array([0.]), 'action': array([0.40900257], dtype=float32), 'reward': -0.4974398985505104, 'newState': array([0.9359216], dtype=float32), 'info': {'arrival': 0.9359216104006971}}\n",
      "new state: [0.61460465]\n",
      "old state: [0.9359216]\n",
      "{'iter': 1, 'episode': 28, 'step': 1, 'oldState': array([0.9359216], dtype=float32), 'action': array([0.7106002], dtype=float32), 'reward': -0.12832701206207275, 'newState': array([0.61460465], dtype=float32), 'info': {'arrival': 0.6146046403307744}}\n",
      "new state: [0.6704422]\n",
      "old state: [0.61460465]\n",
      "{'iter': 1, 'episode': 28, 'step': 2, 'oldState': array([0.61460465], dtype=float32), 'action': array([0.13212271], dtype=float32), 'reward': -0.5243601351976395, 'newState': array([0.6704422], dtype=float32), 'info': {'arrival': 0.6704422493954056}}\n",
      "new state: [0.86381745]\n",
      "old state: [0.6704422]\n",
      "{'iter': 1, 'episode': 28, 'step': 3, 'oldState': array([0.6704422], dtype=float32), 'action': array([0.3563865], dtype=float32), 'reward': -0.459087111055851, 'newState': array([0.86381745], dtype=float32), 'info': {'arrival': 0.8638174354345426}}\n",
      "new state: [0.81946135]\n",
      "old state: [0.86381745]\n",
      "{'iter': 1, 'episode': 28, 'step': 4, 'oldState': array([0.86381745], dtype=float32), 'action': array([0.6331044], dtype=float32), 'reward': -0.19744598865509033, 'newState': array([0.81946135], dtype=float32), 'info': {'arrival': 0.8194613379417747}}\n",
      "new state: [0.61303854]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 29, 'step': 0, 'oldState': array([0.]), 'action': array([0.1664002], dtype=float32), 'reward': -0.37657880783081055, 'newState': array([0.61303854], dtype=float32), 'info': {'arrival': 0.6130385532300813}}\n",
      "new state: [0.6777214]\n",
      "old state: [0.61303854]\n",
      "{'iter': 1, 'episode': 29, 'step': 1, 'oldState': array([0.61303854], dtype=float32), 'action': array([0.9754685], dtype=float32), 'reward': -0.3139178454875946, 'newState': array([0.6777214], dtype=float32), 'info': {'arrival': 0.6777213691821014}}\n",
      "new state: [0.45616612]\n",
      "old state: [0.6777214]\n",
      "{'iter': 1, 'episode': 29, 'step': 2, 'oldState': array([0.6777214], dtype=float32), 'action': array([0.47646707], dtype=float32), 'reward': -0.06553929299116135, 'newState': array([0.45616612], dtype=float32), 'info': {'arrival': 0.45616612864586226}}\n",
      "new state: [0.90664965]\n",
      "old state: [0.45616612]\n",
      "{'iter': 1, 'episode': 29, 'step': 3, 'oldState': array([0.45616612], dtype=float32), 'action': array([0.7533591], dtype=float32), 'reward': -0.1892661675810814, 'newState': array([0.90664965], dtype=float32), 'info': {'arrival': 0.9066496650250575}}\n",
      "new state: [0.66110224]\n",
      "old state: [0.90664965]\n",
      "{'iter': 1, 'episode': 29, 'step': 4, 'oldState': array([0.90664965], dtype=float32), 'action': array([0.9292734], dtype=float32), 'reward': -0.20678433775901794, 'newState': array([0.66110224], dtype=float32), 'info': {'arrival': 0.6611022233555737}}\n",
      "new state: [0.6965237]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 30, 'step': 0, 'oldState': array([0.]), 'action': array([0.18555552], dtype=float32), 'reward': -0.4296150356531143, 'newState': array([0.6965237], dtype=float32), 'info': {'arrival': 0.6965237494716642}}\n",
      "new state: [0.6981045]\n",
      "old state: [0.6965237]\n",
      "{'iter': 1, 'episode': 30, 'step': 1, 'oldState': array([0.6965237], dtype=float32), 'action': array([0.9756894], dtype=float32), 'reward': -0.27798010408878326, 'newState': array([0.6981045], dtype=float32), 'info': {'arrival': 0.6981045022850161}}\n",
      "new state: [0.8706215]\n",
      "old state: [0.6981045]\n",
      "{'iter': 1, 'episode': 30, 'step': 2, 'oldState': array([0.6981045], dtype=float32), 'action': array([0.30431315], dtype=float32), 'reward': -0.5231791213154793, 'newState': array([0.8706215], dtype=float32), 'info': {'arrival': 0.8706215088095016}}\n",
      "new state: [0.57512283]\n",
      "old state: [0.8706215]\n",
      "{'iter': 1, 'episode': 30, 'step': 3, 'oldState': array([0.8706215], dtype=float32), 'action': array([0.5439767], dtype=float32), 'reward': -0.10502077639102936, 'newState': array([0.57512283], dtype=float32), 'info': {'arrival': 0.5751228179022854}}\n",
      "new state: [0.72656333]\n",
      "old state: [0.57512283]\n",
      "{'iter': 1, 'episode': 30, 'step': 4, 'oldState': array([0.57512283], dtype=float32), 'action': array([0.24074139], dtype=float32), 'reward': -0.44796183705329895, 'newState': array([0.72656333], dtype=float32), 'info': {'arrival': 0.7265633126150802}}\n",
      "new state: [0.847006]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 31, 'step': 0, 'oldState': array([0.]), 'action': array([0.884862], dtype=float32), 'reward': -0.24960748851299286, 'newState': array([0.847006], dtype=float32), 'info': {'arrival': 0.8470060079515147}}\n",
      "new state: [0.6691137]\n",
      "old state: [0.847006]\n",
      "{'iter': 1, 'episode': 31, 'step': 1, 'oldState': array([0.847006], dtype=float32), 'action': array([0.40041977], dtype=float32), 'reward': -0.313167005777359, 'newState': array([0.6691137], dtype=float32), 'info': {'arrival': 0.6691137132191832}}\n",
      "new state: [0.76585174]\n",
      "old state: [0.6691137]\n",
      "{'iter': 1, 'episode': 31, 'step': 2, 'oldState': array([0.6691137], dtype=float32), 'action': array([0.4885304], dtype=float32), 'reward': -0.2531368285417557, 'newState': array([0.76585174], dtype=float32), 'info': {'arrival': 0.7658517136394565}}\n",
      "new state: [0.55078936]\n",
      "old state: [0.76585174]\n",
      "{'iter': 1, 'episode': 31, 'step': 3, 'oldState': array([0.76585174], dtype=float32), 'action': array([0.9136334], dtype=float32), 'reward': -0.3090784549713135, 'newState': array([0.55078936], dtype=float32), 'info': {'arrival': 0.5507893685777075}}\n",
      "new state: [0.4593903]\n",
      "old state: [0.55078936]\n",
      "{'iter': 1, 'episode': 31, 'step': 4, 'oldState': array([0.55078936], dtype=float32), 'action': array([0.48095617], dtype=float32), 'reward': -0.03363268822431564, 'newState': array([0.4593903], dtype=float32), 'info': {'arrival': 0.45939031705493083}}\n",
      "new state: [0.5933565]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 32, 'step': 0, 'oldState': array([0.]), 'action': array([0.69423884], dtype=float32), 'reward': -0.24922147393226624, 'newState': array([0.5933565], dtype=float32), 'info': {'arrival': 0.5933565106940203}}\n",
      "new state: [0.78504777]\n",
      "old state: [0.5933565]\n",
      "{'iter': 1, 'episode': 32, 'step': 1, 'oldState': array([0.5933565], dtype=float32), 'action': array([0.36856464], dtype=float32), 'reward': -0.3685603141784668, 'newState': array([0.78504777], dtype=float32), 'info': {'arrival': 0.7850477889140698}}\n",
      "new state: [0.574963]\n",
      "old state: [0.78504777]\n",
      "{'iter': 1, 'episode': 32, 'step': 2, 'oldState': array([0.78504777], dtype=float32), 'action': array([0.20933965], dtype=float32), 'reward': -0.4181445315480232, 'newState': array([0.574963], dtype=float32), 'info': {'arrival': 0.5749629828710864}}\n",
      "new state: [0.34602255]\n",
      "old state: [0.574963]\n",
      "{'iter': 1, 'episode': 32, 'step': 3, 'oldState': array([0.574963], dtype=float32), 'action': array([0.8634945], dtype=float32), 'reward': -0.4602368623018265, 'newState': array([0.34602255], dtype=float32), 'info': {'arrival': 0.346022561025325}}\n",
      "new state: [0.7803187]\n",
      "old state: [0.34602255]\n",
      "{'iter': 1, 'episode': 32, 'step': 4, 'oldState': array([0.34602255], dtype=float32), 'action': array([0.40523505], dtype=float32), 'reward': -0.29611584544181824, 'newState': array([0.7803187], dtype=float32), 'info': {'arrival': 0.7803187058644323}}\n",
      "new state: [0.9064457]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 33, 'step': 0, 'oldState': array([0.]), 'action': array([0.76905495], dtype=float32), 'reward': -0.2953067868947983, 'newState': array([0.9064457], dtype=float32), 'info': {'arrival': 0.9064456679278173}}\n",
      "new state: [0.8610443]\n",
      "old state: [0.9064457]\n",
      "{'iter': 1, 'episode': 33, 'step': 1, 'oldState': array([0.9064457], dtype=float32), 'action': array([0.8136375], dtype=float32), 'reward': -0.05875714123249054, 'newState': array([0.8610443], dtype=float32), 'info': {'arrival': 0.8610442670147769}}\n",
      "new state: [0.8393785]\n",
      "old state: [0.8610443]\n",
      "{'iter': 1, 'episode': 33, 'step': 2, 'oldState': array([0.8610443], dtype=float32), 'action': array([0.07776382], dtype=float32), 'reward': -0.7670311331748962, 'newState': array([0.8393785], dtype=float32), 'info': {'arrival': 0.8393784922829809}}\n",
      "new state: [0.4717241]\n",
      "old state: [0.8393785]\n",
      "{'iter': 1, 'episode': 33, 'step': 3, 'oldState': array([0.8393785], dtype=float32), 'action': array([0.7525057], dtype=float32), 'reward': -0.2323044091463089, 'newState': array([0.4717241], dtype=float32), 'info': {'arrival': 0.47172408080821665}}\n",
      "new state: [0.87350297]\n",
      "old state: [0.4717241]\n",
      "{'iter': 1, 'episode': 33, 'step': 4, 'oldState': array([0.4717241], dtype=float32), 'action': array([0.9404916], dtype=float32), 'reward': -0.16743336617946625, 'newState': array([0.87350297], dtype=float32), 'info': {'arrival': 0.8735029425483201}}\n",
      "new state: [0.78061444]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 34, 'step': 0, 'oldState': array([0.]), 'action': array([0.38199624], dtype=float32), 'reward': -0.3944627046585083, 'newState': array([0.78061444], dtype=float32), 'info': {'arrival': 0.7806144559898873}}\n",
      "new state: [0.5232629]\n",
      "old state: [0.78061444]\n",
      "{'iter': 1, 'episode': 34, 'step': 1, 'oldState': array([0.78061444], dtype=float32), 'action': array([0.42372867], dtype=float32), 'reward': -0.1638721227645874, 'newState': array([0.5232629], dtype=float32), 'info': {'arrival': 0.5232629259272527}}\n",
      "new state: [0.9914221]\n",
      "old state: [0.5232629]\n",
      "{'iter': 1, 'episode': 34, 'step': 2, 'oldState': array([0.5232629], dtype=float32), 'action': array([0.5134211], dtype=float32), 'reward': -0.3609611988067627, 'newState': array([0.9914221], dtype=float32), 'info': {'arrival': 0.9914220909571693}}\n",
      "new state: [0.67373604]\n",
      "old state: [0.9914221]\n",
      "{'iter': 1, 'episode': 34, 'step': 3, 'oldState': array([0.9914221], dtype=float32), 'action': array([0.9442412], dtype=float32), 'reward': -0.21467411518096924, 'newState': array([0.67373604], dtype=float32), 'info': {'arrival': 0.6737360209062191}}\n",
      "new state: [0.5474973]\n",
      "old state: [0.67373604]\n",
      "{'iter': 1, 'episode': 34, 'step': 4, 'oldState': array([0.67373604], dtype=float32), 'action': array([0.6542847], dtype=float32), 'reward': -0.0849534124135971, 'newState': array([0.5474973], dtype=float32), 'info': {'arrival': 0.5474972967383508}}\n",
      "new state: [0.74847376]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 35, 'step': 0, 'oldState': array([0.]), 'action': array([0.24769944], dtype=float32), 'reward': -0.4375056028366089, 'newState': array([0.74847376], dtype=float32), 'info': {'arrival': 0.7484737794620547}}\n",
      "new state: [0.9583632]\n",
      "old state: [0.74847376]\n",
      "{'iter': 1, 'episode': 35, 'step': 1, 'oldState': array([0.74847376], dtype=float32), 'action': array([0.4770925], dtype=float32), 'reward': -0.4287983179092407, 'newState': array([0.9583632], dtype=float32), 'info': {'arrival': 0.9583631706155307}}\n",
      "new state: [0.84837407]\n",
      "old state: [0.9583632]\n",
      "{'iter': 1, 'episode': 35, 'step': 2, 'oldState': array([0.9583632], dtype=float32), 'action': array([0.69077903], dtype=float32), 'reward': -0.18509231507778168, 'newState': array([0.84837407], dtype=float32), 'info': {'arrival': 0.8483740647184608}}\n",
      "new state: [0.8770393]\n",
      "old state: [0.84837407]\n",
      "{'iter': 1, 'episode': 35, 'step': 3, 'oldState': array([0.84837407], dtype=float32), 'action': array([0.9859599], dtype=float32), 'reward': -0.11608688533306122, 'newState': array([0.8770393], dtype=float32), 'info': {'arrival': 0.8770393225740729}}\n",
      "new state: [0.8883029]\n",
      "old state: [0.8770393]\n",
      "{'iter': 1, 'episode': 35, 'step': 4, 'oldState': array([0.8770393], dtype=float32), 'action': array([0.30039102], dtype=float32), 'reward': -0.585096001625061, 'newState': array([0.8883029], dtype=float32), 'info': {'arrival': 0.8883029413522182}}\n",
      "new state: [0.45629618]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 36, 'step': 0, 'oldState': array([0.]), 'action': array([0.77332366], dtype=float32), 'reward': -0.4311015233397484, 'newState': array([0.45629618], dtype=float32), 'info': {'arrival': 0.4562961610515183}}\n",
      "new state: [0.9575221]\n",
      "old state: [0.45629618]\n",
      "{'iter': 1, 'episode': 36, 'step': 1, 'oldState': array([0.45629618], dtype=float32), 'action': array([0.39626026], dtype=float32), 'reward': -0.43595535308122635, 'newState': array([0.9575221], dtype=float32), 'info': {'arrival': 0.9575221064240967}}\n",
      "new state: [0.85481006]\n",
      "old state: [0.9575221]\n",
      "{'iter': 1, 'episode': 36, 'step': 2, 'oldState': array([0.9575221], dtype=float32), 'action': array([0.5470512], dtype=float32), 'reward': -0.33343687653541565, 'newState': array([0.85481006], dtype=float32), 'info': {'arrival': 0.8548100463915272}}\n",
      "new state: [0.5491881]\n",
      "old state: [0.85481006]\n",
      "{'iter': 1, 'episode': 36, 'step': 3, 'oldState': array([0.85481006], dtype=float32), 'action': array([0.35484618], dtype=float32), 'reward': -0.2707473933696747, 'newState': array([0.5491881], dtype=float32), 'info': {'arrival': 0.5491880977305972}}\n",
      "new state: [0.86644965]\n",
      "old state: [0.5491881]\n",
      "{'iter': 1, 'episode': 36, 'step': 4, 'oldState': array([0.5491881], dtype=float32), 'action': array([0.11429165], dtype=float32), 'reward': -0.6728425920009613, 'newState': array([0.86644965], dtype=float32), 'info': {'arrival': 0.8664496462458418}}\n",
      "new state: [0.78046185]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 37, 'step': 0, 'oldState': array([0.]), 'action': array([0.98309636], dtype=float32), 'reward': -0.39774997532367706, 'newState': array([0.78046185], dtype=float32), 'info': {'arrival': 0.7804618433986056}}\n",
      "new state: [0.4627704]\n",
      "old state: [0.78046185]\n",
      "{'iter': 1, 'episode': 37, 'step': 1, 'oldState': array([0.78046185], dtype=float32), 'action': array([0.0329988], dtype=float32), 'reward': -0.5091944634914398, 'newState': array([0.4627704], dtype=float32), 'info': {'arrival': 0.46277039804647097}}\n",
      "new state: [0.68163955]\n",
      "old state: [0.4627704]\n",
      "{'iter': 1, 'episode': 37, 'step': 2, 'oldState': array([0.4627704], dtype=float32), 'action': array([0.42212683], dtype=float32), 'reward': -0.20479543507099152, 'newState': array([0.68163955], dtype=float32), 'info': {'arrival': 0.6816395299874134}}\n",
      "new state: [0.66750675]\n",
      "old state: [0.68163955]\n",
      "{'iter': 1, 'episode': 37, 'step': 3, 'oldState': array([0.68163955], dtype=float32), 'action': array([0.21107902], dtype=float32), 'reward': -0.4599609524011612, 'newState': array([0.66750675], dtype=float32), 'info': {'arrival': 0.6675067836097655}}\n",
      "new state: [0.69270974]\n",
      "old state: [0.66750675]\n",
      "{'iter': 1, 'episode': 37, 'step': 4, 'oldState': array([0.66750675], dtype=float32), 'action': array([0.77867717], dtype=float32), 'reward': -0.09226816892623901, 'newState': array([0.69270974], dtype=float32), 'info': {'arrival': 0.6927097647949857}}\n",
      "new state: [0.54598737]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 38, 'step': 0, 'oldState': array([0.]), 'action': array([0.9166469], dtype=float32), 'reward': -0.5071563720703125, 'newState': array([0.54598737], dtype=float32), 'info': {'arrival': 0.5459873415043991}}\n",
      "new state: [0.8439529]\n",
      "old state: [0.54598737]\n",
      "{'iter': 1, 'episode': 38, 'step': 1, 'oldState': array([0.54598737], dtype=float32), 'action': array([0.74167836], dtype=float32), 'reward': -0.12562865018844604, 'newState': array([0.8439529], dtype=float32), 'info': {'arrival': 0.8439528829642188}}\n",
      "new state: [0.54880965]\n",
      "old state: [0.8439529]\n",
      "{'iter': 1, 'episode': 38, 'step': 2, 'oldState': array([0.8439529], dtype=float32), 'action': array([0.42756903], dtype=float32), 'reward': -0.1950264275074005, 'newState': array([0.54880965], dtype=float32), 'info': {'arrival': 0.5488096461601628}}\n",
      "new state: [0.6431703]\n",
      "old state: [0.54880965]\n",
      "{'iter': 1, 'episode': 38, 'step': 3, 'oldState': array([0.54880965], dtype=float32), 'action': array([0.9963984], dtype=float32), 'reward': -0.3768182545900345, 'newState': array([0.6431703], dtype=float32), 'info': {'arrival': 0.6431702995530381}}\n",
      "new state: [0.52839607]\n",
      "old state: [0.6431703]\n",
      "{'iter': 1, 'episode': 38, 'step': 4, 'oldState': array([0.6431703], dtype=float32), 'action': array([0.04170723], dtype=float32), 'reward': -0.5153824090957642, 'newState': array([0.52839607], dtype=float32), 'info': {'arrival': 0.5283960549966751}}\n",
      "new state: [0.9183288]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 39, 'step': 0, 'oldState': array([0.]), 'action': array([0.7268938], dtype=float32), 'reward': -0.3252997249364853, 'newState': array([0.9183288], dtype=float32), 'info': {'arrival': 0.9183288325559593}}\n",
      "new state: [0.6864181]\n",
      "old state: [0.9183288]\n",
      "{'iter': 1, 'episode': 39, 'step': 1, 'oldState': array([0.9183288], dtype=float32), 'action': array([0.8794387], dtype=float32), 'reward': -0.1544879674911499, 'newState': array([0.6864181], dtype=float32), 'info': {'arrival': 0.6864181209251154}}\n",
      "new state: [0.7952651]\n",
      "old state: [0.6864181]\n",
      "{'iter': 1, 'episode': 39, 'step': 2, 'oldState': array([0.6864181], dtype=float32), 'action': array([0.08284823], dtype=float32), 'reward': -0.6852050870656967, 'newState': array([0.7952651], dtype=float32), 'info': {'arrival': 0.7952651044335183}}\n",
      "new state: [0.92200506]\n",
      "old state: [0.7952651]\n",
      "{'iter': 1, 'episode': 39, 'step': 3, 'oldState': array([0.7952651], dtype=float32), 'action': array([0.36425528], dtype=float32), 'reward': -0.5260647609829903, 'newState': array([0.92200506], dtype=float32), 'info': {'arrival': 0.9220050586212458}}\n",
      "new state: [0.92966163]\n",
      "old state: [0.92200506]\n",
      "{'iter': 1, 'episode': 39, 'step': 4, 'oldState': array([0.92200506], dtype=float32), 'action': array([0.9898251], dtype=float32), 'reward': -0.06207764148712158, 'newState': array([0.92966163], dtype=float32), 'info': {'arrival': 0.9296616447358058}}\n",
      "new state: [0.56370455]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 40, 'step': 0, 'oldState': array([0.]), 'action': array([0.8848524], dtype=float32), 'reward': -0.46207399666309357, 'newState': array([0.56370455], dtype=float32), 'info': {'arrival': 0.5637045702225951}}\n",
      "new state: [0.60732985]\n",
      "old state: [0.56370455]\n",
      "{'iter': 1, 'episode': 40, 'step': 1, 'oldState': array([0.56370455], dtype=float32), 'action': array([0.15168288], dtype=float32), 'reward': -0.4447406381368637, 'newState': array([0.60732985], dtype=float32), 'info': {'arrival': 0.6073298195503204}}\n",
      "new state: [0.63003606]\n",
      "old state: [0.60732985]\n",
      "{'iter': 1, 'episode': 40, 'step': 2, 'oldState': array([0.60732985], dtype=float32), 'action': array([0.6094087], dtype=float32), 'reward': -0.0159902423620224, 'newState': array([0.63003606], dtype=float32), 'info': {'arrival': 0.6300360776602277}}\n",
      "new state: [0.63933927]\n",
      "old state: [0.63003606]\n",
      "{'iter': 1, 'episode': 40, 'step': 3, 'oldState': array([0.63003606], dtype=float32), 'action': array([0.4695303], dtype=float32), 'reward': -0.1674831509590149, 'newState': array([0.63933927], dtype=float32), 'info': {'arrival': 0.6393392692272428}}\n",
      "new state: [0.8349821]\n",
      "old state: [0.63933927]\n",
      "{'iter': 1, 'episode': 40, 'step': 4, 'oldState': array([0.63933927], dtype=float32), 'action': array([0.8801114], dtype=float32), 'reward': -0.09404000639915466, 'newState': array([0.8349821], dtype=float32), 'info': {'arrival': 0.8349820907306648}}\n",
      "new state: [0.79940474]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 41, 'step': 0, 'oldState': array([0.]), 'action': array([0.9334495], dtype=float32), 'reward': -0.3338959515094757, 'newState': array([0.79940474], dtype=float32), 'info': {'arrival': 0.7994047204396916}}\n",
      "new state: [0.9725642]\n",
      "old state: [0.79940474]\n",
      "{'iter': 1, 'episode': 41, 'step': 1, 'oldState': array([0.79940474], dtype=float32), 'action': array([0.5353909], dtype=float32), 'reward': -0.39388343691825867, 'newState': array([0.9725642], dtype=float32), 'info': {'arrival': 0.9725642021830965}}\n",
      "new state: [0.7208186]\n",
      "old state: [0.9725642]\n",
      "{'iter': 1, 'episode': 41, 'step': 2, 'oldState': array([0.9725642], dtype=float32), 'action': array([0.828994], dtype=float32), 'reward': -0.11702410876750946, 'newState': array([0.7208186], dtype=float32), 'info': {'arrival': 0.7208185741816008}}\n",
      "new state: [0.74383515]\n",
      "old state: [0.7208186]\n",
      "{'iter': 1, 'episode': 41, 'step': 3, 'oldState': array([0.7208186], dtype=float32), 'action': array([0.08875534], dtype=float32), 'reward': -0.6493256986141205, 'newState': array([0.74383515], dtype=float32), 'info': {'arrival': 0.7438351556562159}}\n",
      "new state: [0.71912825]\n",
      "old state: [0.74383515]\n",
      "{'iter': 1, 'episode': 41, 'step': 4, 'oldState': array([0.74383515], dtype=float32), 'action': array([0.52770805], dtype=float32), 'reward': -0.19759692251682281, 'newState': array([0.71912825], dtype=float32), 'info': {'arrival': 0.7191282585056519}}\n",
      "new state: [0.95771426]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 42, 'step': 0, 'oldState': array([0.]), 'action': array([0.37710553], dtype=float32), 'reward': -0.5297329276800156, 'newState': array([0.95771426], dtype=float32), 'info': {'arrival': 0.9577142749840756}}\n",
      "new state: [0.46158338]\n",
      "old state: [0.95771426]\n",
      "{'iter': 1, 'episode': 42, 'step': 1, 'oldState': array([0.95771426], dtype=float32), 'action': array([0.16847946], dtype=float32), 'reward': -0.41713665425777435, 'newState': array([0.46158338], dtype=float32), 'info': {'arrival': 0.4615833623047356}}\n",
      "new state: [0.93073094]\n",
      "old state: [0.46158338]\n",
      "{'iter': 1, 'episode': 42, 'step': 2, 'oldState': array([0.46158338], dtype=float32), 'action': array([0.09097382], dtype=float32), 'reward': -0.7224702462553978, 'newState': array([0.93073094], dtype=float32), 'info': {'arrival': 0.9307309348165048}}\n",
      "new state: [0.53764606]\n",
      "old state: [0.93073094]\n",
      "{'iter': 1, 'episode': 42, 'step': 3, 'oldState': array([0.93073094], dtype=float32), 'action': array([0.47880688], dtype=float32), 'reward': -0.15711039304733276, 'newState': array([0.53764606], dtype=float32), 'info': {'arrival': 0.5376460602985857}}\n",
      "new state: [0.7589169]\n",
      "old state: [0.53764606]\n",
      "{'iter': 1, 'episode': 42, 'step': 4, 'oldState': array([0.53764606], dtype=float32), 'action': array([0.20842682], dtype=float32), 'reward': -0.4951723664999008, 'newState': array([0.7589169], dtype=float32), 'info': {'arrival': 0.7589168908609509}}\n",
      "new state: [0.5927287]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 43, 'step': 0, 'oldState': array([0.]), 'action': array([0.4804725], dtype=float32), 'reward': -0.20431025326251984, 'newState': array([0.5927287], dtype=float32), 'info': {'arrival': 0.5927286645622429}}\n",
      "new state: [0.90586334]\n",
      "old state: [0.5927287]\n",
      "{'iter': 1, 'episode': 43, 'step': 1, 'oldState': array([0.5927287], dtype=float32), 'action': array([0.14494504], dtype=float32), 'reward': -0.6826346516609192, 'newState': array([0.90586334], dtype=float32), 'info': {'arrival': 0.9058633665501433}}\n",
      "new state: [0.45553926]\n",
      "old state: [0.90586334]\n",
      "{'iter': 1, 'episode': 43, 'step': 2, 'oldState': array([0.90586334], dtype=float32), 'action': array([0.07760902], dtype=float32), 'reward': -0.4905112534761429, 'newState': array([0.45553926], dtype=float32), 'info': {'arrival': 0.4555392613255116}}\n",
      "new state: [0.80944896]\n",
      "old state: [0.45553926]\n",
      "{'iter': 1, 'episode': 43, 'step': 3, 'oldState': array([0.45553926], dtype=float32), 'action': array([0.04251017], dtype=float32), 'reward': -0.6784613728523254, 'newState': array([0.80944896], dtype=float32), 'info': {'arrival': 0.809448972887149}}\n",
      "new state: [0.42803583]\n",
      "old state: [0.80944896]\n",
      "{'iter': 1, 'episode': 43, 'step': 4, 'oldState': array([0.80944896], dtype=float32), 'action': array([0.49392277], dtype=float32), 'reward': -0.12829675525426865, 'newState': array([0.42803583], dtype=float32), 'info': {'arrival': 0.4280358348579755}}\n",
      "new state: [0.67819303]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 44, 'step': 0, 'oldState': array([0.]), 'action': array([0.46968538], dtype=float32), 'reward': -0.27380208671092987, 'newState': array([0.67819303], dtype=float32), 'info': {'arrival': 0.6781930279966955}}\n",
      "new state: [0.37596866]\n",
      "old state: [0.67819303]\n",
      "{'iter': 1, 'episode': 44, 'step': 1, 'oldState': array([0.67819303], dtype=float32), 'action': array([0.7131847], dtype=float32), 'reward': -0.2616599574685097, 'newState': array([0.37596866], dtype=float32), 'info': {'arrival': 0.37596867231575665}}\n",
      "new state: [0.91472995]\n",
      "old state: [0.37596866]\n",
      "{'iter': 1, 'episode': 44, 'step': 2, 'oldState': array([0.37596866], dtype=float32), 'action': array([0.11654635], dtype=float32), 'reward': -0.6634932905435562, 'newState': array([0.91472995], dtype=float32), 'info': {'arrival': 0.9147299410947529}}\n",
      "new state: [0.7644476]\n",
      "old state: [0.91472995]\n",
      "{'iter': 1, 'episode': 44, 'step': 3, 'oldState': array([0.91472995], dtype=float32), 'action': array([0.28467035], dtype=float32), 'reward': -0.5173478573560715, 'newState': array([0.7644476], dtype=float32), 'info': {'arrival': 0.7644476124834366}}\n",
      "new state: [0.7576178]\n",
      "old state: [0.7644476]\n",
      "{'iter': 1, 'episode': 44, 'step': 4, 'oldState': array([0.7644476], dtype=float32), 'action': array([0.853669], dtype=float32), 'reward': -0.09434375166893005, 'newState': array([0.7576178], dtype=float32), 'info': {'arrival': 0.757617750733346}}\n",
      "new state: [0.782385]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 45, 'step': 0, 'oldState': array([0.]), 'action': array([0.8385436], dtype=float32), 'reward': -0.25175485014915466, 'newState': array([0.782385], dtype=float32), 'info': {'arrival': 0.7823850198741475}}\n",
      "new state: [0.9424704]\n",
      "old state: [0.782385]\n",
      "{'iter': 1, 'episode': 45, 'step': 1, 'oldState': array([0.782385], dtype=float32), 'action': array([0.06841864], dtype=float32), 'reward': -0.8340304046869278, 'newState': array([0.9424704], dtype=float32), 'info': {'arrival': 0.9424703645435544}}\n",
      "new state: [0.6756654]\n",
      "old state: [0.9424704]\n",
      "{'iter': 1, 'episode': 45, 'step': 2, 'oldState': array([0.9424704], dtype=float32), 'action': array([0.59556013], dtype=float32), 'reward': -0.1468064934015274, 'newState': array([0.6756654], dtype=float32), 'info': {'arrival': 0.6756653899506047}}\n",
      "new state: [0.75791407]\n",
      "old state: [0.6756654]\n",
      "{'iter': 1, 'episode': 45, 'step': 3, 'oldState': array([0.6756654], dtype=float32), 'action': array([0.519927], dtype=float32), 'reward': -0.21742486953735352, 'newState': array([0.75791407], dtype=float32), 'info': {'arrival': 0.7579140543069205}}\n",
      "new state: [0.8318863]\n",
      "old state: [0.75791407]\n",
      "{'iter': 1, 'episode': 45, 'step': 4, 'oldState': array([0.75791407], dtype=float32), 'action': array([0.9299874], dtype=float32), 'reward': -0.11659413576126099, 'newState': array([0.8318863], dtype=float32), 'info': {'arrival': 0.8318862981170221}}\n",
      "new state: [0.62408614]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 46, 'step': 0, 'oldState': array([0.]), 'action': array([0.00416345], dtype=float32), 'reward': -0.46598288672976196, 'newState': array([0.62408614], dtype=float32), 'info': {'arrival': 0.6240861537355519}}\n",
      "new state: [0.91710883]\n",
      "old state: [0.62408614]\n",
      "{'iter': 1, 'episode': 46, 'step': 1, 'oldState': array([0.62408614], dtype=float32), 'action': array([0.40865606], dtype=float32), 'reward': -0.4351971000432968, 'newState': array([0.91710883], dtype=float32), 'info': {'arrival': 0.9171088359384987}}\n",
      "new state: [0.8207711]\n",
      "old state: [0.91710883]\n",
      "{'iter': 1, 'episode': 46, 'step': 2, 'oldState': array([0.91710883], dtype=float32), 'action': array([0.33409867], dtype=float32), 'reward': -0.5107568725943565, 'newState': array([0.8207711], dtype=float32), 'info': {'arrival': 0.8207710764119419}}\n",
      "new state: [0.4300969]\n",
      "old state: [0.8207711]\n",
      "{'iter': 1, 'episode': 46, 'step': 3, 'oldState': array([0.8207711], dtype=float32), 'action': array([0.83105886], dtype=float32), 'reward': -0.303293414413929, 'newState': array([0.4300969], dtype=float32), 'info': {'arrival': 0.4300968996889486}}\n",
      "new state: [0.8536977]\n",
      "old state: [0.4300969]\n",
      "{'iter': 1, 'episode': 46, 'step': 4, 'oldState': array([0.4300969], dtype=float32), 'action': array([0.8989682], dtype=float32), 'reward': -0.15117070823907852, 'newState': array([0.8536977], dtype=float32), 'info': {'arrival': 0.8536977303698182}}\n",
      "new state: [0.8823461]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 47, 'step': 0, 'oldState': array([0.]), 'action': array([0.16800793], dtype=float32), 'reward': -0.577755618840456, 'newState': array([0.8823461], dtype=float32), 'info': {'arrival': 0.8823460887456896}}\n",
      "new state: [0.68485546]\n",
      "old state: [0.8823461]\n",
      "{'iter': 1, 'episode': 47, 'step': 1, 'oldState': array([0.8823461], dtype=float32), 'action': array([0.9830039], dtype=float32), 'reward': -0.24877579510211945, 'newState': array([0.68485546], dtype=float32), 'info': {'arrival': 0.6848554341228364}}\n",
      "new state: [0.79766387]\n",
      "old state: [0.68485546]\n",
      "{'iter': 1, 'episode': 47, 'step': 2, 'oldState': array([0.68485546], dtype=float32), 'action': array([0.49949035], dtype=float32), 'reward': -0.26997141540050507, 'newState': array([0.79766387], dtype=float32), 'info': {'arrival': 0.797663853955082}}\n",
      "new state: [0.40467894]\n",
      "old state: [0.79766387]\n",
      "{'iter': 1, 'episode': 47, 'step': 3, 'oldState': array([0.79766387], dtype=float32), 'action': array([0.8463666], dtype=float32), 'reward': -0.3434414118528366, 'newState': array([0.40467894], dtype=float32), 'info': {'arrival': 0.40467895194116904}}\n",
      "new state: [0.7294371]\n",
      "old state: [0.40467894]\n",
      "{'iter': 1, 'episode': 47, 'step': 4, 'oldState': array([0.40467894], dtype=float32), 'action': array([0.32151666], dtype=float32), 'reward': -0.3267309069633484, 'newState': array([0.7294371], dtype=float32), 'info': {'arrival': 0.7294371295364984}}\n",
      "new state: [0.5480776]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 48, 'step': 0, 'oldState': array([0.]), 'action': array([0.480033], dtype=float32), 'reward': -0.17104168236255646, 'newState': array([0.5480776], dtype=float32), 'info': {'arrival': 0.5480776086000024}}\n",
      "new state: [0.80670315]\n",
      "old state: [0.5480776]\n",
      "{'iter': 1, 'episode': 48, 'step': 1, 'oldState': array([0.5480776], dtype=float32), 'action': array([0.2130862], dtype=float32), 'reward': -0.528960570693016, 'newState': array([0.80670315], dtype=float32), 'info': {'arrival': 0.8067031583217628}}\n",
      "new state: [0.775323]\n",
      "old state: [0.80670315]\n",
      "{'iter': 1, 'episode': 48, 'step': 2, 'oldState': array([0.80670315], dtype=float32), 'action': array([0.27137393], dtype=float32), 'reward': -0.5117940902709961, 'newState': array([0.775323], dtype=float32), 'info': {'arrival': 0.77532294766554}}\n",
      "new state: [0.6691845]\n",
      "old state: [0.775323]\n",
      "{'iter': 1, 'episode': 48, 'step': 3, 'oldState': array([0.775323], dtype=float32), 'action': array([0.6018236], dtype=float32), 'reward': -0.09389549493789673, 'newState': array([0.6691845], dtype=float32), 'info': {'arrival': 0.6691845211514084}}\n",
      "new state: [0.6446909]\n",
      "old state: [0.6691845]\n",
      "{'iter': 1, 'episode': 48, 'step': 4, 'oldState': array([0.6691845], dtype=float32), 'action': array([0.82730097], dtype=float32), 'reward': -0.17648668587207794, 'newState': array([0.6446909], dtype=float32), 'info': {'arrival': 0.6446908480372092}}\n",
      "new state: [0.39596498]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 49, 'step': 0, 'oldState': array([0.]), 'action': array([0.4824185], dtype=float32), 'reward': -0.18544477224349976, 'newState': array([0.39596498], dtype=float32), 'info': {'arrival': 0.395964985847543}}\n",
      "new state: [0.43782514]\n",
      "old state: [0.39596498]\n",
      "{'iter': 1, 'episode': 49, 'step': 1, 'oldState': array([0.39596498], dtype=float32), 'action': array([0.25636002], dtype=float32), 'reward': -0.17100007832050323, 'newState': array([0.43782514], dtype=float32), 'info': {'arrival': 0.43782513528152184}}\n",
      "new state: [0.4709397]\n",
      "old state: [0.43782514]\n",
      "{'iter': 1, 'episode': 49, 'step': 2, 'oldState': array([0.43782514], dtype=float32), 'action': array([0.38618812], dtype=float32), 'reward': -0.0764729380607605, 'newState': array([0.4709397], dtype=float32), 'info': {'arrival': 0.4709396961016456}}\n",
      "new state: [0.7829092]\n",
      "old state: [0.4709397]\n",
      "{'iter': 1, 'episode': 49, 'step': 3, 'oldState': array([0.4709397], dtype=float32), 'action': array([0.3166575], dtype=float32), 'reward': -0.38825932145118713, 'newState': array([0.7829092], dtype=float32), 'info': {'arrival': 0.7829092286936907}}\n",
      "new state: [0.86565286]\n",
      "old state: [0.7829092]\n",
      "{'iter': 1, 'episode': 49, 'step': 4, 'oldState': array([0.7829092], dtype=float32), 'action': array([0.78774893], dtype=float32), 'reward': -0.059637874364852905, 'newState': array([0.86565286], dtype=float32), 'info': {'arrival': 0.8656528649662615}}\n",
      "new state: [0.7061816]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 50, 'step': 0, 'oldState': array([0.]), 'action': array([0.40923673], dtype=float32), 'reward': -0.3250178247690201, 'newState': array([0.7061816], dtype=float32), 'info': {'arrival': 0.7061815934057988}}\n",
      "new state: [0.37216118]\n",
      "old state: [0.7061816]\n",
      "{'iter': 1, 'episode': 50, 'step': 1, 'oldState': array([0.7061816], dtype=float32), 'action': array([0.12532441], dtype=float32), 'reward': -0.3303418643772602, 'newState': array([0.37216118], dtype=float32), 'info': {'arrival': 0.3721611803822426}}\n",
      "new state: [0.6004702]\n",
      "old state: [0.37216118]\n",
      "{'iter': 1, 'episode': 50, 'step': 2, 'oldState': array([0.37216118], dtype=float32), 'action': array([0.8593266], dtype=float32), 'reward': -0.3159336671233177, 'newState': array([0.6004702], dtype=float32), 'info': {'arrival': 0.6004701555413977}}\n",
      "new state: [0.36954576]\n",
      "old state: [0.6004702]\n",
      "{'iter': 1, 'episode': 50, 'step': 3, 'oldState': array([0.6004702], dtype=float32), 'action': array([0.64909256], dtype=float32), 'reward': -0.22181569039821625, 'newState': array([0.36954576], dtype=float32), 'info': {'arrival': 0.369545744733518}}\n",
      "new state: [0.7865947]\n",
      "old state: [0.36954576]\n",
      "{'iter': 1, 'episode': 50, 'step': 4, 'oldState': array([0.36954576], dtype=float32), 'action': array([0.24762239], dtype=float32), 'reward': -0.434710081666708, 'newState': array([0.7865947], dtype=float32), 'info': {'arrival': 0.7865946819031192}}\n",
      "new state: [0.79779774]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 51, 'step': 0, 'oldState': array([0.]), 'action': array([0.14190027], dtype=float32), 'reward': -0.5273981913924217, 'newState': array([0.79779774], dtype=float32), 'info': {'arrival': 0.7977977587193364}}\n",
      "new state: [0.7465631]\n",
      "old state: [0.79779774]\n",
      "{'iter': 1, 'episode': 51, 'step': 1, 'oldState': array([0.79779774], dtype=float32), 'action': array([0.6022813], dtype=float32), 'reward': -0.1570904701948166, 'newState': array([0.7465631], dtype=float32), 'info': {'arrival': 0.7465630680864289}}\n",
      "new state: [0.7519709]\n",
      "old state: [0.7465631]\n",
      "{'iter': 1, 'episode': 51, 'step': 2, 'oldState': array([0.7465631], dtype=float32), 'action': array([0.23905583], dtype=float32), 'reward': -0.5115631222724915, 'newState': array([0.7519709], dtype=float32), 'info': {'arrival': 0.7519708686763831}}\n",
      "new state: [0.5120453]\n",
      "old state: [0.7519709]\n",
      "{'iter': 1, 'episode': 51, 'step': 3, 'oldState': array([0.7519709], dtype=float32), 'action': array([0.6530424], dtype=float32), 'reward': -0.13047991693019867, 'newState': array([0.5120453], dtype=float32), 'info': {'arrival': 0.5120453238112409}}\n",
      "new state: [0.6932481]\n",
      "old state: [0.5120453]\n",
      "{'iter': 1, 'episode': 51, 'step': 4, 'oldState': array([0.5120453], dtype=float32), 'action': array([0.40155348], dtype=float32), 'reward': -0.24639391899108887, 'newState': array([0.6932481], dtype=float32), 'info': {'arrival': 0.6932480854747635}}\n",
      "new state: [0.77540535]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 52, 'step': 0, 'oldState': array([0.]), 'action': array([0.76420593], dtype=float32), 'reward': -0.1994510442018509, 'newState': array([0.77540535], dtype=float32), 'info': {'arrival': 0.7754053414141926}}\n",
      "new state: [0.4565663]\n",
      "old state: [0.77540535]\n",
      "{'iter': 1, 'episode': 52, 'step': 1, 'oldState': array([0.77540535], dtype=float32), 'action': array([0.6436185], dtype=float32), 'reward': -0.17323587089776993, 'newState': array([0.4565663], dtype=float32), 'info': {'arrival': 0.4565663099305243}}\n",
      "new state: [0.88639784]\n",
      "old state: [0.4565663]\n",
      "{'iter': 1, 'episode': 52, 'step': 2, 'oldState': array([0.4565663], dtype=float32), 'action': array([0.24300174], dtype=float32), 'reward': -0.535938199609518, 'newState': array([0.88639784], dtype=float32), 'info': {'arrival': 0.8863978399882764}}\n",
      "new state: [0.624329]\n",
      "old state: [0.88639784]\n",
      "{'iter': 1, 'episode': 52, 'step': 3, 'oldState': array([0.88639784], dtype=float32), 'action': array([0.50507116], dtype=float32), 'reward': -0.18477502465248108, 'newState': array([0.624329], dtype=float32), 'info': {'arrival': 0.6243289436934822}}\n",
      "new state: [0.48684824]\n",
      "old state: [0.624329]\n",
      "{'iter': 1, 'episode': 52, 'step': 4, 'oldState': array([0.624329], dtype=float32), 'action': array([0.8058524], dtype=float32), 'reward': -0.284633994102478, 'newState': array([0.48684824], dtype=float32), 'info': {'arrival': 0.4868482274114359}}\n",
      "new state: [0.848462]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 53, 'step': 0, 'oldState': array([0.]), 'action': array([0.28951398], dtype=float32), 'reward': -0.4915895238518715, 'newState': array([0.848462], dtype=float32), 'info': {'arrival': 0.8484619894382788}}\n",
      "new state: [0.80629236]\n",
      "old state: [0.848462]\n",
      "{'iter': 1, 'episode': 53, 'step': 1, 'oldState': array([0.848462], dtype=float32), 'action': array([0.71168727], dtype=float32), 'reward': -0.10514749586582184, 'newState': array([0.80629236], dtype=float32), 'info': {'arrival': 0.8062923486848822}}\n",
      "new state: [0.7545262]\n",
      "old state: [0.80629236]\n",
      "{'iter': 1, 'episode': 53, 'step': 2, 'oldState': array([0.80629236], dtype=float32), 'action': array([0.514534], dtype=float32), 'reward': -0.2529337406158447, 'newState': array([0.7545262], dtype=float32), 'info': {'arrival': 0.7545261822333157}}\n",
      "new state: [0.8577972]\n",
      "old state: [0.7545262]\n",
      "{'iter': 1, 'episode': 53, 'step': 3, 'oldState': array([0.7545262], dtype=float32), 'action': array([0.7232768], dtype=float32), 'reward': -0.1087026596069336, 'newState': array([0.8577972], dtype=float32), 'info': {'arrival': 0.8577972154771337}}\n",
      "new state: [0.92216724]\n",
      "old state: [0.8577972]\n",
      "{'iter': 1, 'episode': 53, 'step': 4, 'oldState': array([0.8577972], dtype=float32), 'action': array([0.39002126], dtype=float32), 'reward': -0.5160534679889679, 'newState': array([0.92216724], dtype=float32), 'info': {'arrival': 0.9221672366089081}}\n",
      "new state: [0.94540125]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 54, 'step': 0, 'oldState': array([0.]), 'action': array([0.699305], dtype=float32), 'reward': -0.3593984395265579, 'newState': array([0.94540125], dtype=float32), 'info': {'arrival': 0.9454012486190979}}\n",
      "new state: [0.6153734]\n",
      "old state: [0.94540125]\n",
      "{'iter': 1, 'episode': 54, 'step': 1, 'oldState': array([0.94540125], dtype=float32), 'action': array([0.6691842], dtype=float32), 'reward': -0.10941238701343536, 'newState': array([0.6153734], dtype=float32), 'info': {'arrival': 0.6153733473713658}}\n",
      "new state: [0.48987898]\n",
      "old state: [0.6153734]\n",
      "{'iter': 1, 'episode': 54, 'step': 2, 'oldState': array([0.6153734], dtype=float32), 'action': array([0.77783847], dtype=float32), 'reward': -0.25658588856458664, 'newState': array([0.48987898], dtype=float32), 'info': {'arrival': 0.4898789960599422}}\n",
      "new state: [0.64813596]\n",
      "old state: [0.48987898]\n",
      "{'iter': 1, 'episode': 54, 'step': 3, 'oldState': array([0.48987898], dtype=float32), 'action': array([0.04778132], dtype=float32), 'reward': -0.5607903748750687, 'newState': array([0.64813596], dtype=float32), 'info': {'arrival': 0.6481359647884848}}\n",
      "new state: [0.7481547]\n",
      "old state: [0.64813596]\n",
      "{'iter': 1, 'episode': 54, 'step': 4, 'oldState': array([0.64813596], dtype=float32), 'action': array([0.79342663], dtype=float32), 'reward': -0.07027661800384521, 'newState': array([0.7481547], dtype=float32), 'info': {'arrival': 0.7481547007205411}}\n",
      "new state: [0.42643848]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 55, 'step': 0, 'oldState': array([0.]), 'action': array([0.82045513], dtype=float32), 'reward': -0.5006262734532356, 'newState': array([0.42643848], dtype=float32), 'info': {'arrival': 0.42643849117687105}}\n",
      "new state: [0.871328]\n",
      "old state: [0.42643848]\n",
      "{'iter': 1, 'episode': 55, 'step': 1, 'oldState': array([0.42643848], dtype=float32), 'action': array([0.4555525], dtype=float32), 'reward': -0.31911013275384903, 'newState': array([0.871328], dtype=float32), 'info': {'arrival': 0.8713279971879525}}\n",
      "new state: [0.6913839]\n",
      "old state: [0.871328]\n",
      "{'iter': 1, 'episode': 55, 'step': 2, 'oldState': array([0.871328], dtype=float32), 'action': array([0.65268177], dtype=float32), 'reward': -0.0836881548166275, 'newState': array([0.6913839], dtype=float32), 'info': {'arrival': 0.6913838949603561}}\n",
      "new state: [0.37352088]\n",
      "old state: [0.6913839]\n",
      "{'iter': 1, 'episode': 55, 'step': 3, 'oldState': array([0.6913839], dtype=float32), 'action': array([0.98094386], dtype=float32), 'reward': -0.5279572010040283, 'newState': array([0.37352088], dtype=float32), 'info': {'arrival': 0.3735208711927796}}\n",
      "new state: [0.69146985]\n",
      "old state: [0.37352088]\n",
      "{'iter': 1, 'episode': 55, 'step': 4, 'oldState': array([0.37352088], dtype=float32), 'action': array([0.6513576], dtype=float32), 'reward': -0.09954337030649185, 'newState': array([0.69146985], dtype=float32), 'info': {'arrival': 0.6914698584127786}}\n",
      "new state: [0.6058537]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 56, 'step': 0, 'oldState': array([0.]), 'action': array([0.25853062], dtype=float32), 'reward': -0.32512494921684265, 'newState': array([0.6058537], dtype=float32), 'info': {'arrival': 0.6058536558647543}}\n",
      "new state: [0.86228514]\n",
      "old state: [0.6058537]\n",
      "{'iter': 1, 'episode': 56, 'step': 1, 'oldState': array([0.6058537], dtype=float32), 'action': array([0.31664437], dtype=float32), 'reward': -0.48153290152549744, 'newState': array([0.86228514], dtype=float32), 'info': {'arrival': 0.8622851601819508}}\n",
      "new state: [0.4929963]\n",
      "old state: [0.86228514]\n",
      "{'iter': 1, 'episode': 56, 'step': 2, 'oldState': array([0.86228514], dtype=float32), 'action': array([0.89309746], dtype=float32), 'reward': -0.3077789470553398, 'newState': array([0.4929963], dtype=float32), 'info': {'arrival': 0.4929962953959866}}\n",
      "new state: [0.8901081]\n",
      "old state: [0.4929963]\n",
      "{'iter': 1, 'episode': 56, 'step': 3, 'oldState': array([0.4929963], dtype=float32), 'action': array([0.54588914], dtype=float32), 'reward': -0.2713874354958534, 'newState': array([0.8901081], dtype=float32), 'info': {'arrival': 0.8901081280273976}}\n",
      "new state: [0.58736694]\n",
      "old state: [0.8901081]\n",
      "{'iter': 1, 'episode': 56, 'step': 4, 'oldState': array([0.8901081], dtype=float32), 'action': array([0.4509262], dtype=float32), 'reward': -0.2121260166168213, 'newState': array([0.58736694], dtype=float32), 'info': {'arrival': 0.5873669240292118}}\n",
      "new state: [0.7448861]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 57, 'step': 0, 'oldState': array([0.]), 'action': array([0.94859546], dtype=float32), 'reward': -0.3899308890104294, 'newState': array([0.7448861], dtype=float32), 'info': {'arrival': 0.7448861016238103}}\n",
      "new state: [0.66510963]\n",
      "old state: [0.7448861]\n",
      "{'iter': 1, 'episode': 57, 'step': 1, 'oldState': array([0.7448861], dtype=float32), 'action': array([0.8201708], dtype=float32), 'reward': -0.1351170688867569, 'newState': array([0.66510963], dtype=float32), 'info': {'arrival': 0.6651096376328751}}\n",
      "new state: [0.7975816]\n",
      "old state: [0.66510963]\n",
      "{'iter': 1, 'episode': 57, 'step': 2, 'oldState': array([0.66510963], dtype=float32), 'action': array([0.14563169], dtype=float32), 'reward': -0.6188319474458694, 'newState': array([0.7975816], dtype=float32), 'info': {'arrival': 0.7975816143065679}}\n",
      "new state: [0.7087867]\n",
      "old state: [0.7975816]\n",
      "{'iter': 1, 'episode': 57, 'step': 3, 'oldState': array([0.7975816], dtype=float32), 'action': array([0.42647526], dtype=float32), 'reward': -0.3045101910829544, 'newState': array([0.7087867], dtype=float32), 'info': {'arrival': 0.7087867275232504}}\n",
      "new state: [0.553255]\n",
      "old state: [0.7087867]\n",
      "{'iter': 1, 'episode': 57, 'step': 4, 'oldState': array([0.7087867], dtype=float32), 'action': array([0.07041294], dtype=float32), 'reward': -0.5217250138521194, 'newState': array([0.553255], dtype=float32), 'info': {'arrival': 0.5532550152231178}}\n",
      "new state: [0.6124329]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 58, 'step': 0, 'oldState': array([0.]), 'action': array([0.7670551], dtype=float32), 'reward': -0.30773042142391205, 'newState': array([0.6124329], dtype=float32), 'info': {'arrival': 0.6124328697003623}}\n",
      "new state: [0.6471119]\n",
      "old state: [0.6124329]\n",
      "{'iter': 1, 'episode': 58, 'step': 1, 'oldState': array([0.6124329], dtype=float32), 'action': array([0.94939333], dtype=float32), 'reward': -0.31095118820667267, 'newState': array([0.6471119], dtype=float32), 'info': {'arrival': 0.6471119079346058}}\n",
      "new state: [0.7420556]\n",
      "old state: [0.6471119]\n",
      "{'iter': 1, 'episode': 58, 'step': 2, 'oldState': array([0.6471119], dtype=float32), 'action': array([0.67907774], dtype=float32), 'reward': -0.05522485077381134, 'newState': array([0.7420556], dtype=float32), 'info': {'arrival': 0.7420556100017108}}\n",
      "new state: [0.7632149]\n",
      "old state: [0.7420556]\n",
      "{'iter': 1, 'episode': 58, 'step': 3, 'oldState': array([0.7420556], dtype=float32), 'action': array([0.78856146], dtype=float32), 'reward': -0.03063639998435974, 'newState': array([0.7632149], dtype=float32), 'info': {'arrival': 0.7632148763695924}}\n",
      "new state: [0.9389314]\n",
      "old state: [0.7632149]\n",
      "{'iter': 1, 'episode': 58, 'step': 4, 'oldState': array([0.7632149], dtype=float32), 'action': array([0.7136034], dtype=float32), 'reward': -0.1813988983631134, 'newState': array([0.9389314], dtype=float32), 'info': {'arrival': 0.9389314036008539}}\n",
      "new state: [0.8511962]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 59, 'step': 0, 'oldState': array([0.]), 'action': array([0.11474632], dtype=float32), 'reward': -0.5810240041464567, 'newState': array([0.8511962], dtype=float32), 'info': {'arrival': 0.8511962487150252}}\n",
      "new state: [0.94405067]\n",
      "old state: [0.8511962]\n",
      "{'iter': 1, 'episode': 59, 'step': 1, 'oldState': array([0.8511962], dtype=float32), 'action': array([0.9163046], dtype=float32), 'reward': -0.03708665072917938, 'newState': array([0.94405067], dtype=float32), 'info': {'arrival': 0.9440506641404681}}\n",
      "new state: [0.9505466]\n",
      "old state: [0.94405067]\n",
      "{'iter': 1, 'episode': 59, 'step': 2, 'oldState': array([0.94405067], dtype=float32), 'action': array([0.6854246], dtype=float32), 'reward': -0.2634980082511902, 'newState': array([0.9505466], dtype=float32), 'info': {'arrival': 0.9505466199062584}}\n",
      "new state: [0.8178964]\n",
      "old state: [0.9505466]\n",
      "{'iter': 1, 'episode': 59, 'step': 3, 'oldState': array([0.9505466], dtype=float32), 'action': array([0.07694978], dtype=float32), 'reward': -0.7741091996431351, 'newState': array([0.8178964], dtype=float32), 'info': {'arrival': 0.8178964231266174}}\n",
      "new state: [0.6015288]\n",
      "old state: [0.8178964]\n",
      "{'iter': 1, 'episode': 59, 'step': 4, 'oldState': array([0.8178964], dtype=float32), 'action': array([0.2685982], dtype=float32), 'reward': -0.3870225250720978, 'newState': array([0.6015288], dtype=float32), 'info': {'arrival': 0.6015288072715756}}\n",
      "new state: [0.79381967]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 60, 'step': 0, 'oldState': array([0.]), 'action': array([0.6090885], dtype=float32), 'reward': -0.29082050919532776, 'newState': array([0.79381967], dtype=float32), 'info': {'arrival': 0.7938196437787505}}\n",
      "new state: [0.7518574]\n",
      "old state: [0.79381967]\n",
      "{'iter': 1, 'episode': 60, 'step': 1, 'oldState': array([0.79381967], dtype=float32), 'action': array([0.00401651], dtype=float32), 'reward': -0.7583314478397369, 'newState': array([0.7518574], dtype=float32), 'info': {'arrival': 0.7518573969824408}}\n",
      "new state: [0.7866965]\n",
      "old state: [0.7518574]\n",
      "{'iter': 1, 'episode': 60, 'step': 2, 'oldState': array([0.7518574], dtype=float32), 'action': array([0.5101884], dtype=float32), 'reward': -0.2677983194589615, 'newState': array([0.7866965], dtype=float32), 'info': {'arrival': 0.7866964704073606}}\n",
      "new state: [0.8915684]\n",
      "old state: [0.7866965]\n",
      "{'iter': 1, 'episode': 60, 'step': 3, 'oldState': array([0.7866965], dtype=float32), 'action': array([0.26020804], dtype=float32), 'reward': -0.6051424145698547, 'newState': array([0.8915684], dtype=float32), 'info': {'arrival': 0.891568425230863}}\n",
      "new state: [0.798451]\n",
      "old state: [0.8915684]\n",
      "{'iter': 1, 'episode': 60, 'step': 4, 'oldState': array([0.8915684], dtype=float32), 'action': array([0.7903628], dtype=float32), 'reward': -0.03136758506298065, 'newState': array([0.798451], dtype=float32), 'info': {'arrival': 0.7984510280070869}}\n",
      "new state: [0.91757727]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 61, 'step': 0, 'oldState': array([0.]), 'action': array([0.08498138], dtype=float32), 'reward': -0.6456922590732574, 'newState': array([0.91757727], dtype=float32), 'info': {'arrival': 0.9175772539501874}}\n",
      "new state: [0.6167802]\n",
      "old state: [0.91757727]\n",
      "{'iter': 1, 'episode': 61, 'step': 1, 'oldState': array([0.91757727], dtype=float32), 'action': array([0.20750925], dtype=float32), 'reward': -0.4844702258706093, 'newState': array([0.6167802], dtype=float32), 'info': {'arrival': 0.6167802062845245}}\n",
      "new state: [0.8237286]\n",
      "old state: [0.6167802]\n",
      "{'iter': 1, 'episode': 61, 'step': 2, 'oldState': array([0.6167802], dtype=float32), 'action': array([0.29624245], dtype=float32), 'reward': -0.47574909776449203, 'newState': array([0.8237286], dtype=float32), 'info': {'arrival': 0.8237286041270968}}\n",
      "new state: [0.6920042]\n",
      "old state: [0.8237286]\n",
      "{'iter': 1, 'episode': 61, 'step': 3, 'oldState': array([0.8237286], dtype=float32), 'action': array([0.09413433], dtype=float32), 'reward': -0.6308009773492813, 'newState': array([0.6920042], dtype=float32), 'info': {'arrival': 0.6920041845365899}}\n",
      "new state: [0.81518763]\n",
      "old state: [0.6920042]\n",
      "{'iter': 1, 'episode': 61, 'step': 4, 'oldState': array([0.6920042], dtype=float32), 'action': array([0.3739288], dtype=float32), 'reward': -0.41046299040317535, 'newState': array([0.81518763], dtype=float32), 'info': {'arrival': 0.8151876205812993}}\n",
      "new state: [0.4170331]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 62, 'step': 0, 'oldState': array([0.]), 'action': array([0.14843667], dtype=float32), 'reward': -0.23855649679899216, 'newState': array([0.4170331], dtype=float32), 'info': {'arrival': 0.4170330919313315}}\n",
      "new state: [0.75830376]\n",
      "old state: [0.4170331]\n",
      "{'iter': 1, 'episode': 62, 'step': 1, 'oldState': array([0.4170331], dtype=float32), 'action': array([0.17677243], dtype=float32), 'reward': -0.4962136782705784, 'newState': array([0.75830376], dtype=float32), 'info': {'arrival': 0.7583037842317658}}\n",
      "new state: [0.8896539]\n",
      "old state: [0.75830376]\n",
      "{'iter': 1, 'episode': 62, 'step': 2, 'oldState': array([0.75830376], dtype=float32), 'action': array([0.86058295], dtype=float32), 'reward': -0.047373026609420776, 'newState': array([0.8896539], dtype=float32), 'info': {'arrival': 0.8896539488521126}}\n",
      "new state: [0.82268196]\n",
      "old state: [0.8896539]\n",
      "{'iter': 1, 'episode': 62, 'step': 3, 'oldState': array([0.8896539], dtype=float32), 'action': array([0.37657416], dtype=float32), 'reward': -0.46285079419612885, 'newState': array([0.82268196], dtype=float32), 'info': {'arrival': 0.8226819414196322}}\n",
      "new state: [0.61360264]\n",
      "old state: [0.82268196]\n",
      "{'iter': 1, 'episode': 62, 'step': 4, 'oldState': array([0.82268196], dtype=float32), 'action': array([0.7901361], dtype=float32), 'reward': -0.14053656160831451, 'newState': array([0.61360264], dtype=float32), 'info': {'arrival': 0.6136026293273463}}\n",
      "new state: [0.9194748]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 63, 'step': 0, 'oldState': array([0.]), 'action': array([0.65671074], dtype=float32), 'reward': -0.36125071346759796, 'newState': array([0.9194748], dtype=float32), 'info': {'arrival': 0.9194747775611907}}\n",
      "new state: [0.82924384]\n",
      "old state: [0.9194748]\n",
      "{'iter': 1, 'episode': 63, 'step': 1, 'oldState': array([0.9194748], dtype=float32), 'action': array([0.5183577], dtype=float32), 'reward': -0.33344388008117676, 'newState': array([0.82924384], dtype=float32), 'info': {'arrival': 0.8292438403693936}}\n",
      "new state: [0.56659675]\n",
      "old state: [0.82924384]\n",
      "{'iter': 1, 'episode': 63, 'step': 2, 'oldState': array([0.82924384], dtype=float32), 'action': array([0.06181621], dtype=float32), 'reward': -0.5704423040151596, 'newState': array([0.56659675], dtype=float32), 'info': {'arrival': 0.5665967719830702}}\n",
      "new state: [0.6452801]\n",
      "old state: [0.56659675]\n",
      "{'iter': 1, 'episode': 63, 'step': 3, 'oldState': array([0.56659675], dtype=float32), 'action': array([0.39102527], dtype=float32), 'reward': -0.2345840036869049, 'newState': array([0.6452801], dtype=float32), 'info': {'arrival': 0.6452800940905733}}\n",
      "new state: [0.8609676]\n",
      "old state: [0.6452801]\n",
      "{'iter': 1, 'episode': 63, 'step': 4, 'oldState': array([0.6452801], dtype=float32), 'action': array([0.00345266], dtype=float32), 'reward': -0.8035930544137955, 'newState': array([0.8609676], dtype=float32), 'info': {'arrival': 0.8609675657462281}}\n",
      "new state: [0.93441373]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 64, 'step': 0, 'oldState': array([0.]), 'action': array([0.35586128], dtype=float32), 'reward': -0.5228796824812889, 'newState': array([0.93441373], dtype=float32), 'info': {'arrival': 0.9344137217207186}}\n",
      "new state: [0.87310034]\n",
      "old state: [0.93441373]\n",
      "{'iter': 1, 'episode': 64, 'step': 1, 'oldState': array([0.93441373], dtype=float32), 'action': array([0.57032645], dtype=float32), 'reward': -0.31810224056243896, 'newState': array([0.87310034], dtype=float32), 'info': {'arrival': 0.8731003215250267}}\n",
      "new state: [0.6588299]\n",
      "old state: [0.87310034]\n",
      "{'iter': 1, 'episode': 64, 'step': 2, 'oldState': array([0.87310034], dtype=float32), 'action': array([0.45869887], dtype=float32), 'reward': -0.2536986619234085, 'newState': array([0.6588299], dtype=float32), 'info': {'arrival': 0.6588299428034802}}\n",
      "new state: [0.5953764]\n",
      "old state: [0.6588299]\n",
      "{'iter': 1, 'episode': 64, 'step': 3, 'oldState': array([0.6588299], dtype=float32), 'action': array([0.9186117], dtype=float32), 'reward': -0.30737194418907166, 'newState': array([0.5953764], dtype=float32), 'info': {'arrival': 0.5953763542735148}}\n",
      "new state: [0.68313783]\n",
      "old state: [0.5953764]\n",
      "{'iter': 1, 'episode': 64, 'step': 4, 'oldState': array([0.5953764], dtype=float32), 'action': array([0.8902385], dtype=float32), 'reward': -0.22904105484485626, 'newState': array([0.68313783], dtype=float32), 'info': {'arrival': 0.6831378225368899}}\n",
      "new state: [0.8404316]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 65, 'step': 0, 'oldState': array([0.]), 'action': array([0.2911348], dtype=float32), 'reward': -0.4847562536597252, 'newState': array([0.8404316], dtype=float32), 'info': {'arrival': 0.8404315929852623}}\n",
      "new state: [0.7348525]\n",
      "old state: [0.8404316]\n",
      "{'iter': 1, 'episode': 65, 'step': 1, 'oldState': array([0.8404316], dtype=float32), 'action': array([0.7781609], dtype=float32), 'reward': -0.04804898798465729, 'newState': array([0.7348525], dtype=float32), 'info': {'arrival': 0.7348524910078201}}\n",
      "new state: [0.67715514]\n",
      "old state: [0.7348525]\n",
      "{'iter': 1, 'episode': 65, 'step': 2, 'oldState': array([0.7348525], dtype=float32), 'action': array([0.70912874], dtype=float32), 'reward': -0.030411139130592346, 'newState': array([0.67715514], dtype=float32), 'info': {'arrival': 0.6771551525546343}}\n",
      "new state: [0.6666695]\n",
      "old state: [0.67715514]\n",
      "{'iter': 1, 'episode': 65, 'step': 3, 'oldState': array([0.67715514], dtype=float32), 'action': array([0.35560632], dtype=float32), 'reward': -0.3136845827102661, 'newState': array([0.6666695], dtype=float32), 'info': {'arrival': 0.6666695008722308}}\n",
      "new state: [0.7484826]\n",
      "old state: [0.6666695]\n",
      "{'iter': 1, 'episode': 65, 'step': 4, 'oldState': array([0.6666695], dtype=float32), 'action': array([0.4927279], dtype=float32), 'reward': -0.2353014051914215, 'newState': array([0.7484826], dtype=float32), 'info': {'arrival': 0.748482585052599}}\n",
      "new state: [0.7962951]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 66, 'step': 0, 'oldState': array([0.]), 'action': array([0.5509566], dtype=float32), 'reward': -0.32174302637577057, 'newState': array([0.7962951], dtype=float32), 'info': {'arrival': 0.7962951231476743}}\n",
      "new state: [0.37607977]\n",
      "old state: [0.7962951]\n",
      "{'iter': 1, 'episode': 66, 'step': 1, 'oldState': array([0.7962951], dtype=float32), 'action': array([0.02107402], dtype=float32), 'reward': -0.46005958318710327, 'newState': array([0.37607977], dtype=float32), 'info': {'arrival': 0.3760797641512756}}\n",
      "new state: [0.5482966]\n",
      "old state: [0.37607977]\n",
      "{'iter': 1, 'episode': 66, 'step': 2, 'oldState': array([0.37607977], dtype=float32), 'action': array([0.75401884], dtype=float32), 'reward': -0.24877647310495377, 'newState': array([0.5482966], dtype=float32), 'info': {'arrival': 0.5482965896786841}}\n",
      "new state: [0.83947724]\n",
      "old state: [0.5482966]\n",
      "{'iter': 1, 'episode': 66, 'step': 3, 'oldState': array([0.5482966], dtype=float32), 'action': array([0.70128506], dtype=float32), 'reward': -0.1418912559747696, 'newState': array([0.83947724], dtype=float32), 'info': {'arrival': 0.8394772558305329}}\n",
      "new state: [0.629209]\n",
      "old state: [0.83947724]\n",
      "{'iter': 1, 'episode': 66, 'step': 4, 'oldState': array([0.83947724], dtype=float32), 'action': array([0.22162646], dtype=float32), 'reward': -0.4601495862007141, 'newState': array([0.629209], dtype=float32), 'info': {'arrival': 0.6292089688338618}}\n",
      "new state: [0.9066166]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 67, 'step': 0, 'oldState': array([0.]), 'action': array([0.37348884], dtype=float32), 'reward': -0.4932180494070053, 'newState': array([0.9066166], dtype=float32), 'info': {'arrival': 0.9066166437125958}}\n",
      "new state: [0.7919995]\n",
      "old state: [0.9066166]\n",
      "{'iter': 1, 'episode': 67, 'step': 1, 'oldState': array([0.9066166], dtype=float32), 'action': array([0.9540001], dtype=float32), 'reward': -0.1333463191986084, 'newState': array([0.7919995], dtype=float32), 'info': {'arrival': 0.7919995016432341}}\n",
      "new state: [0.697742]\n",
      "old state: [0.7919995]\n",
      "{'iter': 1, 'episode': 67, 'step': 2, 'oldState': array([0.7919995], dtype=float32), 'action': array([0.25302312], dtype=float32), 'reward': -0.4682832583785057, 'newState': array([0.697742], dtype=float32), 'info': {'arrival': 0.6977419790384347}}\n",
      "new state: [0.76970726]\n",
      "old state: [0.697742]\n",
      "{'iter': 1, 'episode': 67, 'step': 3, 'oldState': array([0.697742], dtype=float32), 'action': array([0.53634065], dtype=float32), 'reward': -0.21537528932094574, 'newState': array([0.76970726], dtype=float32), 'info': {'arrival': 0.7697072549742019}}\n",
      "new state: [0.2726862]\n",
      "old state: [0.76970726]\n",
      "{'iter': 1, 'episode': 67, 'step': 4, 'oldState': array([0.76970726], dtype=float32), 'action': array([0.8567207], dtype=float32), 'reward': -0.45977918803691864, 'newState': array([0.2726862], dtype=float32), 'info': {'arrival': 0.27268620309460134}}\n",
      "new state: [0.74976987]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 68, 'step': 0, 'oldState': array([0.]), 'action': array([0.6793964], dtype=float32), 'reward': -0.22262920439243317, 'newState': array([0.74976987], dtype=float32), 'info': {'arrival': 0.7497698703991033}}\n",
      "new state: [0.6641755]\n",
      "old state: [0.74976987]\n",
      "{'iter': 1, 'episode': 68, 'step': 1, 'oldState': array([0.74976987], dtype=float32), 'action': array([0.71820647], dtype=float32), 'reward': -0.048414066433906555, 'newState': array([0.6641755], dtype=float32), 'info': {'arrival': 0.6641755332782626}}\n",
      "new state: [0.85569066]\n",
      "old state: [0.6641755]\n",
      "{'iter': 1, 'episode': 68, 'step': 2, 'oldState': array([0.6641755], dtype=float32), 'action': array([0.49682295], dtype=float32), 'reward': -0.3109889179468155, 'newState': array([0.85569066], dtype=float32), 'info': {'arrival': 0.8556906630682534}}\n",
      "new state: [0.90007824]\n",
      "old state: [0.85569066]\n",
      "{'iter': 1, 'episode': 68, 'step': 3, 'oldState': array([0.85569066], dtype=float32), 'action': array([0.6041874], dtype=float32), 'reward': -0.2847939133644104, 'newState': array([0.90007824], dtype=float32), 'info': {'arrival': 0.9000782596903741}}\n",
      "new state: [0.7095617]\n",
      "old state: [0.90007824]\n",
      "{'iter': 1, 'episode': 68, 'step': 4, 'oldState': array([0.90007824], dtype=float32), 'action': array([0.9903221], dtype=float32), 'reward': -0.2331312745809555, 'newState': array([0.7095617], dtype=float32), 'info': {'arrival': 0.7095617096659708}}\n",
      "new state: [0.58918417]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 69, 'step': 0, 'oldState': array([0.]), 'action': array([0.21256195], dtype=float32), 'reward': -0.3356071375310421, 'newState': array([0.58918417], dtype=float32), 'info': {'arrival': 0.5891841756095736}}\n",
      "new state: [0.78040946]\n",
      "old state: [0.58918417]\n",
      "{'iter': 1, 'episode': 69, 'step': 1, 'oldState': array([0.58918417], dtype=float32), 'action': array([0.67926985], dtype=float32), 'reward': -0.09837612509727478, 'newState': array([0.78040946], dtype=float32), 'info': {'arrival': 0.7804094411627213}}\n",
      "new state: [0.67123526]\n",
      "old state: [0.78040946]\n",
      "{'iter': 1, 'episode': 69, 'step': 2, 'oldState': array([0.78040946], dtype=float32), 'action': array([0.32577753], dtype=float32), 'reward': -0.37275128066539764, 'newState': array([0.67123526], dtype=float32), 'info': {'arrival': 0.6712352516703225}}\n",
      "new state: [0.8469489]\n",
      "old state: [0.67123526]\n",
      "{'iter': 1, 'episode': 69, 'step': 3, 'oldState': array([0.67123526], dtype=float32), 'action': array([0.23902729], dtype=float32), 'reward': -0.5639931932091713, 'newState': array([0.8469489], dtype=float32), 'info': {'arrival': 0.8469489353788692}}\n",
      "new state: [0.9954696]\n",
      "old state: [0.8469489]\n",
      "{'iter': 1, 'episode': 69, 'step': 4, 'oldState': array([0.8469489], dtype=float32), 'action': array([0.6829146], dtype=float32), 'reward': -0.2754248380661011, 'newState': array([0.9954696], dtype=float32), 'info': {'arrival': 0.995469658179832}}\n",
      "new state: [0.6923749]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 70, 'step': 0, 'oldState': array([0.]), 'action': array([0.6589955], dtype=float32), 'reward': -0.18978340923786163, 'newState': array([0.6923749], dtype=float32), 'info': {'arrival': 0.6923749068176522}}\n",
      "new state: [0.83886343]\n",
      "old state: [0.6923749]\n",
      "{'iter': 1, 'episode': 70, 'step': 1, 'oldState': array([0.6923749], dtype=float32), 'action': array([0.07465999], dtype=float32), 'reward': -0.7275812923908234, 'newState': array([0.83886343], dtype=float32), 'info': {'arrival': 0.8388634384807063}}\n",
      "new state: [0.6277871]\n",
      "old state: [0.83886343]\n",
      "{'iter': 1, 'episode': 70, 'step': 2, 'oldState': array([0.83886343], dtype=float32), 'action': array([0.8111436], dtype=float32), 'reward': -0.14444731175899506, 'newState': array([0.6277871], dtype=float32), 'info': {'arrival': 0.6277871137267494}}\n",
      "new state: [0.7564455]\n",
      "old state: [0.6277871]\n",
      "{'iter': 1, 'episode': 70, 'step': 3, 'oldState': array([0.6277871], dtype=float32), 'action': array([0.9200555], dtype=float32), 'reward': -0.19577458500862122, 'newState': array([0.7564455], dtype=float32), 'info': {'arrival': 0.7564455516981486}}\n",
      "new state: [0.8844778]\n",
      "old state: [0.7564455]\n",
      "{'iter': 1, 'episode': 70, 'step': 4, 'oldState': array([0.7564455], dtype=float32), 'action': array([0.09264527], dtype=float32), 'reward': -0.7598244398832321, 'newState': array([0.8844778], dtype=float32), 'info': {'arrival': 0.8844777678740936}}\n",
      "new state: [0.8697868]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 71, 'step': 0, 'oldState': array([0.]), 'action': array([0.94684553], dtype=float32), 'reward': -0.29450543224811554, 'newState': array([0.8697868], dtype=float32), 'info': {'arrival': 0.8697867972696359}}\n",
      "new state: [0.6720896]\n",
      "old state: [0.8697868]\n",
      "{'iter': 1, 'episode': 71, 'step': 1, 'oldState': array([0.8697868], dtype=float32), 'action': array([0.23014472], dtype=float32), 'reward': -0.4913691431283951, 'newState': array([0.6720896], dtype=float32), 'info': {'arrival': 0.6720895872492367}}\n",
      "new state: [0.62414277]\n",
      "old state: [0.6720896]\n",
      "{'iter': 1, 'episode': 71, 'step': 2, 'oldState': array([0.6720896], dtype=float32), 'action': array([0.9266893], dtype=float32), 'reward': -0.290559858083725, 'newState': array([0.62414277], dtype=float32), 'info': {'arrival': 0.6241427562256475}}\n",
      "new state: [0.85992986]\n",
      "old state: [0.62414277]\n",
      "{'iter': 1, 'episode': 71, 'step': 3, 'oldState': array([0.62414277], dtype=float32), 'action': array([0.24221928], dtype=float32), 'reward': -0.5587638169527054, 'newState': array([0.85992986], dtype=float32), 'info': {'arrival': 0.8599298436739196}}\n",
      "new state: [0.59034026]\n",
      "old state: [0.85992986]\n",
      "{'iter': 1, 'episode': 71, 'step': 4, 'oldState': array([0.85992986], dtype=float32), 'action': array([0.8270643], dtype=float32), 'reward': -0.18575941026210785, 'newState': array([0.59034026], dtype=float32), 'info': {'arrival': 0.5903402832726137}}\n",
      "new state: [0.5314812]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 72, 'step': 0, 'oldState': array([0.]), 'action': array([0.56228995], dtype=float32), 'reward': -0.16367904841899872, 'newState': array([0.5314812], dtype=float32), 'info': {'arrival': 0.5314811950648776}}\n",
      "new state: [0.8403757]\n",
      "old state: [0.5314812]\n",
      "{'iter': 1, 'episode': 72, 'step': 1, 'oldState': array([0.5314812], dtype=float32), 'action': array([0.9571167], dtype=float32), 'reward': -0.1939646303653717, 'newState': array([0.8403757], dtype=float32), 'info': {'arrival': 0.8403757416403373}}\n",
      "new state: [0.795441]\n",
      "old state: [0.8403757]\n",
      "{'iter': 1, 'episode': 72, 'step': 2, 'oldState': array([0.8403757], dtype=float32), 'action': array([0.8063347], dtype=float32), 'reward': -0.016680538654327393, 'newState': array([0.795441], dtype=float32), 'info': {'arrival': 0.7954409697681185}}\n",
      "new state: [0.9944988]\n",
      "old state: [0.795441]\n",
      "{'iter': 1, 'episode': 72, 'step': 3, 'oldState': array([0.795441], dtype=float32), 'action': array([0.41794175], dtype=float32), 'reward': -0.526792585849762, 'newState': array([0.9944988], dtype=float32), 'info': {'arrival': 0.9944988171194186}}\n",
      "new state: [0.81816363]\n",
      "old state: [0.9944988]\n",
      "{'iter': 1, 'episode': 72, 'step': 4, 'oldState': array([0.9944988], dtype=float32), 'action': array([0.9343638], dtype=float32), 'reward': -0.10218386352062225, 'newState': array([0.81816363], dtype=float32), 'info': {'arrival': 0.8181636080642489}}\n",
      "new state: [0.7482123]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 73, 'step': 0, 'oldState': array([0.]), 'action': array([0.8481905], dtype=float32), 'reward': -0.28703127801418304, 'newState': array([0.7482123], dtype=float32), 'info': {'arrival': 0.7482122664429931}}\n",
      "new state: [0.77635175]\n",
      "old state: [0.7482123]\n",
      "{'iter': 1, 'episode': 73, 'step': 1, 'oldState': array([0.7482123], dtype=float32), 'action': array([0.44557565], dtype=float32), 'reward': -0.32374122738838196, 'newState': array([0.77635175], dtype=float32), 'info': {'arrival': 0.7763517378587463}}\n",
      "new state: [0.50380534]\n",
      "old state: [0.77635175]\n",
      "{'iter': 1, 'episode': 73, 'step': 2, 'oldState': array([0.77635175], dtype=float32), 'action': array([0.365306], dtype=float32), 'reward': -0.2066359519958496, 'newState': array([0.50380534], dtype=float32), 'info': {'arrival': 0.5038053365614329}}\n",
      "new state: [0.6313679]\n",
      "old state: [0.50380534]\n",
      "{'iter': 1, 'episode': 73, 'step': 3, 'oldState': array([0.50380534], dtype=float32), 'action': array([0.6171189], dtype=float32), 'reward': -0.039015159010887146, 'newState': array([0.6313679], dtype=float32), 'info': {'arrival': 0.6313679471627568}}\n",
      "new state: [0.8961404]\n",
      "old state: [0.6313679]\n",
      "{'iter': 1, 'episode': 73, 'step': 4, 'oldState': array([0.6313679], dtype=float32), 'action': array([0.47209603], dtype=float32), 'reward': -0.3578512519598007, 'newState': array([0.8961404], dtype=float32), 'info': {'arrival': 0.8961404131686851}}\n",
      "new state: [0.83162946]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 74, 'step': 0, 'oldState': array([0.]), 'action': array([0.04727396], dtype=float32), 'reward': -0.600085130892694, 'newState': array([0.83162946], dtype=float32), 'info': {'arrival': 0.8316294493145759}}\n",
      "new state: [0.7803869]\n",
      "old state: [0.83162946]\n",
      "{'iter': 1, 'episode': 74, 'step': 1, 'oldState': array([0.83162946], dtype=float32), 'action': array([0.42722648], dtype=float32), 'reward': -0.36597107350826263, 'newState': array([0.7803869], dtype=float32), 'info': {'arrival': 0.7803868959540701}}\n",
      "new state: [0.89854014]\n",
      "old state: [0.7803869]\n",
      "{'iter': 1, 'episode': 74, 'step': 2, 'oldState': array([0.7803869], dtype=float32), 'action': array([0.4168654], dtype=float32), 'reward': -0.45213642716407776, 'newState': array([0.89854014], dtype=float32), 'info': {'arrival': 0.8985401307985902}}\n",
      "new state: [0.47400478]\n",
      "old state: [0.89854014]\n",
      "{'iter': 1, 'episode': 74, 'step': 3, 'oldState': array([0.89854014], dtype=float32), 'action': array([0.68562263], dtype=float32), 'reward': -0.21194276958703995, 'newState': array([0.47400478], dtype=float32), 'info': {'arrival': 0.47400477016838993}}\n",
      "new state: [0.6596426]\n",
      "old state: [0.47400478]\n",
      "{'iter': 1, 'episode': 74, 'step': 4, 'oldState': array([0.47400478], dtype=float32), 'action': array([0.76792115], dtype=float32), 'reward': -0.1546880230307579, 'newState': array([0.6596426], dtype=float32), 'info': {'arrival': 0.6596425869696418}}\n",
      "new state: [0.6275026]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 75, 'step': 0, 'oldState': array([0.]), 'action': array([0.99257326], dtype=float32), 'reward': -0.5219462960958481, 'newState': array([0.6275026], dtype=float32), 'info': {'arrival': 0.6275026010821451}}\n",
      "new state: [0.81207603]\n",
      "old state: [0.6275026]\n",
      "{'iter': 1, 'episode': 75, 'step': 1, 'oldState': array([0.6275026], dtype=float32), 'action': array([0.58303154], dtype=float32), 'reward': -0.18290114402770996, 'newState': array([0.81207603], dtype=float32), 'info': {'arrival': 0.8120760453208351}}\n",
      "new state: [0.8674381]\n",
      "old state: [0.81207603]\n",
      "{'iter': 1, 'episode': 75, 'step': 2, 'oldState': array([0.81207603], dtype=float32), 'action': array([0.0351333], dtype=float32), 'reward': -0.8184642642736435, 'newState': array([0.8674381], dtype=float32), 'info': {'arrival': 0.8674380933685082}}\n",
      "new state: [0.72444516]\n",
      "old state: [0.8674381]\n",
      "{'iter': 1, 'episode': 75, 'step': 3, 'oldState': array([0.8674381], dtype=float32), 'action': array([0.20382348], dtype=float32), 'reward': -0.5563699007034302, 'newState': array([0.72444516], dtype=float32), 'info': {'arrival': 0.7244451611864137}}\n",
      "new state: [0.6931601]\n",
      "old state: [0.72444516]\n",
      "{'iter': 1, 'episode': 75, 'step': 4, 'oldState': array([0.72444516], dtype=float32), 'action': array([0.31761855], dtype=float32), 'reward': -0.3833628296852112, 'newState': array([0.6931601], dtype=float32), 'info': {'arrival': 0.6931600884173136}}\n",
      "new state: [0.9399452]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 76, 'step': 0, 'oldState': array([0.]), 'action': array([0.32068297], dtype=float32), 'reward': -0.5446174070239067, 'newState': array([0.9399452], dtype=float32), 'info': {'arrival': 0.9399452274411673}}\n",
      "new state: [0.8542191]\n",
      "old state: [0.9399452]\n",
      "{'iter': 1, 'episode': 76, 'step': 1, 'oldState': array([0.9399452], dtype=float32), 'action': array([0.3662904], dtype=float32), 'reward': -0.5093602240085602, 'newState': array([0.8542191], dtype=float32), 'info': {'arrival': 0.8542190725458864}}\n",
      "new state: [0.6321274]\n",
      "old state: [0.8542191]\n",
      "{'iter': 1, 'episode': 76, 'step': 2, 'oldState': array([0.8542191], dtype=float32), 'action': array([0.83115214], dtype=float32), 'reward': -0.15503528714179993, 'newState': array([0.6321274], dtype=float32), 'info': {'arrival': 0.6321273953649839}}\n",
      "new state: [0.3729915]\n",
      "old state: [0.6321274]\n",
      "{'iter': 1, 'episode': 76, 'step': 3, 'oldState': array([0.6321274], dtype=float32), 'action': array([0.8713536], dtype=float32), 'reward': -0.43357814848423004, 'newState': array([0.3729915], dtype=float32), 'info': {'arrival': 0.3729914877260021}}\n",
      "new state: [0.58367324]\n",
      "old state: [0.3729915]\n",
      "{'iter': 1, 'episode': 76, 'step': 4, 'oldState': array([0.3729915], dtype=float32), 'action': array([0.08171251], dtype=float32), 'reward': -0.44929031282663345, 'newState': array([0.58367324], dtype=float32), 'info': {'arrival': 0.5836732470401356}}\n",
      "new state: [0.8799005]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 77, 'step': 0, 'oldState': array([0.]), 'action': array([0.1048213], dtype=float32), 'reward': -0.6075147185474634, 'newState': array([0.8799005], dtype=float32), 'info': {'arrival': 0.8799005129893648}}\n",
      "new state: [0.9184922]\n",
      "old state: [0.8799005]\n",
      "{'iter': 1, 'episode': 77, 'step': 1, 'oldState': array([0.8799005], dtype=float32), 'action': array([0.27923965], dtype=float32), 'reward': -0.6296046227216721, 'newState': array([0.9184922], dtype=float32), 'info': {'arrival': 0.9184921978358173}}\n",
      "new state: [0.49138975]\n",
      "old state: [0.9184922]\n",
      "{'iter': 1, 'episode': 77, 'step': 2, 'oldState': array([0.9184922], dtype=float32), 'action': array([0.13193117], dtype=float32), 'reward': -0.4662341773509979, 'newState': array([0.49138975], dtype=float32), 'info': {'arrival': 0.49138974239554334}}\n",
      "new state: [0.95830184]\n",
      "old state: [0.49138975]\n",
      "{'iter': 1, 'episode': 77, 'step': 3, 'oldState': array([0.49138975], dtype=float32), 'action': array([0.46856657], dtype=float32), 'reward': -0.37300725281238556, 'newState': array([0.95830184], dtype=float32), 'info': {'arrival': 0.9583018607010674}}\n",
      "new state: [0.70179003]\n",
      "old state: [0.95830184]\n",
      "{'iter': 1, 'episode': 77, 'step': 4, 'oldState': array([0.95830184], dtype=float32), 'action': array([0.9228634], dtype=float32), 'reward': -0.17466464638710022, 'newState': array([0.70179003], dtype=float32), 'info': {'arrival': 0.7017900194195333}}\n",
      "new state: [0.5178697]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 78, 'step': 0, 'oldState': array([0.]), 'action': array([0.19296817], dtype=float32), 'reward': -0.29191818460822105, 'newState': array([0.5178697], dtype=float32), 'info': {'arrival': 0.5178697003228488}}\n",
      "new state: [0.9381719]\n",
      "old state: [0.5178697]\n",
      "{'iter': 1, 'episode': 78, 'step': 1, 'oldState': array([0.5178697], dtype=float32), 'action': array([0.4969714], dtype=float32), 'reward': -0.3361249715089798, 'newState': array([0.9381719], dtype=float32), 'info': {'arrival': 0.9381719026905131}}\n",
      "new state: [0.8895844]\n",
      "old state: [0.9381719]\n",
      "{'iter': 1, 'episode': 78, 'step': 2, 'oldState': array([0.9381719], dtype=float32), 'action': array([0.96241826], dtype=float32), 'reward': -0.06068696081638336, 'newState': array([0.8895844], dtype=float32), 'info': {'arrival': 0.8895844517767961}}\n",
      "new state: [0.7024367]\n",
      "old state: [0.8895844]\n",
      "{'iter': 1, 'episode': 78, 'step': 3, 'oldState': array([0.8895844], dtype=float32), 'action': array([0.2703251], dtype=float32), 'reward': -0.4788985326886177, 'newState': array([0.7024367], dtype=float32), 'info': {'arrival': 0.702436662561156}}\n",
      "new state: [0.9690932]\n",
      "old state: [0.7024367]\n",
      "{'iter': 1, 'episode': 78, 'step': 4, 'oldState': array([0.7024367], dtype=float32), 'action': array([0.22106688], dtype=float32), 'reward': -0.6813621819019318, 'newState': array([0.9690932], dtype=float32), 'info': {'arrival': 0.9690932313564409}}\n",
      "new state: [0.45809457]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 79, 'step': 0, 'oldState': array([0.]), 'action': array([0.55470604], dtype=float32), 'reward': -0.2111351117491722, 'newState': array([0.45809457], dtype=float32), 'info': {'arrival': 0.45809457382229046}}\n",
      "new state: [0.35976914]\n",
      "old state: [0.45809457]\n",
      "{'iter': 1, 'episode': 79, 'step': 1, 'oldState': array([0.45809457], dtype=float32), 'action': array([0.8634349], dtype=float32), 'reward': -0.47908443957567215, 'newState': array([0.35976914], dtype=float32), 'info': {'arrival': 0.35976913612813527}}\n",
      "new state: [0.47668418]\n",
      "old state: [0.35976914]\n",
      "{'iter': 1, 'episode': 79, 'step': 2, 'oldState': array([0.35976914], dtype=float32), 'action': array([0.4092275], dtype=float32), 'reward': -0.06295710802078247, 'newState': array([0.47668418], dtype=float32), 'info': {'arrival': 0.4766841792377771}}\n",
      "new state: [0.57604265]\n",
      "old state: [0.47668418]\n",
      "{'iter': 1, 'episode': 79, 'step': 3, 'oldState': array([0.47668418], dtype=float32), 'action': array([0.5806211], dtype=float32), 'reward': -0.029418088495731354, 'newState': array([0.57604265], dtype=float32), 'info': {'arrival': 0.5760426314304057}}\n",
      "new state: [0.57350785]\n",
      "old state: [0.57604265]\n",
      "{'iter': 1, 'episode': 79, 'step': 4, 'oldState': array([0.57604265], dtype=float32), 'action': array([0.10582049], dtype=float32), 'reward': -0.4683210700750351, 'newState': array([0.57350785], dtype=float32), 'info': {'arrival': 0.5735078665181202}}\n",
      "new state: [0.69979143]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 80, 'step': 0, 'oldState': array([0.]), 'action': array([0.60916924], dtype=float32), 'reward': -0.2202589511871338, 'newState': array([0.69979143], dtype=float32), 'info': {'arrival': 0.6997914247432339}}\n",
      "new state: [0.45895684]\n",
      "old state: [0.69979143]\n",
      "{'iter': 1, 'episode': 80, 'step': 1, 'oldState': array([0.69979143], dtype=float32), 'action': array([0.89770985], dtype=float32), 'reward': -0.3785443603992462, 'newState': array([0.45895684], dtype=float32), 'info': {'arrival': 0.458956827388649}}\n",
      "new state: [0.85829705]\n",
      "old state: [0.45895684]\n",
      "{'iter': 1, 'episode': 80, 'step': 2, 'oldState': array([0.45895684], dtype=float32), 'action': array([0.508336], dtype=float32), 'reward': -0.2748155742883682, 'newState': array([0.85829705], dtype=float32), 'info': {'arrival': 0.8582970744128859}}\n",
      "new state: [0.954837]\n",
      "old state: [0.85829705]\n",
      "{'iter': 1, 'episode': 80, 'step': 3, 'oldState': array([0.85829705], dtype=float32), 'action': array([0.63133687], dtype=float32), 'reward': -0.29936516284942627, 'newState': array([0.954837], dtype=float32), 'info': {'arrival': 0.95483699598248}}\n",
      "new state: [0.5311707]\n",
      "old state: [0.954837]\n",
      "{'iter': 1, 'episode': 80, 'step': 4, 'oldState': array([0.954837], dtype=float32), 'action': array([0.04958652], dtype=float32), 'reward': -0.5875007659196854, 'newState': array([0.5311707], dtype=float32), 'info': {'arrival': 0.5311707349742927}}\n",
      "new state: [0.6677523]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 81, 'step': 0, 'oldState': array([0.]), 'action': array([0.23614162], dtype=float32), 'reward': -0.3827434331178665, 'newState': array([0.6677523], dtype=float32), 'info': {'arrival': 0.6677523424665209}}\n",
      "new state: [0.7589142]\n",
      "old state: [0.6677523]\n",
      "{'iter': 1, 'episode': 81, 'step': 1, 'oldState': array([0.6677523], dtype=float32), 'action': array([0.12010847], dtype=float32), 'reward': -0.61601522564888, 'newState': array([0.7589142], dtype=float32), 'info': {'arrival': 0.7589141885461074}}\n",
      "new state: [0.9443521]\n",
      "old state: [0.7589142]\n",
      "{'iter': 1, 'episode': 81, 'step': 2, 'oldState': array([0.7589142], dtype=float32), 'action': array([0.50715166], dtype=float32), 'reward': -0.39084094762802124, 'newState': array([0.9443521], dtype=float32), 'info': {'arrival': 0.9443521153428295}}\n",
      "new state: [0.5562355]\n",
      "old state: [0.9443521]\n",
      "{'iter': 1, 'episode': 81, 'step': 3, 'oldState': array([0.9443521], dtype=float32), 'action': array([0.13787954], dtype=float32), 'reward': -0.515385091304779, 'newState': array([0.5562355], dtype=float32), 'info': {'arrival': 0.5562355158641346}}\n",
      "new state: [0.77747005]\n",
      "old state: [0.5562355]\n",
      "{'iter': 1, 'episode': 81, 'step': 4, 'oldState': array([0.5562355], dtype=float32), 'action': array([0.98143643], dtype=float32), 'reward': -0.25927501916885376, 'newState': array([0.77747005], dtype=float32), 'info': {'arrival': 0.7774700460479429}}\n",
      "new state: [0.84308743]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 82, 'step': 0, 'oldState': array([0.]), 'action': array([0.54359883], dtype=float32), 'reward': -0.36051616072654724, 'newState': array([0.84308743], dtype=float32), 'info': {'arrival': 0.8430874474900764}}\n",
      "new state: [0.9327469]\n",
      "old state: [0.84308743]\n",
      "{'iter': 1, 'episode': 82, 'step': 1, 'oldState': array([0.84308743], dtype=float32), 'action': array([0.48352024], dtype=float32), 'reward': -0.4268117845058441, 'newState': array([0.9327469], dtype=float32), 'info': {'arrival': 0.9327468975368629}}\n",
      "new state: [0.5528119]\n",
      "old state: [0.9327469]\n",
      "{'iter': 1, 'episode': 82, 'step': 2, 'oldState': array([0.9327469], dtype=float32), 'action': array([0.60764813], dtype=float32), 'reward': -0.12240184843540192, 'newState': array([0.5528119], dtype=float32), 'info': {'arrival': 0.5528119046688096}}\n",
      "new state: [0.8571652]\n",
      "old state: [0.5528119]\n",
      "{'iter': 1, 'episode': 82, 'step': 3, 'oldState': array([0.5528119], dtype=float32), 'action': array([0.9747786], dtype=float32), 'reward': -0.19370169937610626, 'newState': array([0.8571652], dtype=float32), 'info': {'arrival': 0.857165217589518}}\n",
      "new state: [0.28818196]\n",
      "old state: [0.8571652]\n",
      "{'iter': 1, 'episode': 82, 'step': 4, 'oldState': array([0.8571652], dtype=float32), 'action': array([0.24076757], dtype=float32), 'reward': -0.1896601989865303, 'newState': array([0.28818196], dtype=float32), 'info': {'arrival': 0.2881819672699525}}\n",
      "new state: [0.60212934]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 83, 'step': 0, 'oldState': array([0.]), 'action': array([0.7977171], dtype=float32), 'reward': -0.34612008929252625, 'newState': array([0.60212934], dtype=float32), 'info': {'arrival': 0.6021293592774877}}\n",
      "new state: [0.6141135]\n",
      "old state: [0.60212934]\n",
      "{'iter': 1, 'episode': 83, 'step': 1, 'oldState': array([0.60212934], dtype=float32), 'action': array([0.03830955], dtype=float32), 'reward': -0.5728078931570053, 'newState': array([0.6141135], dtype=float32), 'info': {'arrival': 0.6141134831011548}}\n",
      "new state: [0.6443499]\n",
      "old state: [0.6141135]\n",
      "{'iter': 1, 'episode': 83, 'step': 2, 'oldState': array([0.6141135], dtype=float32), 'action': array([0.38150203], dtype=float32), 'reward': -0.2552887499332428, 'newState': array([0.6443499], dtype=float32), 'info': {'arrival': 0.6443498777453904}}\n",
      "new state: [0.90838087]\n",
      "old state: [0.6443499]\n",
      "{'iter': 1, 'episode': 83, 'step': 3, 'oldState': array([0.6443499], dtype=float32), 'action': array([0.76324034], dtype=float32), 'reward': -0.13857801258563995, 'newState': array([0.90838087], dtype=float32), 'info': {'arrival': 0.908380839980258}}\n",
      "new state: [0.5491792]\n",
      "old state: [0.90838087]\n",
      "{'iter': 1, 'episode': 83, 'step': 4, 'oldState': array([0.90838087], dtype=float32), 'action': array([0.17642656], dtype=float32), 'reward': -0.46255306154489517, 'newState': array([0.5491792], dtype=float32), 'info': {'arrival': 0.5491791855338239}}\n",
      "new state: [0.24155372]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 84, 'step': 0, 'oldState': array([0.]), 'action': array([0.8325627], dtype=float32), 'reward': -0.6513973921537399, 'newState': array([0.24155372], dtype=float32), 'info': {'arrival': 0.24155372315013998}}\n",
      "new state: [0.906559]\n",
      "old state: [0.24155372]\n",
      "{'iter': 1, 'episode': 84, 'step': 1, 'oldState': array([0.24155372], dtype=float32), 'action': array([0.28463453], dtype=float32), 'reward': -0.4772135466337204, 'newState': array([0.906559], dtype=float32), 'info': {'arrival': 0.906558963682377}}\n",
      "new state: [0.786508]\n",
      "old state: [0.906559]\n",
      "{'iter': 1, 'episode': 84, 'step': 2, 'oldState': array([0.906559], dtype=float32), 'action': array([0.9969681], dtype=float32), 'reward': -0.18044732511043549, 'newState': array([0.786508], dtype=float32), 'info': {'arrival': 0.7865080175047816}}\n",
      "new state: [0.8306377]\n",
      "old state: [0.786508]\n",
      "{'iter': 1, 'episode': 84, 'step': 3, 'oldState': array([0.786508], dtype=float32), 'action': array([0.52199674], dtype=float32), 'reward': -0.29760853946208954, 'newState': array([0.8306377], dtype=float32), 'info': {'arrival': 0.8306377143418452}}\n",
      "new state: [0.7747229]\n",
      "old state: [0.8306377]\n",
      "{'iter': 1, 'episode': 84, 'step': 4, 'oldState': array([0.8306377], dtype=float32), 'action': array([0.02301413], dtype=float32), 'reward': -0.7656874507665634, 'newState': array([0.7747229], dtype=float32), 'info': {'arrival': 0.7747228600698355}}\n",
      "new state: [0.59209377]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 85, 'step': 0, 'oldState': array([0.]), 'action': array([0.98538417], dtype=float32), 'reward': -0.5413138419389725, 'newState': array([0.59209377], dtype=float32), 'info': {'arrival': 0.5920937841707378}}\n",
      "new state: [0.497338]\n",
      "old state: [0.59209377]\n",
      "{'iter': 1, 'episode': 85, 'step': 1, 'oldState': array([0.59209377], dtype=float32), 'action': array([0.8540286], dtype=float32), 'reward': -0.33300164341926575, 'newState': array([0.497338], dtype=float32), 'info': {'arrival': 0.49733799806971746}}\n",
      "new state: [0.48828003]\n",
      "old state: [0.497338]\n",
      "{'iter': 1, 'episode': 85, 'step': 2, 'oldState': array([0.497338], dtype=float32), 'action': array([0.35267907], dtype=float32), 'reward': -0.13786544650793076, 'newState': array([0.48828003], dtype=float32), 'info': {'arrival': 0.4882800191264927}}\n",
      "new state: [0.67369473]\n",
      "old state: [0.48828003]\n",
      "{'iter': 1, 'episode': 85, 'step': 3, 'oldState': array([0.48828003], dtype=float32), 'action': array([0.13897847], dtype=float32), 'reward': -0.488362580537796, 'newState': array([0.67369473], dtype=float32), 'info': {'arrival': 0.673694731764207}}\n",
      "new state: [0.84701455]\n",
      "old state: [0.67369473]\n",
      "{'iter': 1, 'episode': 85, 'step': 4, 'oldState': array([0.67369473], dtype=float32), 'action': array([0.65943325], dtype=float32), 'reward': -0.14425134658813477, 'newState': array([0.84701455], dtype=float32), 'info': {'arrival': 0.8470145235559442}}\n",
      "new state: [0.4612985]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 86, 'step': 0, 'oldState': array([0.]), 'action': array([0.639392], dtype=float32), 'reward': -0.29341814666986465, 'newState': array([0.4612985], dtype=float32), 'info': {'arrival': 0.46129848156896874}}\n",
      "new state: [0.8220117]\n",
      "old state: [0.4612985]\n",
      "{'iter': 1, 'episode': 86, 'step': 1, 'oldState': array([0.4612985], dtype=float32), 'action': array([0.06488743], dtype=float32), 'reward': -0.6669459939002991, 'newState': array([0.8220117], dtype=float32), 'info': {'arrival': 0.8220116934143843}}\n",
      "new state: [0.52331096]\n",
      "old state: [0.8220117]\n",
      "{'iter': 1, 'episode': 86, 'step': 2, 'oldState': array([0.8220117], dtype=float32), 'action': array([0.03486541], dtype=float32), 'reward': -0.5631207451224327, 'newState': array([0.52331096], dtype=float32), 'info': {'arrival': 0.5233109315381012}}\n",
      "new state: [0.69209284]\n",
      "old state: [0.52331096]\n",
      "{'iter': 1, 'episode': 86, 'step': 3, 'oldState': array([0.52331096], dtype=float32), 'action': array([0.13905658], dtype=float32), 'reward': -0.5108408033847809, 'newState': array([0.69209284], dtype=float32), 'info': {'arrival': 0.6920928144317595}}\n",
      "new state: [0.68540776]\n",
      "old state: [0.69209284]\n",
      "{'iter': 1, 'episode': 86, 'step': 4, 'oldState': array([0.69209284], dtype=float32), 'action': array([0.4144697], dtype=float32), 'reward': -0.27260933816432953, 'newState': array([0.68540776], dtype=float32), 'info': {'arrival': 0.6854077559553241}}\n",
      "new state: [0.9403655]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 87, 'step': 0, 'oldState': array([0.]), 'action': array([0.2614004], dtype=float32), 'reward': -0.5745739191770554, 'newState': array([0.9403655], dtype=float32), 'info': {'arrival': 0.9403654956787014}}\n",
      "new state: [0.8723894]\n",
      "old state: [0.9403655]\n",
      "{'iter': 1, 'episode': 87, 'step': 1, 'oldState': array([0.9403655], dtype=float32), 'action': array([0.5362272], dtype=float32), 'reward': -0.353156179189682, 'newState': array([0.8723894], dtype=float32), 'info': {'arrival': 0.872389372452745}}\n",
      "new state: [0.8498173]\n",
      "old state: [0.8723894]\n",
      "{'iter': 1, 'episode': 87, 'step': 2, 'oldState': array([0.8723894], dtype=float32), 'action': array([0.267857], dtype=float32), 'reward': -0.5876033306121826, 'newState': array([0.8498173], dtype=float32), 'info': {'arrival': 0.8498172841532163}}\n",
      "new state: [0.97444695]\n",
      "old state: [0.8498173]\n",
      "{'iter': 1, 'episode': 87, 'step': 3, 'oldState': array([0.8498173], dtype=float32), 'action': array([0.7701954], dtype=float32), 'reward': -0.17309410870075226, 'newState': array([0.97444695], dtype=float32), 'info': {'arrival': 0.9744469690876948}}\n",
      "new state: [0.5800539]\n",
      "old state: [0.97444695]\n",
      "{'iter': 1, 'episode': 87, 'step': 4, 'oldState': array([0.97444695], dtype=float32), 'action': array([0.21582103], dtype=float32), 'reward': -0.46283115446567535, 'newState': array([0.5800539], dtype=float32), 'info': {'arrival': 0.5800539376480711}}\n",
      "new state: [0.9066108]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 88, 'step': 0, 'oldState': array([0.]), 'action': array([0.454171], dtype=float32), 'reward': -0.4528725892305374, 'newState': array([0.9066108], dtype=float32), 'info': {'arrival': 0.9066107768629309}}\n",
      "new state: [0.45637348]\n",
      "old state: [0.9066108]\n",
      "{'iter': 1, 'episode': 88, 'step': 1, 'oldState': array([0.9066108], dtype=float32), 'action': array([0.75243115], dtype=float32), 'reward': -0.2605881616473198, 'newState': array([0.45637348], dtype=float32), 'info': {'arrival': 0.45637346968843767}}\n",
      "new state: [0.88734233]\n",
      "old state: [0.45637348]\n",
      "{'iter': 1, 'episode': 88, 'step': 2, 'oldState': array([0.45637348], dtype=float32), 'action': array([0.8322996], dtype=float32), 'reward': -0.1352635845541954, 'newState': array([0.88734233], dtype=float32), 'info': {'arrival': 0.8873423380390313}}\n",
      "new state: [0.54627734]\n",
      "old state: [0.88734233]\n",
      "{'iter': 1, 'episode': 88, 'step': 3, 'oldState': array([0.88734233], dtype=float32), 'action': array([0.8384352], dtype=float32), 'reward': -0.23134516179561615, 'newState': array([0.54627734], dtype=float32), 'info': {'arrival': 0.5462773719621609}}\n",
      "new state: [0.4438874]\n",
      "old state: [0.54627734]\n",
      "{'iter': 1, 'episode': 88, 'step': 4, 'oldState': array([0.54627734], dtype=float32), 'action': array([0.12923072], dtype=float32), 'reward': -0.34025415778160095, 'newState': array([0.4438874], dtype=float32), 'info': {'arrival': 0.4438874194818803}}\n",
      "new state: [0.6889342]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 89, 'step': 0, 'oldState': array([0.]), 'action': array([0.28845537], dtype=float32), 'reward': -0.37247297167778015, 'newState': array([0.6889342], dtype=float32), 'info': {'arrival': 0.6889341779457779}}\n",
      "new state: [0.8233892]\n",
      "old state: [0.6889342]\n",
      "{'iter': 1, 'episode': 89, 'step': 1, 'oldState': array([0.6889342], dtype=float32), 'action': array([0.4359773], dtype=float32), 'reward': -0.35379812121391296, 'newState': array([0.8233892], dtype=float32), 'info': {'arrival': 0.8233891872312568}}\n",
      "new state: [0.64066565]\n",
      "old state: [0.8233892]\n",
      "{'iter': 1, 'episode': 89, 'step': 2, 'oldState': array([0.8233892], dtype=float32), 'action': array([0.556595], dtype=float32), 'reward': -0.12975150346755981, 'newState': array([0.64066565], dtype=float32), 'info': {'arrival': 0.6406656377999287}}\n",
      "new state: [0.5249617]\n",
      "old state: [0.64066565]\n",
      "{'iter': 1, 'episode': 89, 'step': 3, 'oldState': array([0.64066565], dtype=float32), 'action': array([0.73947954], dtype=float32), 'reward': -0.18559184670448303, 'newState': array([0.5249617], dtype=float32), 'info': {'arrival': 0.524961689313965}}\n",
      "new state: [0.28750637]\n",
      "old state: [0.5249617]\n",
      "{'iter': 1, 'episode': 89, 'step': 4, 'oldState': array([0.5249617], dtype=float32), 'action': array([0.3000464], dtype=float32), 'reward': -0.0656338557600975, 'newState': array([0.28750637], dtype=float32), 'info': {'arrival': 0.28750637767958914}}\n",
      "new state: [0.66633934]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 90, 'step': 0, 'oldState': array([0.]), 'action': array([0.578317], dtype=float32), 'reward': -0.2105960100889206, 'newState': array([0.66633934], dtype=float32), 'info': {'arrival': 0.6663393193621396}}\n",
      "new state: [0.9792966]\n",
      "old state: [0.66633934]\n",
      "{'iter': 1, 'episode': 90, 'step': 1, 'oldState': array([0.66633934], dtype=float32), 'action': array([0.55502146], dtype=float32), 'reward': -0.34603583812713623, 'newState': array([0.9792966], dtype=float32), 'info': {'arrival': 0.9792966309446511}}\n",
      "new state: [0.71245235]\n",
      "old state: [0.9792966]\n",
      "{'iter': 1, 'episode': 90, 'step': 2, 'oldState': array([0.9792966], dtype=float32), 'action': array([0.1537158], dtype=float32), 'reward': -0.6254476308822632, 'newState': array([0.71245235], dtype=float32), 'info': {'arrival': 0.7124523367029733}}\n",
      "new state: [0.32053742]\n",
      "old state: [0.71245235]\n",
      "{'iter': 1, 'episode': 90, 'step': 3, 'oldState': array([0.71245235], dtype=float32), 'action': array([0.19027478], dtype=float32), 'reward': -0.22824137657880783, 'newState': array([0.32053742], dtype=float32), 'info': {'arrival': 0.3205374232565296}}\n",
      "new state: [0.7327752]\n",
      "old state: [0.32053742]\n",
      "{'iter': 1, 'episode': 90, 'step': 4, 'oldState': array([0.32053742], dtype=float32), 'action': array([0.37297276], dtype=float32), 'reward': -0.2829606756567955, 'newState': array([0.7327752], dtype=float32), 'info': {'arrival': 0.7327752309791808}}\n",
      "new state: [0.8048119]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 91, 'step': 0, 'oldState': array([0.]), 'action': array([0.12763996], dtype=float32), 'reward': -0.5397889502346516, 'newState': array([0.8048119], dtype=float32), 'info': {'arrival': 0.8048118981226664}}\n",
      "new state: [0.74118346]\n",
      "old state: [0.8048119]\n",
      "{'iter': 1, 'episode': 91, 'step': 1, 'oldState': array([0.8048119], dtype=float32), 'action': array([0.45399], dtype=float32), 'reward': -0.3031005561351776, 'newState': array([0.74118346], dtype=float32), 'info': {'arrival': 0.7411834589881447}}\n",
      "new state: [0.75181895]\n",
      "old state: [0.74118346]\n",
      "{'iter': 1, 'episode': 91, 'step': 2, 'oldState': array([0.74118346], dtype=float32), 'action': array([0.41613442], dtype=float32), 'reward': -0.33302566409111023, 'newState': array([0.75181895], dtype=float32), 'info': {'arrival': 0.7518189414696002}}\n",
      "new state: [0.83171636]\n",
      "old state: [0.75181895]\n",
      "{'iter': 1, 'episode': 91, 'step': 3, 'oldState': array([0.75181895], dtype=float32), 'action': array([0.04177415], dtype=float32), 'reward': -0.7699678540229797, 'newState': array([0.83171636], dtype=float32), 'info': {'arrival': 0.8317163722736604}}\n",
      "new state: [0.9532375]\n",
      "old state: [0.83171636]\n",
      "{'iter': 1, 'episode': 91, 'step': 4, 'oldState': array([0.83171636], dtype=float32), 'action': array([0.3208426], dtype=float32), 'reward': -0.6020146310329437, 'newState': array([0.9532375], dtype=float32), 'info': {'arrival': 0.9532374519129169}}\n",
      "new state: [0.59301513]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 92, 'step': 0, 'oldState': array([0.]), 'action': array([0.43633574], dtype=float32), 'reward': -0.226593479514122, 'newState': array([0.59301513], dtype=float32), 'info': {'arrival': 0.5930151277949716}}\n",
      "new state: [0.3954649]\n",
      "old state: [0.59301513]\n",
      "{'iter': 1, 'episode': 92, 'step': 1, 'oldState': array([0.59301513], dtype=float32), 'action': array([0.7625427], dtype=float32), 'reward': -0.31769026815891266, 'newState': array([0.3954649], dtype=float32), 'info': {'arrival': 0.3954648965735961}}\n",
      "new state: [0.83024174]\n",
      "old state: [0.3954649]\n",
      "{'iter': 1, 'episode': 92, 'step': 2, 'oldState': array([0.3954649], dtype=float32), 'action': array([0.26844487], dtype=float32), 'reward': -0.4531026855111122, 'newState': array([0.83024174], dtype=float32), 'info': {'arrival': 0.8302417263705617}}\n",
      "new state: [0.7017874]\n",
      "old state: [0.83024174]\n",
      "{'iter': 1, 'episode': 92, 'step': 3, 'oldState': array([0.83024174], dtype=float32), 'action': array([0.14352153], dtype=float32), 'reward': -0.5903794467449188, 'newState': array([0.7017874], dtype=float32), 'info': {'arrival': 0.70178738598395}}\n",
      "new state: [0.67042917]\n",
      "old state: [0.7017874]\n",
      "{'iter': 1, 'episode': 92, 'step': 4, 'oldState': array([0.7017874], dtype=float32), 'action': array([0.7237322], dtype=float32), 'reward': -0.0454634428024292, 'newState': array([0.67042917], dtype=float32), 'info': {'arrival': 0.6704291554903559}}\n",
      "new state: [0.67217886]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 93, 'step': 0, 'oldState': array([0.]), 'action': array([0.51011336], dtype=float32), 'reward': -0.2490774691104889, 'newState': array([0.67217886], dtype=float32), 'info': {'arrival': 0.6721788925604859}}\n",
      "new state: [0.9462746]\n",
      "old state: [0.67217886]\n",
      "{'iter': 1, 'episode': 93, 'step': 1, 'oldState': array([0.67217886], dtype=float32), 'action': array([0.10169694], dtype=float32), 'reward': -0.7760537266731262, 'newState': array([0.9462746], dtype=float32), 'info': {'arrival': 0.9462745762219489}}\n",
      "new state: [0.90082556]\n",
      "old state: [0.9462746]\n",
      "{'iter': 1, 'episode': 93, 'step': 2, 'oldState': array([0.9462746], dtype=float32), 'action': array([0.49594644], dtype=float32), 'reward': -0.4162413775920868, 'newState': array([0.90082556], dtype=float32), 'info': {'arrival': 0.900825563938641}}\n",
      "new state: [0.6685545]\n",
      "old state: [0.90082556]\n",
      "{'iter': 1, 'episode': 93, 'step': 3, 'oldState': array([0.90082556], dtype=float32), 'action': array([0.25195295], dtype=float32), 'reward': -0.47466930747032166, 'newState': array([0.6685545], dtype=float32), 'info': {'arrival': 0.6685544756928645}}\n",
      "new state: [0.68720526]\n",
      "old state: [0.6685545]\n",
      "{'iter': 1, 'episode': 93, 'step': 4, 'oldState': array([0.6685545], dtype=float32), 'action': array([0.66653925], dtype=float32), 'reward': -0.016003310680389404, 'newState': array([0.68720526], dtype=float32), 'info': {'arrival': 0.6872052582071272}}\n",
      "new state: [0.99052596]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 94, 'step': 0, 'oldState': array([0.]), 'action': array([0.7964593], dtype=float32), 'reward': -0.3446648120880127, 'newState': array([0.99052596], dtype=float32), 'info': {'arrival': 0.9905259619828488}}\n",
      "new state: [0.9690156]\n",
      "old state: [0.99052596]\n",
      "{'iter': 1, 'episode': 94, 'step': 1, 'oldState': array([0.99052596], dtype=float32), 'action': array([0.0810043], dtype=float32), 'reward': -0.8933888673782349, 'newState': array([0.9690156], dtype=float32), 'info': {'arrival': 0.9690156150854327}}\n",
      "new state: [0.5082614]\n",
      "old state: [0.9690156]\n",
      "{'iter': 1, 'episode': 94, 'step': 2, 'oldState': array([0.9690156], dtype=float32), 'action': array([0.77163154], dtype=float32), 'reward': -0.2468736320734024, 'newState': array([0.5082614], dtype=float32), 'info': {'arrival': 0.5082613561039655}}\n",
      "new state: [0.65188295]\n",
      "old state: [0.5082614]\n",
      "{'iter': 1, 'episode': 94, 'step': 3, 'oldState': array([0.5082614], dtype=float32), 'action': array([0.52703846], dtype=float32), 'reward': -0.09832763671875, 'newState': array([0.65188295], dtype=float32), 'info': {'arrival': 0.6518829206690373}}\n",
      "new state: [0.9152749]\n",
      "old state: [0.65188295]\n",
      "{'iter': 1, 'episode': 94, 'step': 4, 'oldState': array([0.65188295], dtype=float32), 'action': array([0.32164282], dtype=float32), 'reward': -0.5277841091156006, 'newState': array([0.9152749], dtype=float32), 'info': {'arrival': 0.9152749343159661}}\n",
      "new state: [0.8121299]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 95, 'step': 0, 'oldState': array([0.]), 'action': array([0.63796544], dtype=float32), 'reward': -0.29011471569538116, 'newState': array([0.8121299], dtype=float32), 'info': {'arrival': 0.8121299046812063}}\n",
      "new state: [0.7166742]\n",
      "old state: [0.8121299]\n",
      "{'iter': 1, 'episode': 95, 'step': 1, 'oldState': array([0.8121299], dtype=float32), 'action': array([0.01017157], dtype=float32), 'reward': -0.7303665429353714, 'newState': array([0.7166742], dtype=float32), 'info': {'arrival': 0.7166742182008666}}\n",
      "new state: [0.6233649]\n",
      "old state: [0.7166742]\n",
      "{'iter': 1, 'episode': 95, 'step': 2, 'oldState': array([0.7166742], dtype=float32), 'action': array([0.47110826], dtype=float32), 'reward': -0.17558398842811584, 'newState': array([0.6233649], dtype=float32), 'info': {'arrival': 0.6233649238140817}}\n",
      "new state: [0.81990844]\n",
      "old state: [0.6233649]\n",
      "{'iter': 1, 'episode': 95, 'step': 3, 'oldState': array([0.6233649], dtype=float32), 'action': array([0.48327416], dtype=float32), 'reward': -0.2874983996152878, 'newState': array([0.81990844], dtype=float32), 'info': {'arrival': 0.8199084171746013}}\n",
      "new state: [0.7813164]\n",
      "old state: [0.81990844]\n",
      "{'iter': 1, 'episode': 95, 'step': 4, 'oldState': array([0.81990844], dtype=float32), 'action': array([0.5440265], dtype=float32), 'reward': -0.24693791568279266, 'newState': array([0.7813164], dtype=float32), 'info': {'arrival': 0.7813164279576196}}\n",
      "new state: [0.6036665]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 96, 'step': 0, 'oldState': array([0.]), 'action': array([0.861626], dtype=float32), 'reward': -0.4088761657476425, 'newState': array([0.6036665], dtype=float32), 'info': {'arrival': 0.6036665132060357}}\n",
      "new state: [0.8104926]\n",
      "old state: [0.6036665]\n",
      "{'iter': 1, 'episode': 96, 'step': 1, 'oldState': array([0.6036665], dtype=float32), 'action': array([0.04402221], dtype=float32), 'reward': -0.7147638499736786, 'newState': array([0.8104926], dtype=float32), 'info': {'arrival': 0.8104925950699093}}\n",
      "new state: [0.66132826]\n",
      "old state: [0.8104926]\n",
      "{'iter': 1, 'episode': 96, 'step': 2, 'oldState': array([0.8104926], dtype=float32), 'action': array([0.15773296], dtype=float32), 'reward': -0.5408863723278046, 'newState': array([0.66132826], dtype=float32), 'info': {'arrival': 0.6613282461102857}}\n",
      "new state: [0.67576575]\n",
      "old state: [0.66132826]\n",
      "{'iter': 1, 'episode': 96, 'step': 3, 'oldState': array([0.66132826], dtype=float32), 'action': array([0.02407606], dtype=float32), 'reward': -0.6480803340673447, 'newState': array([0.67576575], dtype=float32), 'info': {'arrival': 0.6757657616878525}}\n",
      "new state: [0.64695984]\n",
      "old state: [0.67576575]\n",
      "{'iter': 1, 'episode': 96, 'step': 4, 'oldState': array([0.67576575], dtype=float32), 'action': array([0.6574123], dtype=float32), 'reward': -0.01242770254611969, 'newState': array([0.64695984], dtype=float32), 'info': {'arrival': 0.6469598209000885}}\n",
      "new state: [0.8904341]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 97, 'step': 0, 'oldState': array([0.]), 'action': array([0.718905], dtype=float32), 'reward': -0.3083730787038803, 'newState': array([0.8904341], dtype=float32), 'info': {'arrival': 0.8904341131092317}}\n",
      "new state: [0.9424535]\n",
      "old state: [0.8904341]\n",
      "{'iter': 1, 'episode': 97, 'step': 1, 'oldState': array([0.8904341], dtype=float32), 'action': array([0.8154901], dtype=float32), 'reward': -0.11395852267742157, 'newState': array([0.9424535], dtype=float32), 'info': {'arrival': 0.9424534741074311}}\n",
      "new state: [0.73420143]\n",
      "old state: [0.9424535]\n",
      "{'iter': 1, 'episode': 97, 'step': 2, 'oldState': array([0.9424535], dtype=float32), 'action': array([0.70623696], dtype=float32), 'reward': -0.0800274908542633, 'newState': array([0.73420143], dtype=float32), 'info': {'arrival': 0.7342014306917001}}\n",
      "new state: [0.88519293]\n",
      "old state: [0.73420143]\n",
      "{'iter': 1, 'episode': 97, 'step': 3, 'oldState': array([0.73420143], dtype=float32), 'action': array([0.5821622], dtype=float32), 'reward': -0.26528285443782806, 'newState': array([0.88519293], dtype=float32), 'info': {'arrival': 0.8851929259086364}}\n",
      "new state: [0.4655673]\n",
      "old state: [0.88519293]\n",
      "{'iter': 1, 'episode': 97, 'step': 4, 'oldState': array([0.88519293], dtype=float32), 'action': array([0.9316214], dtype=float32), 'reward': -0.3611476719379425, 'newState': array([0.4655673], dtype=float32), 'info': {'arrival': 0.4655672824610187}}\n",
      "new state: [0.48407492]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 98, 'step': 0, 'oldState': array([0.]), 'action': array([0.0101938], dtype=float32), 'reward': -0.35795929399318993, 'newState': array([0.48407492], dtype=float32), 'info': {'arrival': 0.48407493439283544}}\n",
      "new state: [0.62756187]\n",
      "old state: [0.48407492]\n",
      "{'iter': 1, 'episode': 98, 'step': 1, 'oldState': array([0.48407492], dtype=float32), 'action': array([0.3633019], dtype=float32), 'reward': -0.2283882275223732, 'newState': array([0.62756187], dtype=float32), 'info': {'arrival': 0.6275618481218704}}\n",
      "new state: [0.74010634]\n",
      "old state: [0.62756187]\n",
      "{'iter': 1, 'episode': 98, 'step': 2, 'oldState': array([0.62756187], dtype=float32), 'action': array([0.39997146], dtype=float32), 'reward': -0.31199876964092255, 'newState': array([0.74010634], dtype=float32), 'info': {'arrival': 0.7401063451742533}}\n",
      "new state: [0.6822612]\n",
      "old state: [0.74010634]\n",
      "{'iter': 1, 'episode': 98, 'step': 3, 'oldState': array([0.74010634], dtype=float32), 'action': array([0.9802343], dtype=float32), 'reward': -0.28351181745529175, 'newState': array([0.6822612], dtype=float32), 'info': {'arrival': 0.6822612375007837}}\n",
      "new state: [0.8422434]\n",
      "old state: [0.6822612]\n",
      "{'iter': 1, 'episode': 98, 'step': 4, 'oldState': array([0.6822612], dtype=float32), 'action': array([0.7157778], dtype=float32), 'reward': -0.10322831571102142, 'newState': array([0.8422434], dtype=float32), 'info': {'arrival': 0.8422433991988739}}\n",
      "new state: [0.8947433]\n",
      "old state: [0.]\n",
      "{'iter': 1, 'episode': 99, 'step': 0, 'oldState': array([0.]), 'action': array([0.22568808], dtype=float32), 'reward': -0.5582134388387203, 'newState': array([0.8947433], dtype=float32), 'info': {'arrival': 0.8947433221097096}}\n",
      "new state: [0.9306354]\n",
      "old state: [0.8947433]\n",
      "{'iter': 1, 'episode': 99, 'step': 1, 'oldState': array([0.8947433], dtype=float32), 'action': array([0.5832518], dtype=float32), 'reward': -0.3384106010198593, 'newState': array([0.9306354], dtype=float32), 'info': {'arrival': 0.9306353856050769}}\n",
      "new state: [0.8255188]\n",
      "old state: [0.9306354]\n",
      "{'iter': 1, 'episode': 99, 'step': 2, 'oldState': array([0.9306354], dtype=float32), 'action': array([0.58682907], dtype=float32), 'reward': -0.2649688720703125, 'newState': array([0.8255188], dtype=float32), 'info': {'arrival': 0.8255187850184297}}\n",
      "new state: [0.7470699]\n",
      "old state: [0.8255188]\n",
      "{'iter': 1, 'episode': 99, 'step': 3, 'oldState': array([0.8255188], dtype=float32), 'action': array([0.7304379], dtype=float32), 'reward': -0.03624424338340759, 'newState': array([0.7470699], dtype=float32), 'info': {'arrival': 0.7470698919694087}}\n",
      "new state: [0.76860225]\n",
      "old state: [0.7470699]\n",
      "{'iter': 1, 'episode': 99, 'step': 4, 'oldState': array([0.7470699], dtype=float32), 'action': array([0.8996238], dtype=float32), 'reward': -0.13640464842319489, 'newState': array([0.76860225], dtype=float32), 'info': {'arrival': 0.7686022572744586}}\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-boutique",
   "metadata": {},
   "source": [
    "# Step 6: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4cdd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Algorithm    Reward      Time    Space       MRT       RTV\n",
      "0    Random -1.509265  4.222735 -38218.5 -0.328134 -0.050331\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-academy",
   "metadata": {},
   "source": [
    "# Visualization Demo\n",
    "\n",
    "The following demo includes a command-line interface with a visualization to demonstrate how the Ambulance Routing code works with 2 ambulances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-algebra",
   "metadata": {},
   "source": [
    "The following commands need to be used in the terminal to install the necessary packages:\n",
    "* `apt-get install -y xvfb python-opengl`\n",
    "* `pip install gym pyvirtualdisplay`\n",
    "* `pip install scikit-learn-extra`\n",
    "* `pip install stable_baselines3`\n",
    "* `pip install pyglet==1.5.16`\n",
    "\n",
    "The first two are needed for the simulation but the rest should already be installed from the code demo above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-estonia",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "Run the cell below to run the simulation. In this simulation, you are trying to minimize the distance traveled by two ambulances to respond to incoming calls. The parameters in the problem are set up so the distance traveled to respond to a call is three times as costly as the distance traveled between calls. The reward is the negative cost, because reward is something that you want to maximize. Your goal therefore is to keep the reward as close to zero as possible.\n",
    "\n",
    "These are some questions you could ask yourself when choosing actions:\n",
    "\n",
    "* Should I focus more on minimizing distance traveled between calls, or distance traveled to respond to a call?\n",
    "\n",
    "* Do calls seem to arrive more in a certain part of the range $0$ to $1$? Can I take advantage of that?\n",
    "\n",
    "* Am I able to improve your performance over multiple rounds? (once you've finished you can re-run the cell to try again!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "computational-plant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEjCAYAAAAhczZxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlh0lEQVR4nO3de3xU1b338c+amSQkBBgCRMRSYbAgBZSGFBX7iBWQ0+cc8dQieGktXiDWaqXe6E08eqAabU9bn1pfobSex0u1hR7lYL2Bt0NFLQQEEblOq1wUEAgQcp3MOn/MThiGIVkJYWYg3/frtV9k1v7NzMoC9nf2XnvvMdZaREREWuJLdwdEROTEoMAQEREnCgwREXGiwBAREScKDBERcaLAEBERJ4FUvpkxpggoBsJACAhbaxensg8iItI2KQsMY0wIKLXWjotrm2eMCVtrw6nqh4iItE0qD0mVAGUJbWVAaQr7ICIibWRSdaW3MWYzMC5+b8IYEwT2WmtNSjohIiJtlpI9DC8YQsCe+HZrbYW3PpSKfoiISNul6pBUARwKiCQUGCIiGS5Vk97BY30BY4zukigikiLJpgpSelptaxljpgHT0t0PERFJ8YV73lyGM2vtHGttsbW2+Dh1SUREHKUqMBrPjCqIb4wLEF2HISKS4VISGN5kd5gj5zIKgApduCcikvlSeUhqMbHbgsQr8tpFRCTDpfLCvSAwL+HWIIuAEpc9DJ0lJSKSOsnOkkpZYEDTzQfHcujmgytcbz6owBARSZ20B8axUGCIiKROssDQ92GIiIgTBYaIiDhRYIiIiBMFhoiIOFFgiIiIEwWGiIg4UWCIiIgTBYaIiDhRYIiIiBMFhoiIOFFgiIiIEwWGiIg4UWCcJAKBjP56dhE5CXT4rUx2djbDhw/nS1/6EoFAgDVr1rBs2TKqqqrS1qfu3btTXV1NTU1N0vX5+fn4fD7279/fVF9WVsb06dPZvn37ce1bTk4O+fn57N69+7i+T+/evTnvvPP43Oc+x759+3j99dfZsmXLcX1PEWleh97DyMvL4/777+e+++4jNzeXaDRKSUkJt99+Oz5feobG7/fz0EMPMX78+KPWXH/99dx2221Nj6uqqnjsscfYt2/fce/fBRdcwKOPPnrc3+eaa67hkksuoa6ujmHDhvGHP/yBM84447i/r4gcXYfew5g8eTLFxcVMnjyZTz/9FIDHHnuMQYMGYYxh/PjxrF27tumT7Ve/+lW2bt3Kpk2bGDNmDFu3bqVPnz4Eg0HeeecdiouLWb16NaNGjWL58uVs2rSJQYMGMWLECOrq6vjrX//K9u3bMcZw0UUXsW3bNk499VQ+97nP8c4777Bx40YGDx7MWWedRUNDA6eccgpvvvkm69evb+rzKaecwvnnn0/Xrl0pKSlh7dq1LFu2jNzcXIwxh732aaedRmFhIW+++SYVFRVccMEFdO/enTfeeINPPvkEgNzcXM455xz69+/P1q1beeutt6iqqsIYw5AhQygqKiISibB69Wr+/ve/c9FFFzF48GBKSkrYsWMHCxYswOfzMWzYMM4++2wOHDjA//zP//DZZ5/h9/sZP34869evZ9CgQQSDQZYsWdI0nnl5efh8PiorK4/4uykrK6OyspKGhgZycnJ45plnGD9+PJs2bTre/yxE5Cg6bGBkZWUxYcIEFixY0BQWADU1NaxatQq/38+NN97InDlzmjZwU6ZM4ZVXXiEcDjN16lRycnJYsWIF69evJxQK8cADD7Bo0SI2bdqEz+djwoQJ3HTTTbz22mt07dqV6667jpKSErZu3cr1119PTk4O7733Hnl5edx4441ceeWVTRt9n8+H3+/HmMO/w6RxXfz6/Px8fvCDH1BeXk51dTVTp04lKyuLlStX0qtXL6666irefvttAPr168dll13GNddcQzQaZfbs2RQWFlJeXs6YMWMYP348P/zhDxk6dCiPPPIIL774ItXV1QwcOJBf/vKXTXtefr8fv9+Pz+fj29/+Nt/4xjd44403OPvss/nmN79JSUkJlZWVTJ8+nb1797J69Wp69OjBDTfcwLXXXstHH33EzTffTN++fbnllluO+PuJ31sKBAJ06dIlabCISOp02MDIycmhV69efPzxx216vs/nY+3atcyaNYtoNMq5555LIBDg17/+NRs3bqRz5848+uij/OxnP2PJkiX4fD5mzZrFZZddxsMPP4zP52PdunXMnj0bn8/HM888w6hRo5g3bx4bN27k5ZdfZv78+Ue876effsrf/vY3CgoK+M1vfgNAz549j+jbmjVr+OlPf0peXh6vvfYaBw8e5OGHH6ZXr14sXLiQvn370rNnT4qLi/nWt77F3r17WbhwIU888QT9+/dn4MCB7Ny5k9/85jfs27ePhoYGrLW8+eabDB06tOm9CwsLmTZtGt///vf54IMPyMrK4pFHHmHMmDEsWLAAv9/PO++8wy9/+UsCgQCPPPIIkyZN4qGHHuKPf/wjOTk5LY7ztddeS1ZWFi+99FKb/q5EpH102MCIRCIcPHiQYDDo/Jz4T/vRaJT33nuPaDTa1LZz586mAOrZsyf9+/fnrrvu4tZbb8UYQ5cuXdiyZQvGGKLRKO+//z7RaJRoNMqOHTta1ZfmRKNR1qxZQzQa5eDBg+zdu5cNGzZgraW6upq6ujo6derEoEGDOOOMM5g7dy7WWnw+H9nZ2eTl5bFkyRImTZrE/Pnz2bhxI/PmzePVV1894r1OO+00+vbty+zZs4lEIhhjCAaDdOrUqakvK1euxFpLfX09q1evZtiwYQB89NFHzf4ePp+PSZMmcfXVV3PzzTezY8eOdhkfEWmbDhsYNTU1LF26lLFjx/Lkk082nZHUuME7cOAA9fX15ObmArHDIj169Gh6vrWWSCRy2GtGIhEavyO9qqqKzz77jDvvvJNVq1Y11TR+UgcOC5vG9072cyJrbYvrG1/bWou1loaGhiPqdu/ezZo1a5g8efJhZ4XV1dVhreXqq6+mX79+nH/++fz85z/n8ssvb+q7MQZrLfv372fnzp2UlJQctrcWiUTIzs7G5/NRWFjY9JzCwkL27t171L7H//6XXnopt956K7fddhvl5eUtPkdEjq8OfZbU3LlzKSgoYNasWRQVFTFkyBC+973vMX36dABWrlzJxIkTGTJkCJMnT2bAgAHOr717925eeOEF7rjjDoYPH06/fv0YPXo0oVCo2edZa9m1axfDhw+nf//+5OfnH1Gzc+dOvvCFLzBw4EAKCgpa9TvHW7p0KcYYbrzxRkKhEGeeeSYXX3wxeXl5nHXWWZx//vlEo1G2bt1KfX190+/Vs2dPhg0bRu/evdmyZQtvv/02M2bM4Itf/CKhUIgxY8bQp08fIBaKkyZN4pxzzmHcuHGMHz+e559/HoDRo0czYcKEpH0bM2YMs2fP5tFHH+WTTz7h9NNPb7c9MBFpmw4dGNu2bePaa69l+/bt3HHHHcycOZP8/Hwef/xxIpEIv/3tb/nHP/7B3XffTU5ODk8//TQ7duzAWssHH3zArl27ml5r//79rFy5sumTfTQa5cEHH+Tll1/mlltu4d577+XCCy9s2sNYu3YtO3fubHr+hg0b2LZtG9FolLKyMgoLC/nFL37Bueeee0S/X3jhBcLhMKWlpUyePJn6+nrKy8upqalpeu34vq1atYo9e/YAsU/+K1asoLKyks8++4ySkhLy8vK47777uO222+jbt2/TYbKvfe1rzJ49m8mTJzNz5kw2btzI+++/z5///Gfuuecebr/9diKRCD/60Y9YvXo1d911FzNnzqS4uLhpjyYajfLiiy9y1VVXMWXKFB544IGmCfj+/fvzxS9+MenfzZAhQ9i+fTsTJ07kV7/6FQ8//DD/8i//cox/4yJyLEzjIYZMZ4w5MToqTXJzc3nuueeYNWsWS5YsSXd3RKQVrLVHHPfu0HsYcvxFo1FOlA8lItI87WHIcWOMYeDAgWzfvp0DBw6kuzsi0grJ9jAUGCIicoRkgeF8Wq0xZiJQYa1dnGRdEVAMhIEQEE6sc6kREZHM5RQYxpixwG+By5OsCwGl1tpxcW3zjDFha23YtUZERDJbs5PexpiQMaaM2B7BnqOUlQBlCW1lQGkra0REJIM5z2EYYzYDJUkONW0GxsXvKRhjgsDexmNgLjUO7685DBGRFGn302q9jf4Rex/W2gpvfcil5lj6ICIiqXGs12EUwKGNfxIhxxoREclwx3rzwWA71SRljJkGTGvr80VEpP1k9N1qrbVzgDmgOQwRkXRrl1uDePMUx1wjIiKZ61gDo/Gsp8PusR0XDmHHGhERyXDHdEjKWlthjAlz5DxFAbGrwhsv3GuxRkREMlt7HJJaTOyWH/GKvPbW1IiISAZrTWAUkPyMpxkcecuQEq+9NTUiIpLBmr3S25tn+CGxayUmEptvWAwsstbOj6srAsZy6MaCK45y88Fma5rtqM6SEhFJGd3eXEREnOgb90REpM0UGCIi4kSBISIiThQYIiLiRIEhIiJOFBgiIuJEgSEiIk4UGCIi4kSBISIiThQYIiLiRIEhIiJOFBgiIuJEgdFGfr8fny82fD6fD7/ff1zepz1eO76vIiJt1eG3ItnZ2YwcOZKSkhK++93vMnr0aPLy8pp9js/nY9asWfzTP/0TAJdccgn33XffcenfpZdeyr333ntMr3HrrbcyZcqU9umQiHRYx/QVrSe6vLw8/v3f/50hQ4bw0ksvUVtbS0lJCRdccAGzZ88mGo0mfZ4xhj59+tC1a1cAunXrRp8+fY5LH1evXs2nn356TK9RWFh43PaARKTj6NCBMXnyZIqLi5k8eXLTRvmxxx5j0KBBQGxDO3LkSHr16sXWrVt56623qKqqatV7dO7cmZEjR/L5z3+eAwcOsGTJEnbt2gXAsGHD6NatG5WVlQwdOpTFixdz3nnnUV5eTlFREXv27GHHjh1kZ2cDMG7cOD766CM2bNgAQNeuXbn44ov5y1/+QqdOnRg5ciR9+vRh586dLFmyhP3797fXUImIdNxDUllZWUyYMIEFCxYc9gm+pqaGVatWYa1l3LhxjBgxgoKCAr7zne9w9913Ewi0LmOHDRvGxRdfTEFBAePHj6esrIzu3bsDMHbsWB566CGuuOIKcnNzyc/P5+677+aee+7hjDPOwO/3M2rUKK655hoARowYwXe/+92m+YjRo0c3HWoaNWoUX/nKV+jevTtXXnklP//5z8nJyWmHkRIRiemwexg5OTn06tWLjz/+OOl6ay1PP/00OTk5BAIBXnzxRX73u9/Rq1cvdu7c6fw+7777LitXriQ7O5u8vDzmzp3LiBEjWLw49u20Bw4cYNasWVRWVtKzZ0+ysrJYuHAhzz33HMBhcw/PP/88c+fOpVevXuzevZuJEyeyYMECqqureeGFF3j11VfJysqiR48ePPHEE4RCIT788MM2j5GISLwOGxiRSISDBw8SDAaTrjfGMGHCBL797W+Tn59PIBCgX79+5OfntyowzjrrLO666y569eqFz+dj8ODB9OzZs2n9unXrqKysbHpcU1PDmjVrkr7Whg0b2L59OxdccAHLly9n8ODB3HPPPQBceOGF3HTTTXTr1o1AIMCgQYOO+ruJiLRFhw2Mmpoali5dytixY3nyySepqakBYkERDAYxxjBjxgz+7d/+jaVLl1JQUMDzzz/fqtNTA4EAd955J8uXL+c///M/aWho4KmnnjrsNSKRyGHPiUajR51sr6urY8GCBXz961+nsLCQtWvX8vHHH5Obm8uPfvQjfv/73zfNZyxcuFCn0opIu+rQW5S5c+dSUFDArFmzKCoqYsiQIXzve99j+vTpGGOw1tKnTx/69u3L1Vdf3aZP7HV1dZx66qn07t2bf/3Xf2XgwIHH1OdXX32VgQMHMnXqVJ599tmmgIlEIvTp04fTTjuNK664glNPPfWY3kdEJFGHDoxt27Zx7bXXsn37du644w5mzpxJfn4+jz/+OHv27OEnP/kJY8aM4c4772TdunUsXLiQqqoqrLV8+OGHTYemPv3006RzBZFIhPvvv58uXbpwzz33kJOTw1NPPcWOHTsA2LJlC5s2bWqqr6+vp7y8nOrq6qa2Tz75hHXr1jU93r59OwsXLuTDDz9kyZIlANTW1jJz5kyGDBnCj3/8Y3bt2sX8+fPZt28fAOFw+KhzNSIiroy1Nt19cGKMOTE6KiJyErDWmsS2Dr2HISIi7hQYIiLiRIEhIiJOnE6rNcZMBELAAO/PMmvt/ISaIqAYCHs1YWvt4tbWiIhIhrLWNrsAE4GiuMdBYDMwLa4tBCxKeN48INSamhb6YbVo0aJFS2qWZNthl0NSIWvtisYH1toKoBQoi6spSXiM97i0lTUiIpKhmj2t1hgTBF4FxnhB0dgeIraXMcBaGzbGbAbGWWvDCc/d23hqlktNsx3VabUiIinT6tNqvZAIeUtS3kY/BOxJ8lyMMSGXmhZ7LyIiadXipLe1tnuS5iKgwtu7CHl1FUd5iaYwaKEmfJR1IiKSAdp688EfAvd7Pwcd6l1qjmCMmQZMa8tzRUSkfbU6MLyN+B5r7YPHoT+HsdbOAeZ476s5DBGRNGrVhXve4acSa+24JOuCDs9vsUZERDJTa6/0LgXGJLQ1zj0UxDfGhUPYsUZERDKY8yEpY0wZMDVx4tpaW2GMCXPkPEUB3sS49/wWa0REJHM57WF48xalCddijI07HXYxsVt+xCvy2mlFjYiIZKgWvw/Du49UAYc27EHv8eXW2hKvJgjMi5/bMMYsIjbfEXataaEfmvQWEUmRZBfuuVzpvfcoq8PW2gFxtUXAWA7dWHDFUW4+2GxNM31RYIiIpEirAyOTKDBERFJH37gnIiJtpsAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnAZciY8xYYBywGxgAlFtr5yTUFAHFQBgIAWFr7eLW1oiISGZqMTC8sMBaOyOurdwYE7TWPug9DgGl1tpxcTXzjDFha23YtUZERDKXyyGpkiRtixPaS4CyhJoyoLSVNSIikqFc5zDGJWmriPt5IrAiYf1yr701NSIikqGMtbb1TzJmM1BmrX3QGBME9gLdrbUVCXWW2JzHnpZqWjos5dWJiEgKWGtNYlurz5IyxkwDVjTOXwAF3otXHOUpIccaERHJYE5nSQEYYybiHZqy1l4etyro8HSXmmTvOQ2Y1pbniohI+3IODGvtfGC+MSZojCkHplprE+ck2pV36u4c0CEpEZF0a/UhKe+wUhnwany7N5fRLJcaERHJTG290nsxEPSu0WicrC6IL4gLh7BjjYiIZLBmA8MYEzLG7PUuuksm6O1xhDlynqIAqLDWhl1qWtlvERFJMZc9jOXETouN1xggjXMYi4nd8iNekddOK2pERCRTWWubXYC7iO1JxLctInabj8bHQWBRkppQa2pa6IfVokWLFi2pWZJth50u3PNObx1AyzcfbJzTCBG7ViPZzQebrWmmDy13VERE2kWyC/fadKV3OigwRERSp12u9BYRkY5JgSEiIk4UGCIi4kSBISIiThQYIiLiRIEhIiJOnO9WKxKvZ88ejP7KefQ+5ZSmNgts27WHJX99C1tfx969FWnr34mqS5d8vjziSwweNPCw9v01dby8+HWitdXs2bOHaFRnmUvq6ToMaTW/38crz/+ZUeeOxLd2NfVvLKbTzbdT7c/mldrO1B7YT+HebUy77OuE//5Rurt7QvnZ/fdSMnUKnQ7sp2bO/6PTTdOhe09ej3Tl030H+FzdPh68+Tu89PKidHc1NboZKPCRVZhDZIjBxm0GzHaLXV8X+6SyOwr7tYloT8muw9AehrSBoVunHFj0F2rf/iuR117B1/d0ouMnYHO74ysoJBLsRs+ePRUYrdS5cx5Z775F7boPqPvjk/hOOZXA/72USO9hZHfvSQUFfH5AB/mCyu4+uL0zfN5P/aoIptCPL9cQXVcPOQbywH9JNxq6ROH9enjoYCw85LjRHIa0ia2upvaJ31H/+ivYaAO1j8/F7K8ggAVrscbHVy8eS6h/P4w54oOKHI2Fuv/+M3V/egoCfmr/6xka/r6ZLG9cfVhGfOUrDD5zIFlZJ/fnPf+XcyDPwPoGeKIK9kcxUTB1YE73w4oI0d9WYnZF8QcC+Lue3OORCTrsIamsrCyys7Pb8yU7DL/fzxsvP8dZZw6k6ge34h88lJwpUyGQxT4C1OIjnwY6RSMcOHCAd5eV8/tfPcDLyzYQPXIvV+L86mezmXLV5dQ+8Tsi762g889+Df4AVSZAJX46ESWfCHU1tZSvXMV/Pfl7/vDsS1Q1nHyf/WovgohpgPfq8Z2ZQ/SrAdgcwfgNdoAfPm6A/66B4Vn4rKHT+37MrszfnkWjUaqrq9PdjRbpXlJxrrzySq677rr2fMkOwxgoKuxCfpaP6K4d0CkXX5euySpjf0TrqXjjEd4PXUk0kJPSvp5oBnbP5dTO2dh9FdhIPb4evZJUHfp/XFv+FO/lnkVN176p62SK3HfffSxZtgQuy8U3uhP2b7XYMwLQ1eDbYIkONLC0Dv5YDRH4j//4D4YNG5bubrdo586d3HDDDRkfGgqMOIFAQHsYbeQ3hvn//H/40vCh+DesIxBtOEqlIXZQ2fCPAwe4aPFKqhuiKezpiefekUO4ZtwF+D76B9k1VUepiguMSD1jF5ezqbImNR1ModraWhqKfXBTZ4wFW14Pp/kxeQbea8CeG8B0Ap6pwb5QQ05ODn6/P93dbpG1NuPDAjTpfZhIJEIkEkl3N05Ifr+fHtPvpOCsoQBs3badZxf8hW98/RL6nNq7qe6zz3aTm9uJzp0741u3nqqXLqa6+uTbsLWn/Msm0+O6bwFw8OBBnnx6Pud8eQTDzx7aVLNv/36iDVG6dw/CwYNUjRpD1c7E7zg7SfTOim2lLHC6HzY1YLMNnA50jm3P7Cmxw3G1tbVp62ZHcfId+JTjLhqN8sy8Z1n1/gfU1dXx09Jf8P27fsIN37mV2tpajDGE//4R5134NW74znRqamv5/088Q02N/kO35PkXX+HdZeXU1NTwzLxnueX7M5j0zevYtv0TjDEcPFjFN66Ywrh//ga7PtvNX15cxEcfbUl3t48PP1AcwFgTOw7a2w/nZkFRADMggGbDUq/DHpKSY9c5L48BA/qzceNmfD4fZ581lCsnXYbf78fn83HTrXfyhQEhikcMZ/5//Te1dXXp7vIJIRAIcOagL7Blyzbq6us5rc+pTLv+GvI7dybYrSvT7/wxlQeruGHK1Tz+1J+o2Lcv3V0+bvzDs4kOD2DjPtoG+mTTcJr1DnaC//UGIn+qTFcXT1qaw5Djokt+Z/r370cgEGDle6uwFvLychk35kIqKvbx9jvLqKuvT3c3Tzh+v5+BXxhAr149eWvpuzQ0NJCTnc2Xi79EQUF3XntjCZWVB9PdzdTLNpDDoSmyOqBWm4f2psCQlPL5Yh8Lo1FNdLcnn88ARuMqx5UCQ0REnOgrWkVEpM0UGCIi4kSBISIiThQYIiLiRIEhIiJOFBgiIuJEgSEiIk5affNBY0wQKLXWliS0FwHFQBgIAWFr7eLW1oiISGZqy91qS4GC+AZjTIhYiIyLa5tnjAlba8OuNSIikrladUjK2+gXJFlVApQltJURC5fW1IiISIZq1a1BjDHTvB/HWWsvj2vf7LWF49qCwN7Gy8tdalp4b90aREQkRY7p1iDGmLHAn5K0B4nNRxz2DS7W2gpvfcilxrUfIiKSHq05JBVs3MAnKIBDG/8kQo41IiKSwZwmvY0xE62184+yOujwEi41yd53GjCtxUIRETnuWgwM73BSxXHvSRLW2jnAHK8fmsMQEUkjl0NSk1yulfCC5ZhrREQkMzUbGN6FdstbeI3Gs54Sr80Ixq13qRERkQzW0iGpYmCAMWZyXFsREDLGlALLrLXzjTFhjpynKAAq4i7ca7FGREQyV7OB4c0hHMYYcxfwZWvtjLjmxcTCZUVcW5HX3poaERHJUG25+WCPJG0zgMsT2kq89tbUiIhIhnK+0tu7uG4GMInYoaU5QJm1doW3vggYy6EbC644ys0Hm61p5v11lpSISIoku9K7VbcGSScFhohI6hzTrUFERKRjU2CIiIgTBYaIiDhRYIiIiBMFhoiIOFFgiIiIEwWGiIg4UWCIiIgTBYaIiDhRYIiIiBMFhoiIOFFgiIiIEwWGiIg4UWCIiIgTBYaIiDhRYIiIiBMFhoiIOFFgiIiIEwWGiIg4UWCIiIgTBYaIiDhRYIiIiBMFhoiIOFFgiIiIEwWGiIg4UWCIiIiTQEsFxpggMA2Yb60NG2NCwERghbV2cVxdEVAMhIEQEI5f71ojIiIZylrb7EJsw27jlr3AxCQ1ixLa5gGh1tS00A+rRYsWLVpSsyTbDrsekhoHdAcGWGu7W2vnJ6wvAcoS2sqA0lbWiIhIhjLep/ejF8QOQYWaO3RkjNkMjLPWhuPagsBea61xrWmhH813VERE2k2y7fIxT3p7G/0QsCfhzSq89SGXmmPth4iIHF8tTnp7gsaYid7PBcCeuMNSBXBo459EUxi0UBM+yjoREckALoGxByiw1s5pbDDGzDPG4IVG0OE1XGqOYIyZRuwMLRERSbMWD0lZayviw8KTkslqa+0ca22xtbb4eL+XiIg0r61zGGGgcW4CaJrLaJZLjYiIZKYWA8MYc1eS5sbJ6/i5h4KE5wW9H8OONSIiksGaDQzv7KXSJGcxNW74w95Edpgj5ykKgAprrVNNq3suIiIp1WxgeBvykiQb9LHEbg1S4T1eTOyWH/GKvHZaUSMiIpnK4ZYcEzn8Fh9BoBwoSmhLvO3HoiTPa7ZGtwbRokWLlsxYkm2HW7zSG8C7BiME9CC24S9N3Ovwbiw4lkM3Fjzs5oSuNc30oeWOiohIu0h2pbdTYGQCBYaISOocl1uDiIhIx6DAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJwoMERFxosAQEREnCgwREXGiwBAREScKDBERcaLAEBERJ4F0d6AVKoH16e7ESaAn8Fm6O3ES0Di2D41j+2jvcTw9WeOJFBjrrbXF6e7Eic4Ys1zjeOw0ju1D49g+UjWOOiQlIiJOFBgiIuLkRAqMOenuwElC49g+NI7tQ+PYPlIyjsZam4r3ERGRE9yJtIchIiJppMAQEREnGX1arTGmCCgGwkAICFtrF6e3V5nFGDOR2NgM8P4ss9bOT6hpcRw11ocYY4JAqbW2JKFd4+jAG4Ox3sMexP5NhhPWaxybYYwZCxR5D3sAm621cxJqUj+O1tqMXLxfblFC2zwglO6+ZcoCTASK4h4Hgc3AtNaMo8b6iHEtA+YltGkc3cZuIrGAiG8r1Ti2agyLgLFJxjXt/68z+ZBUCbH/uPHKgNI09CVThay1KxofWGsriI1P/Li5jKPG2mOMCQEFSVZpHFuQbM/M2wOeGFemcWxZiU3YC7Cxowbj4mtIxzimO02bSdnNJCQhsU/QNt19y4TFG4tyIJjQHgJs49i5jKPG+rDfe5q3JO5haBxbHrtS4vYm4trjP/VqHFsex/LE399rXxT3c1rGMSP3MLxPKiFgT3y7jX2CbvwU2KF5YxHylqRcxlFjfYh33PhPSdqDaBxdTAOWJTZab/5C4+hsMbDIm38AmvbU5nk/B0nTOGbqpHcBHPrlkggRm8Tp0Ky13ZM0FwEV1tpw4z+KFsYRh5qOMtZBa22FMSax3eXfIw41J/s4BoGwMWYacRsqe+gkDI2jA2vtDO/DS7kxZgbe72sPTXqnbRwzNTCC6e7ACeyHwP3ez0GHepeak54xZqJNOLssTtDhJVxqTlpxn1hDcRs2jDGlxpgCry3o8FIuNSc9a+0IY8wiYof5VgBj4lYHHV7CpabVMvKQlLRN4yc7a+2D6e7LicTbfa9IczdOdMGjtP+RjjNZ3W68/8slxCa6Q8T2NtJ+OC6jA8P7jywOvH9MJdbacUnWBR2e32LNSWySdTg3XePYrHDCnwDY2Fl8wfiNncaxecaYMmCxtbbxmon+xMZ1UUJd0OG1WqxpjUwNjMZ/dIed3hj3y5/UxzDbqJTDd1vBbRw79Fh7E4vLWyjTOLYg7lh5xVFK4o+ZaxyPovH3tHEXOlprK7wPghXe3EbaxjEj5zC8iccwR+7mFuBN6Ka+V5nL+0QyNXGCy3UcO/hYFwMDjDGT49qKgJAxphRYZq2dr3F00nQ1cbJ1+vfopJjYabXJlHHoxIy0jGOm7mFA7NSyxG+QKvLaxeMd6yyNDwtjzNi4QwAu49hhx9paO8daOyN+Ibbrv8J73DgRrnFsWRmHbmcBNO3BheM2UBrH5oWBEUdZFyQ2AQ7pGsd0X6RytMUbnMTL2hfRQW4P4DhGE4md+954PUbjPXzK4mpaHEeN9RHjWsqRF+5pHFsetyCxex4l/v5jE2o0js2PYxlH3hokxOG3WEnLOGb092HE3cSscVd3he1ANyBrjncscu9RVoettQPialscR41104kDM4BJxP6zzSEWviu89RrHFjSefAHsJnZDzHltGSONo5lGbPx2e00VNvnNB1M6jhkdGCIikjkyeQ5DREQyiAJDREScKDBERMSJAkNERJwoMERExIkCQ0REnCgwRETEiQJDREScKDBERMTJ/wLEf2kjWAMzFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 518.4x320.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/ORSuite/lib/python3.8/site-packages/IPython/core/pylabtools.py:132: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 518.4x320.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The most recent call arrival was at 0.8320872, and ambulance 2 responded to the call.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6f9f52849e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m   \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0myour_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ORSuite/or_suite/agents/ambulance/command_line_metric.py\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(self, state, timestep, epsilon)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Where do you want to position ambulance \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mambulance\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"? (choose a number between 0 and 1)\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mnew_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0mnew_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ORSuite/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             )\n\u001b[0;32m--> 848\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ORSuite/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(500, 800))\n",
    "display.start()\n",
    "\n",
    "import or_suite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "a = 5\n",
    "b = 2\n",
    "CONFIG = {'epLen': 5,\n",
    "    'arrival_dist': lambda x : np.random.beta(a,b), \n",
    "    'alpha': 0.25, \n",
    "    'starting_state': np.array([0.0, 0.0]), \n",
    "    'num_ambulance': 2,\n",
    "    'norm': 1\n",
    "}\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "epLen = CONFIG['epLen']\n",
    "state = CONFIG['starting_state']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "agent = or_suite.agents.ambulance.command_line_metric.commandLineAgent(epLen)\n",
    "env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "env.reset()\n",
    "\n",
    "\n",
    "done = False\n",
    "your_rewards = []\n",
    "heuristic_agent_rewards = []\n",
    "your_total_reward = 0\n",
    "heuristic_agent_total_reward = 0\n",
    "\n",
    "median_est = (a - 1/3)/(a + b - 2/3)\n",
    "heuristic_agent_states = [state]\n",
    "\n",
    "x_axis = ['Your Reward So Far', 'RL Algorithm Reward So Far']\n",
    "\n",
    "\n",
    "def display_animation(screen, time_to_display):\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    if time_to_display is not None:\n",
    "        ipythondisplay.display(plt.gcf())\n",
    "        time.sleep(time_to_display)\n",
    "\n",
    "def plot_rewards():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    y_axis = [your_total_reward, heuristic_agent_total_reward]\n",
    "    ax.bar(x_axis, y_axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = agent.greedy(state, 0)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    your_rewards.append(reward)\n",
    "    your_total_reward += reward\n",
    "\n",
    "    # by comparing the final state with the action the user chose, we can figure out where the most recent arrival was\n",
    "    previous_arrival_ind = np.argmax(np.abs(action - state))\n",
    "    previous_arrival = state[previous_arrival_ind]\n",
    "\n",
    "    # the heuristic agent always chooses to put all the ambulances at the median estimate\n",
    "    heuristic_agent_action = np.full(num_ambulance, median_est)\n",
    "\n",
    "    # the state will have one ambulance where the call arrived, and all other ambulances at the median estimate\n",
    "    # doesn't matter which ambulance responds to the call because they're all at the same place\n",
    "    heuristic_agent_state = np.concatenate([np.full(num_ambulance - 1, median_est), [previous_arrival]])\n",
    "    heuristic_agent_states.append(heuristic_agent_state)\n",
    "\n",
    "    heuristic_agent_reward = -1 * (alpha * np.sum(np.abs(heuristic_agent_states[-2] - heuristic_agent_action)) + (1 - alpha) * np.sum(np.abs(heuristic_agent_action - heuristic_agent_state)))\n",
    "    heuristic_agent_rewards.append(heuristic_agent_reward)\n",
    "    heuristic_agent_total_reward += heuristic_agent_reward\n",
    "\n",
    "    screen1, screen2, screen3 = env.render(mode='rgb_array')\n",
    "\n",
    "    # display each step of the environment for 2 seconds\n",
    "    display_animation(screen1, 2)\n",
    "    display_animation(screen2, 2)\n",
    "    display_animation(screen3, None)\n",
    "\n",
    "    # plot your reward vs the agent's reward\n",
    "    plot_rewards()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"\\nThe most recent call arrival was at \" + str(previous_arrival) + \", and ambulance \" + str(previous_arrival_ind+1) + \" responded to the call.\\n\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "\n",
    "if np.sum(your_rewards) >= np.sum(heuristic_agent_rewards):\n",
    "    print(\"CONGRATS! You beat the RL algorithm.\")\n",
    "else:\n",
    "    print(\"You did not get a better reward than the RL algorithm.\")\n",
    "\n",
    "print(\"\\nYour total reward over all iterations was \", round(sum(your_rewards),3))\n",
    "print(\"The RL algorithm's total reward over all iterations was \", round(sum(heuristic_agent_rewards),3), \"\\n\")\n",
    "\n",
    "plot_rewards()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
