{
 "cells": [
  {
   "source": [
    "# OR Suite \n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making, including inventory control, resource allocation, ridesharing systems, and ambulance routing. In these\n",
    "models, an agent interacts with a system that has stochastic\n",
    "transitions and rewards, and aims to control the system by\n",
    "maximizing their cumulative rewards across the trajectory.\n",
    "Reinforcement learning has been shown in practice to be an\n",
    "effective technique for learning complex control policies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Ambulance Routing Code Demo\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook, we walk through the Ambulance Routing problem with a 1-dimensional reinforcement learning environment in the space $X = [0, 1]$. Each ambulance in the problem can be located anywhere in $X$, so the state space is $S = X^k$, where $k$ is the number of ambulances. For this example there will be only one ambulance, so $k = 1$.\n",
    "\n",
    "The default distribution for call arrivals is $Beta(5, 2)$ over $[0,1]$, however any probability distribution defined over the interval $[0,1]$ is valid. The probability distribution can also change with each timestep.\n",
    "\n",
    "For example, in a problem with two ambulances, imagine the ambulances are initially located at $0.4$ and $0.6$, and the distance function being used is the $\\ell_1$ norm. The agent could choose to move the ambulances to $0.342$ and $0.887$. If a call arrived at $0.115$, ambulance 1, which was at $0.342$, would respond to that call, and the state at the end of the iteration would be ambulance 1 at $0.115$ and ambulance 2 at $0.887$. The agent could then choose new locations to move the ambulances to, and the cycle would repeat."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Step 1: Package Installation\n",
    "First we import the necessary packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54262089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "source": [
    "# Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.ambulance_metric_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1]\n",
    "\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)"
   ]
  },
  {
   "source": [
    "# Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "arrival_dist = beta\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)"
   ]
  },
  {
   "source": [
    "# Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median.medianAgent(CONFIG['epLen']),\n",
    "# 'AdaQL': or_suite.agents.rl.ada_ql.AdaptiveDiscretizationQL(epLen, scaling_list[0], True, num_ambulance*2),\n",
    "# 'AdaMB': or_suite.agents.rl.ada_mb.AdaptiveDiscretizationMB(epLen, scaling_list[0], 0, 2, True, True, num_ambulance, num_ambulance),\n",
    "# 'Unif QL': or_suite.agents.rl.enet_ql.eNetQL(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance)),\n",
    "# 'Unif MB': or_suite.agents.rl.enet_mb.eNetMB(action_net, state_net, epLen, scaling_list[0], (num_ambulance,num_ambulance), 0, False),\n",
    "# 'Command Line': or_suite.agents.ambulance.command_line_metric.commandLineAgent(CONFIG['epLen'])\n",
    "}"
   ]
  },
  {
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "source": [
    "# Step 6: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n"
   ]
  },
  {
   "source": [
    "# Visualization Demo\n",
    "\n",
    "The following demo includes a command-line interface with a visualization to demonstrate how the Ambulance Routing code works with 2 ambulances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The following commands need to be used in the terminal to install the necessary packages:\n",
    "* `apt-get install -y xvfb python-opengl`\n",
    "* `pip install gym pyvirtualdisplay`\n",
    "* `pip install scikit-learn-extra`\n",
    "* `pip install stable_baselines3`\n",
    "* `pip install pyglet==1.5.16`\n",
    "\n",
    "The first two are needed for the simulation but the rest should already be installed from the code demo above."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Simulation\n",
    "\n",
    "Run the cell below to run the simulation. In this simulation, you are trying to minimize the distance traveled by two ambulances to respond to incoming calls. The parameters in the problem are set up so the distance traveled to respond to a call is three times as costly as the distance traveled between calls. The reward is the negative cost, because reward is something that you want to maximize. Your goal therefore is to keep the reward as close to zero as possible.\n",
    "\n",
    "These are some questions you could ask yourself when choosing actions:\n",
    "\n",
    "* Should I focus more on minimizing distance traveled between calls, or distance traveled to respond to a call?\n",
    "\n",
    "* Do calls seem to arrive more in a certain part of the range $0$ to $1$? Can I take advantage of that?\n",
    "\n",
    "* Am I able to improve your performance over multiple rounds? (once you've finished you can re-run the cell to try again!)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 1\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 2\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 3\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 4\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 5\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 6\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 7\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 8\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 9\n",
      "process exited early. stderr:b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"\n",
      "start failed 10\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "XStartError",
     "evalue": "No success after 10 retries. Last stderr: b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXStartError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36m_start1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to start process: %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXStartError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXStartError\u001b[0m: Failed to start process: <pyvirtualdisplay.xvfb.XvfbDisplay object at 0x7fbf181443a0>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mXStartError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6f9f52849e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyvirtualdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/pyvirtualdisplay/display.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/pyvirtualdisplay/abstractdisplay.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                         raise XStartError(\n\u001b[0m\u001b[1;32m    166\u001b[0m                             \u001b[0;34m\"No success after %s retries. Last stderr: %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXStartError\u001b[0m: No success after 10 retries. Last stderr: b\"_XSERVTransmkdir: ERROR: euid != 0,directory /tmp/.X11-unix will not be created.\\n_XSERVTransSocketUNIXCreateListener: mkdir(/tmp/.X11-unix) failed, errno = 2\\n_XSERVTransMakeAllCOTSServerListeners: failed to create listener for local\\n(EE) \\nFatal server error:\\n(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \\n\""
     ]
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(500, 800))\n",
    "display.start()\n",
    "\n",
    "import or_suite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "a = 5\n",
    "b = 2\n",
    "CONFIG = {'epLen': 5,\n",
    "    'arrival_dist': lambda x : np.random.beta(a,b), \n",
    "    'alpha': 0.25, \n",
    "    'starting_state': np.array([0.0, 0.0]), \n",
    "    'num_ambulance': 2,\n",
    "    'norm': 1\n",
    "  }\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "epLen = CONFIG['epLen']\n",
    "state = CONFIG['starting_state']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "agent = or_suite.agents.ambulance.command_line_metric.commandLineAgent(epLen)\n",
    "env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "env.reset()\n",
    "\n",
    "\n",
    "done = False\n",
    "your_rewards = []\n",
    "heuristic_agent_rewards = []\n",
    "your_total_reward = 0\n",
    "heuristic_agent_total_reward = 0\n",
    "\n",
    "median_est = (a - 1/3)/(a + b - 2/3)\n",
    "heuristic_agent_states = [state]\n",
    "\n",
    "x_axis = ['Your Reward So Far', 'RL Algorithm Reward So Far']\n",
    "\n",
    "\n",
    "def display_animation(screen, time_to_display):\n",
    "  plt.imshow(screen)\n",
    "  ipythondisplay.clear_output(wait=True)\n",
    "  if time_to_display is not None:\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    time.sleep(time_to_display)\n",
    "\n",
    "def plot_rewards():\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_axes([0,0,1,1])\n",
    "  y_axis = [your_total_reward, heuristic_agent_total_reward]\n",
    "  ax.bar(x_axis, y_axis)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "while not done:\n",
    "  action = agent.greedy(state, 0)\n",
    "  state, reward, done, info = env.step(action)\n",
    "  your_rewards.append(reward)\n",
    "  your_total_reward += reward\n",
    "\n",
    "  # by comparing the final state with the action the user chose, we can figure out where the most recent arrival was\n",
    "  previous_arrival_ind = np.argmax(np.abs(action - state))\n",
    "  previous_arrival = state[previous_arrival_ind]\n",
    "\n",
    "  # the heuristic agent always chooses to put all the ambulances at the median estimate\n",
    "  heuristic_agent_action = np.full(num_ambulance, median_est)\n",
    "\n",
    "  # the state will have one ambulance where the call arrived, and all other ambulances at the median estimate\n",
    "  # doesn't matter which ambulance responds to the call because they're all at the same place\n",
    "  heuristic_agent_state = np.concatenate([np.full(num_ambulance - 1, median_est), [previous_arrival]])\n",
    "  heuristic_agent_states.append(heuristic_agent_state)\n",
    "  \n",
    "  heuristic_agent_reward = -1 * (alpha * np.sum(np.abs(heuristic_agent_states[-2] - heuristic_agent_action)) + (1 - alpha) * np.sum(np.abs(heuristic_agent_action - heuristic_agent_state)))\n",
    "  heuristic_agent_rewards.append(heuristic_agent_reward)\n",
    "  heuristic_agent_total_reward += heuristic_agent_reward\n",
    "\n",
    "  screen1, screen2, screen3 = env.render(mode='rgb_array')\n",
    "  \n",
    "  # display each step of the environment for 2 seconds\n",
    "  display_animation(screen1, 2)\n",
    "  display_animation(screen2, 2)\n",
    "  display_animation(screen3, None)\n",
    "\n",
    "  # plot your reward vs the agent's reward\n",
    "  plot_rewards()\n",
    "  time.sleep(2)\n",
    "\n",
    "  print(\"\\nThe most recent call arrival was at \" + str(previous_arrival) + \", and ambulance \" + str(previous_arrival_ind+1) + \" responded to the call.\\n\")\n",
    "\n",
    "  time.sleep(2)\n",
    "\n",
    "\n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "\n",
    "if np.sum(your_rewards) >= np.sum(heuristic_agent_rewards):\n",
    "  print(\"CONGRATS! You beat the RL algorithm.\")\n",
    "else:\n",
    "  print(\"You did not get a better reward than the RL algorithm.\")\n",
    "\n",
    "print(\"\\nYour total reward over all iterations was \", round(sum(your_rewards),3))\n",
    "print(\"The RL algorithm's total reward over all iterations was \", round(sum(heuristic_agent_rewards),3), \"\\n\")\n",
    "\n",
    "plot_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd03aea52f0e504fc0c8fab1bd0b595280953bcd0b51f1e5356364f35786baaa868",
   "display_name": "Python 3.8.5 64-bit ('ORSuite': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}