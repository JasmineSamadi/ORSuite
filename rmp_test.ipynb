{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "revolutionary-universe",
   "metadata": {},
   "source": [
    "# Step 1: Package Installation\n",
    "First we import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-burst",
   "metadata": {},
   "source": [
    "# Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG =  or_suite.envs.env_configs.airline_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 1\n",
    "numIters = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-going",
   "metadata": {},
   "source": [
    "# Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "noticed-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "\n",
    "revenue_env = gym.make('Airline-v0', config=CONFIG)\n",
    "mon_env = Monitor(revenue_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-shooting",
   "metadata": {},
   "source": [
    "# Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comprehensive-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'BayesSelector': or_suite.agents.airline_revenue_management.bayes_selector.bayes_selectorAgent(epLen),\n",
    "'BayesSelectorBadRounding': or_suite.agents.airline_revenue_management.bayes_selector.bayes_selectorAgent(epLen, round_flag=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honest-equipment",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "BayesSelector\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "BayesSelectorBadRounding\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/airline_'+str(agent)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(revenue_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/airline_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/airline_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4cdd7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Algorithm  Reward      Time     Space\n",
      "0                    Random    1.55  7.531308  -4025.27\n",
      "1             BayesSelector    2.79  3.622935 -32864.49\n",
      "2  BayesSelectorBadRounding    2.69  3.645927 -29529.85\n"
     ]
    }
   ],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'revenue'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "# \n",
    "additional_metric = {}\n",
    "fig_name = 'revenue'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03c289",
   "metadata": {},
   "source": [
    "### Dual Degeneracy Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44cd7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "BayesSelector\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "BayesSelectorBadRounding\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "                  Algorithm  Reward      Time     Space\n",
      "0                    Random    2.15  7.489257  -3740.83\n",
      "1             BayesSelector    3.22  3.623419 -30498.44\n",
      "2  BayesSelectorBadRounding    3.16  3.607217 -29543.17\n"
     ]
    }
   ],
   "source": [
    "p = .45 # either do .44 or .45\n",
    "CONFIG['P'] = np.asarray([[1-p, p],[1-p,p],[1-p,p],[1-p,p],[1-p,p]])\n",
    "\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "\n",
    "revenue_env = gym.make('Airline-v0', config=CONFIG)\n",
    "mon_env = Monitor(revenue_env)\n",
    "\n",
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'BayesSelector': or_suite.agents.airline_revenue_management.bayes_selector.bayes_selectorAgent(epLen),\n",
    "'BayesSelectorBadRounding': or_suite.agents.airline_revenue_management.bayes_selector.bayes_selectorAgent(epLen, round_flag=False),\n",
    "}\n",
    "\n",
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/airline_'+str(agent)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(revenue_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/airline_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/airline_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))\n",
    "        \n",
    "        \n",
    "fig_path = '../figures/'\n",
    "fig_name = 'revenue'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "# \n",
    "additional_metric = {}\n",
    "fig_name = 'revenue'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5bcbf",
   "metadata": {},
   "source": [
    "# Run with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1d004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "071ee0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epLen = 4\n",
    "A = np.asarray([[1, 1, 0,0,0,0], [ 0,0, 1, 1, 1, 1], [ 0,0, 0,0, 1, 1] ])\n",
    "tau = 23\n",
    "P = np.ones((tau, A.shape[1]))/3\n",
    "c = [5, 5, 5]\n",
    "f = range(10, 16)\n",
    "CONFIG = {'A': A, 'f': f, 'P': P, 'starting_state': c , 'tau': tau}\n",
    "nEps = 134\n",
    "numIters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eacf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 6\n",
    "l = 3\n",
    "A = np.identity(m)\n",
    "for i in range(l):\n",
    "    for j in range(l):\n",
    "        if i != j:\n",
    "            demand_col = np.zeros((m, 1))\n",
    "            demand_col[2 * i + 1] = 1.0\n",
    "            demand_col[2 * j] = 1.0\n",
    "            A=  np.append(A, demand_col, axis = 1)\n",
    "A = np.append(A, A, axis = 1)\n",
    "tau = 20\n",
    "P = np.array([0.01327884, 0.02244177, 0.07923761, 0.0297121,  0.02654582, 0.08408091, 0.09591975, 0.00671065, 0.08147508, 0.00977341, 0.02966204, 0.121162, 0.00442628, 0.00748059, 0.02641254, 0.00990403, 0.00884861, 0.02802697, 0.03197325, 0.00223688, 0.02715836, 0.0032578,  0.00988735, 0.04038733])\n",
    "P = np.array([P]*tau)\n",
    "c = [2]*6\n",
    "f = np.array([33, 28, 36, 34, 17, 20, 39, 24, 31, 19, 30, 48, 165, 140, 180, 170, 85, 100,195, 120, 155, 95, 150, 240])\n",
    "CONFIG = {'epLen':epLen, 'A': A, 'f': f, 'P': P, 'starting_state': c , 'tau': tau}\n",
    "epLen = CONFIG['epLen']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f573f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "\n",
    "revenue_env = gym.make('Airline-v0', config=CONFIG)\n",
    "mon_env = Monitor(revenue_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b41f68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'BayesSelector': or_suite.agents.airline_revenue_management.bayes_selector.bayes_selectorAgent(epLen),\n",
    "'BayesSelectorBadRounding': or_suite.agents.airline_revenue_management.bayes_selector.bayes_selectorAgent(epLen, round_flag=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ad8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "BayesSelector\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/airline_'+str(agent)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(revenue_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/airline_'+str(agent))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/airline_'+str(agent))\n",
    "        algo_list_radar.append(str(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd08b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'revenue'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "# \n",
    "additional_metric = {}\n",
    "fig_name = 'revenue'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d19b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
