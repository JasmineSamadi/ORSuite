{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divided-unknown",
   "metadata": {},
   "source": [
    "# Ambulance Routing Ithaca Dataset\n",
    "\n",
    "One potential application of reinforcement learning involves positioning a server or servers (in this case an ambulance) in an optimal way geographically to respond to incoming calls while minimizing the distance traveled by the servers. This is closely related to the [k-server problem](https://en.wikipedia.org/wiki/K-server_problem), where there are $k$ servers stationed in a space that must respond to requests arriving in that space in such a way as to minimize the total distance traveled. \n",
    "\n",
    "The ambulance routing problem addresses the problem by modeling an environment where there are ambulances stationed at locations, and calls come in that one of the ambulances must be sent to respond to. The goal of the agent is to minimize both the distance traveled by the ambulances between calls and the distance traveled to respond to a call by optimally choosing the locations to station the ambulances. The ambulance environment has been implemented in two different ways; as a 1-dimensional number line $[0,1]$ along which ambulances will be stationed and calls will arrive, and a graph with nodes where ambulances can be stationed and calls can arrive, and edges between the nodes that ambulances travel along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-income",
   "metadata": {},
   "source": [
    "In this notebook, we walk through the Ambulance Routing problem with on a graph. There is a structured as a graph of nodes $V$ with edges between the nodes $E$. Each node represents a location where an ambulance could be stationed or a call could come in. The edges between nodes are undirected and have a weight representing the distance between those two nodes.\n",
    "\n",
    "The nearest ambulance to a call is determined by computing the shortest path from each ambulance to the call, and choosing the ambulance with the minimum length path. The calls arrive using a prespecified iid probability distribution. The default is for the probability of call arrivals to be evenly distributed over all the nodes; however, the user can also choose different probabilities for each of the nodes that a call will arrive at that node. For example, in the following graph the default setting would be for each call to have a 0.25 probability of arriving at each node, but the user could instead specify that there is a 0.1 probability of a call at node 0, and a 0.3 probability of a call arriving at each of the other three nodes.\n",
    "\n",
    "\n",
    "We do a single experiment using the underlying graph taken as the Ithaca city, with arrivals from a historical police call dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-universe",
   "metadata": {},
   "source": [
    "### Package Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54262089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting out configuration parameter for the environment\n",
    "CONFIG =  or_suite.envs.env_configs.ambulance_graph_ithaca_config\n",
    "\n",
    "\n",
    "# Specifying training iteration, epLen, number of episodes, and number of iterations\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 1\n",
    "numIters = 2\n",
    "\n",
    "\n",
    "\n",
    "# Configuration parameters for running the experiment\n",
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, # save trajectory for calculating additional metrics\n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False # indicator for pickling final information\n",
    "                    }\n",
    "\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v1', config=CONFIG)\n",
    "mon_env = Monitor(ambulance_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-shooting",
   "metadata": {},
   "source": [
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comprehensive-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/ORSuite/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:138: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=5 and n_envs=1)\n",
      "  f\"You have specified a mini-batch size of {batch_size},\"\n"
     ]
    }
   ],
   "source": [
    "agents = { 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'Stable': or_suite.agents.ambulance.stable.stableAgent(CONFIG['epLen']),\n",
    "'Mode': or_suite.agents.ambulance.mode_graph.modeAgent(CONFIG['epLen']),\n",
    "'Median': or_suite.agents.ambulance.median_graph.medianAgent(CONFIG['epLen'], CONFIG['edges'], CONFIG['num_ambulance']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-dublin",
   "metadata": {},
   "source": [
    "Run the different heuristics in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honest-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "New Experiment Run\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "[-351.27500000000003, -485.40000000000003]\n",
      "2\n",
      "Writing to file ../data/ambulance_metric_SB PPO_2_0.25/data.csv\n",
      "Random\n",
      "Writing to file data.csv\n",
      "Stable\n",
      "Writing to file data.csv\n",
      "Mode\n",
      "Writing to file data.csv\n",
      "Median\n",
      "Writing to file data.csv\n",
      "  Algorithm    Reward      Time    Space\n",
      "0    Random -602.6500  3.713925 -11682.0\n",
      "1    Stable -491.1750  4.982460  -5116.5\n",
      "2      Mode -474.0875  4.925335  -6982.5\n",
      "3    Median -404.1125  4.143475  -5917.0\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(ambulance_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha))\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':\n",
    "        path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_ambulance)+'_'+str(alpha))\n",
    "        algo_list_radar.append(str(agent))\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11dfcb",
   "metadata": {},
   "source": [
    "Here we see with a quick set-up that the best-performing algorithm in this limited data regime is the Mode algorithm, essentially putting the ambulances at the estimated mode from the observed data thus far."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
