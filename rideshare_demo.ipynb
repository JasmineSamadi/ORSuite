{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OR Suite \n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making, including inventory control, resource allocation, ridesharing systems, and ambulance routing. In these models, an agent interacts with a system that has stochastic transitions and rewards, and aims to control the system by maximizing their cumulative rewards across the trajectory. Reinforcement learning has been shown in practice to be an effective technique for learning complex control policies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ridesharing Code Demo\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook, we walk through the Ambulance Routing problem with a 1-dimensional reinforcement learning environment in the space $X = [0, 1]$. Each ambulance in the problem can be located anywhere in $X$, so the state space is $S = X^k$, where $k$ is the number of ambulances. For this example there will be only one ambulance, so $k = 1$.\n",
    "\n",
    "The default distribution for call arrivals is $Beta(5, 2)$ over $[0,1]$, however any probability distribution defined over the interval $[0,1]$ is valid. The probability distribution can also change with each timestep.\n",
    "\n",
    "For example, in a problem with two ambulances, imagine the ambulances are initially located at $0.4$ and $0.6$, and the distance function being used is the $\\ell_1$ norm. The agent could choose to move the ambulances to $0.342$ and $0.887$. If a call arrived at $0.115$, ambulance 1, which was at $0.342$, would respond to that call, and the state at the end of the iteration would be ambulance 1 at $0.115$ and ambulance 2 at $0.887$. The agent could then choose new locations to move the ambulances to, and the cycle would repeat."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Package Installation\n",
    "First we import the necessary packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1]\n",
    "\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': True, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': False, \n",
    "                    'epLen' : epLen,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "\n",
    "rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'max_weight_fixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent(CONFIG['epLen'], num_cars, [1 for _ in range(len(starting_state))]),\n",
    "'closest_car' : or_suite.agents.rideshare.closest_car.closetCarAgent(CONFIG['epLen'], CONFIG)\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "\n",
    "linspace_alpha = []\n",
    "\n",
    "param_list = [list(p) for p in it.product(np.linspace(0,1,4),repeat = len(starting_state))]\n",
    "\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare'+str(agent)+'_'+str(num_cars)\n",
    "    if agent == 'max_weight_fixed':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env,agents[agent], param_list, DEFAULT_SETTINGS)\n",
    "    elif agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/rideshare_metric_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    path_list_radar.append('../data/rideshare_metric_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_radar.append(str(agent))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 0 3 7 0 1]\n",
      "action : 0\n",
      "new state: [0 0 3 7 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 0 3 7 1 3]\n",
      "Episode : 1\n",
      "state : [0 0 3 7 1 3]\n",
      "action : 0\n",
      "new state: [0 0 3 7 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 0 3 7 0 0]\n",
      "Episode : 2\n",
      "state : [0 0 3 7 0 0]\n",
      "action : 1\n",
      "new state: [0 0 3 7 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 0 3 7 3 1]\n",
      "Episode : 3\n",
      "state : [0 0 3 7 3 1]\n",
      "action : 2\n",
      "new state: [0 0 3 7 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [0 0 3 7 3 0]\n",
      "action : 2\n",
      "new state: [0 0 3 7 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [0 0 3 7 0 3]\n",
      "action : 0\n",
      "new state: [0 0 3 7 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.5\n",
      "final state: [0 0 3 7 1 0]\n",
      "Episode : 4\n",
      "state : [0 0 3 7 1 0]\n",
      "action : 1\n",
      "new state: [0 0 3 7 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 0 3 7 2 1]\n",
      "Episode : 5\n",
      "state : [0 0 3 7 2 1]\n",
      "action : 0\n",
      "new state: [0 0 3 7 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 0 3 7 2 0]\n",
      "Episode : 6\n",
      "state : [0 0 3 7 2 0]\n",
      "action : 1\n",
      "new state: [0 0 3 7 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 0 3 7 2 1]\n",
      "Episode : 7\n",
      "state : [0 0 3 7 2 1]\n",
      "action : 3\n",
      "new state: [0 1 3 6 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [0 1 3 6 3 0]\n",
      "action : 2\n",
      "new state: [1 1 2 6 1 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [1 1 2 6 1 2]\n",
      "action : 2\n",
      "new state: [1 1 2 6 3 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "state : [1 1 2 6 3 3]\n",
      "action : 1\n",
      "new state: [1 0 2 7 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [1 0 2 7 3 2]\n",
      "action : 0\n",
      "new state: [1 0 2 7 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "final state: [1 0 2 7 1 1]\n",
      "Episode : 8\n",
      "state : [1 0 2 7 1 1]\n",
      "action : 1\n",
      "new state: [1 0 2 7 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [1 0 2 7 1 3]\n",
      "Episode : 9\n",
      "state : [1 0 2 7 1 3]\n",
      "action : 0\n",
      "new state: [1 0 2 7 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [1 0 2 7 2 1]\n",
      "action : 1\n",
      "new state: [1 0 2 7 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [1 0 2 7 1 0]\n",
      "Episode : 10\n",
      "state : [1 0 2 7 1 0]\n",
      "action : 0\n",
      "new state: [1 0 2 7 0 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [1 0 2 7 0 0]\n",
      "action : 3\n",
      "new state: [1 0 2 7 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [1 0 2 7 3 2]\n",
      "action : 2\n",
      "new state: [1 0 2 7 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [1 0 2 7 2 3]\n",
      "action : 3\n",
      "new state: [1 0 2 7 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "state : [1 0 2 7 1 1]\n",
      "action : 2\n",
      "new state: [1 1 1 7 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -3.25\n",
      "final state: [1 1 1 7 0 0]\n",
      "Episode : 11\n",
      "state : [1 1 1 7 0 0]\n",
      "action : 1\n",
      "new state: [1 1 1 7 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [1 1 1 7 0 2]\n",
      "action : 3\n",
      "new state: [1 1 2 6 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [1 1 2 6 1 3]\n",
      "action : 3\n",
      "new state: [1 1 2 6 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [1 1 2 6 3 0]\n",
      "action : 0\n",
      "new state: [1 1 2 6 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.25\n",
      "state : [1 1 2 6 3 2]\n",
      "action : 2\n",
      "new state: [1 1 2 6 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -2.75\n",
      "final state: [1 1 2 6 2 1]\n",
      "Episode : 12\n",
      "state : [1 1 2 6 2 1]\n",
      "action : 0\n",
      "new state: [1 1 2 6 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [1 1 2 6 1 3]\n",
      "action : 1\n",
      "new state: [1 0 2 7 3 1]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "state : [1 0 2 7 3 1]\n",
      "action : 3\n",
      "new state: [1 1 2 6 1 1]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [1 1 2 6 1 1]\n",
      "action : 1\n",
      "new state: [1 1 2 6 0 0]\n",
      "reward: 0.0\n",
      "epReward so far: -0.25\n",
      "state : [1 1 2 6 0 0]\n",
      "action : 0\n",
      "new state: [1 1 2 6 3 3]\n",
      "reward: 0.0\n",
      "epReward so far: -0.25\n",
      "final state: [1 1 2 6 3 3]\n",
      "Episode : 13\n",
      "state : [1 1 2 6 3 3]\n",
      "action : 2\n",
      "new state: [1 1 2 6 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [1 1 2 6 1 3]\n",
      "action : 2\n",
      "new state: [1 1 2 6 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [1 1 2 6 2 2]\n",
      "action : 2\n",
      "new state: [1 1 2 6 0 3]\n",
      "reward: 0.0\n",
      "epReward so far: -1.5\n",
      "state : [1 1 2 6 0 3]\n",
      "action : 1\n",
      "new state: [1 1 2 6 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [1 1 2 6 1 1]\n",
      "action : 1\n",
      "new state: [1 1 2 6 0 1]\n",
      "reward: 0.0\n",
      "epReward so far: -2.25\n",
      "final state: [1 1 2 6 0 1]\n",
      "Episode : 14\n",
      "state : [1 1 2 6 0 1]\n",
      "action : 3\n",
      "new state: [1 2 2 5 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [1 2 2 5 0 1]\n",
      "action : 1\n",
      "new state: [1 2 2 5 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [1 2 2 5 0 3]\n",
      "action : 3\n",
      "new state: [1 2 2 5 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "state : [1 2 2 5 3 1]\n",
      "action : 2\n",
      "new state: [1 2 2 5 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [1 2 2 5 0 3]\n",
      "action : 1\n",
      "new state: [1 1 2 6 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -2.75\n",
      "final state: [1 1 2 6 0 3]\n",
      "Episode : 15\n",
      "state : [1 1 2 6 0 3]\n",
      "action : 1\n",
      "new state: [1 1 2 6 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [1 1 2 6 0 1]\n",
      "action : 3\n",
      "new state: [1 1 2 6 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [1 1 2 6 2 0]\n",
      "action : 3\n",
      "new state: [2 1 2 5 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -2.0\n",
      "state : [2 1 2 5 3 0]\n",
      "action : 3\n",
      "new state: [3 1 2 4 1 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.75\n",
      "state : [3 1 2 4 1 0]\n",
      "action : 0\n",
      "new state: [3 1 2 4 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "final state: [3 1 2 4 0 0]\n",
      "Episode : 16\n",
      "state : [3 1 2 4 0 0]\n",
      "action : 3\n",
      "new state: [4 1 2 3 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 1 2 3 2 0]\n",
      "action : 2\n",
      "new state: [4 1 2 3 2 3]\n",
      "reward: -0.0\n",
      "epReward so far: -0.75\n",
      "state : [4 1 2 3 2 3]\n",
      "action : 3\n",
      "new state: [4 1 2 3 0 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [4 1 2 3 0 0]\n",
      "action : 3\n",
      "new state: [5 1 2 2 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [5 1 2 2 2 2]\n",
      "action : 1\n",
      "new state: [5 0 3 2 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "final state: [5 0 3 2 2 2]\n",
      "Episode : 17\n",
      "state : [5 0 3 2 2 2]\n",
      "action : 0\n",
      "new state: [5 0 3 2 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 0 3 2 3 3]\n",
      "action : 1\n",
      "new state: [5 0 3 2 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [5 0 3 2 0 2]\n",
      "Episode : 18\n",
      "state : [5 0 3 2 0 2]\n",
      "action : 1\n",
      "new state: [5 0 3 2 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [5 0 3 2 3 1]\n",
      "Episode : 19\n",
      "state : [5 0 3 2 3 1]\n",
      "action : 0\n",
      "new state: [4 1 3 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 1 3 2 0 2]\n",
      "action : 2\n",
      "new state: [4 1 3 2 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [4 1 3 2 1 1]\n",
      "action : 2\n",
      "new state: [4 1 3 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [4 1 3 2 1 1]\n",
      "action : 3\n",
      "new state: [4 2 3 1 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "state : [4 2 3 1 0 3]\n",
      "action : 1\n",
      "new state: [4 1 3 2 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -3.0\n",
      "final state: [4 1 3 2 1 1]\n",
      "Episode : 20\n",
      "state : [4 1 3 2 1 1]\n",
      "action : 3\n",
      "new state: [4 2 3 1 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 2 3 1 1 3]\n",
      "action : 2\n",
      "new state: [4 2 3 1 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [4 2 3 1 2 1]\n",
      "action : 0\n",
      "new state: [3 3 3 1 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.0\n",
      "state : [3 3 3 1 3 2]\n",
      "action : 2\n",
      "new state: [3 3 3 1 3 3]\n",
      "reward: -0.5\n",
      "epReward so far: -2.5\n",
      "state : [3 3 3 1 3 3]\n",
      "action : 1\n",
      "new state: [3 2 3 2 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.25\n",
      "final state: [3 2 3 2 1 2]\n",
      "Episode : 21\n",
      "state : [3 2 3 2 1 2]\n",
      "action : 3\n",
      "new state: [3 2 3 2 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 2 3 2 1 0]\n",
      "action : 2\n",
      "new state: [3 2 3 2 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [3 2 3 2 1 0]\n",
      "action : 3\n",
      "new state: [3 2 3 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [3 2 3 2 1 1]\n",
      "action : 1\n",
      "new state: [3 2 3 2 0 2]\n",
      "reward: 0.0\n",
      "epReward so far: -2.25\n",
      "state : [3 2 3 2 0 2]\n",
      "action : 2\n",
      "new state: [3 2 3 2 0 0]\n",
      "reward: -0.5\n",
      "epReward so far: -2.75\n",
      "final state: [3 2 3 2 0 0]\n",
      "Episode : 22\n",
      "state : [3 2 3 2 0 0]\n",
      "action : 3\n",
      "new state: [3 2 3 2 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 2 3 2 3 0]\n",
      "action : 0\n",
      "new state: [3 2 3 2 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [3 2 3 2 2 0]\n",
      "action : 0\n",
      "new state: [3 2 3 2 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [3 2 3 2 3 3]\n",
      "action : 2\n",
      "new state: [3 2 3 2 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [3 2 3 2 1 2]\n",
      "action : 0\n",
      "new state: [3 2 3 2 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.5\n",
      "final state: [3 2 3 2 0 2]\n",
      "Episode : 23\n",
      "state : [3 2 3 2 0 2]\n",
      "action : 3\n",
      "new state: [3 2 4 1 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [3 2 4 1 0 3]\n",
      "action : 1\n",
      "new state: [3 2 4 1 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [3 2 4 1 0 2]\n",
      "action : 3\n",
      "new state: [3 2 4 1 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [3 2 4 1 1 3]\n",
      "action : 3\n",
      "new state: [3 2 4 1 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [3 2 4 1 0 1]\n",
      "action : 0\n",
      "new state: [2 3 4 1 1 0]\n",
      "reward: 0.25\n",
      "epReward so far: -2.5\n",
      "final state: [2 3 4 1 1 0]\n",
      "Episode : 24\n",
      "state : [2 3 4 1 1 0]\n",
      "action : 3\n",
      "new state: [2 3 4 1 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [2 3 4 1 0 1]\n",
      "action : 2\n",
      "new state: [2 4 3 1 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [2 4 3 1 0 3]\n",
      "action : 2\n",
      "new state: [2 4 3 1 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [2 4 3 1 2 3]\n",
      "action : 3\n",
      "new state: [2 4 3 1 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -2.5\n",
      "state : [2 4 3 1 2 3]\n",
      "action : 0\n",
      "new state: [1 4 3 2 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -3.0\n",
      "final state: [1 4 3 2 3 1]\n",
      "Episode : 25\n",
      "state : [1 4 3 2 3 1]\n",
      "action : 1\n",
      "new state: [1 4 3 2 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [1 4 3 2 0 3]\n",
      "action : 1\n",
      "new state: [1 4 3 2 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [1 4 3 2 0 0]\n",
      "action : 0\n",
      "new state: [1 4 3 2 0 3]\n",
      "reward: -0.0\n",
      "epReward so far: -1.25\n",
      "state : [1 4 3 2 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 2\n",
      "new state: [0 5 2 3 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [0 5 2 3 1 3]\n",
      "action : 0\n",
      "new state: [0 5 2 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [0 5 2 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 5 2 3 0 2]\n",
      "action : 1\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 2\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 2\n",
      "new state: [1 4 2 3 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [1 4 2 3 2 1]\n",
      "action : 1\n",
      "new state: [1 4 2 3 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [1 4 2 3 1 0]\n",
      "action : 1\n",
      "new state: [2 3 2 3 1 2]\n",
      "reward: 0.25\n",
      "epReward so far: -2.5\n",
      "final state: [2 3 2 3 1 2]\n",
      "Episode : 28\n",
      "state : [2 3 2 3 1 2]\n",
      "action : 2\n",
      "new state: [2 3 2 3 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [2 3 2 3 1 2]\n",
      "action : 2\n",
      "new state: [2 3 2 3 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [2 3 2 3 2 2]\n",
      "action : 1\n",
      "new state: [2 2 3 3 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [2 2 3 3 2 0]\n",
      "action : 2\n",
      "new state: [3 2 2 3 0 3]\n",
      "reward: 0.25\n",
      "epReward so far: -2.0\n",
      "state : [3 2 2 3 0 3]\n",
      "action : 0\n",
      "new state: [3 2 2 3 0 3]\n",
      "reward: -0.0\n",
      "epReward so far: -2.0\n",
      "final state: [3 2 2 3 0 3]\n",
      "Episode : 29\n",
      "state : [3 2 2 3 0 3]\n",
      "action : 1\n",
      "new state: [3 2 2 3 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 2 2 3 3 0]\n",
      "action : 1\n",
      "new state: [4 1 2 3 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [4 1 2 3 3 1]\n",
      "action : 0\n",
      "new state: [3 2 2 3 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [3 2 2 3 3 0]\n",
      "action : 1\n",
      "new state: [3 2 2 3 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "state : [3 2 2 3 2 2]\n",
      "action : 3\n",
      "new state: [3 2 3 2 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.25\n",
      "final state: [3 2 3 2 0 2]\n",
      "Episode : 30\n",
      "state : [3 2 3 2 0 2]\n",
      "action : 2\n",
      "new state: [3 2 3 2 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [3 2 3 2 1 1]\n",
      "action : 0\n",
      "new state: [2 3 3 2 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [2 3 3 2 2 1]\n",
      "action : 1\n",
      "new state: [2 3 3 2 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [2 3 3 2 1 0]\n",
      "action : 2\n",
      "new state: [3 3 2 2 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.5\n",
      "state : [3 3 2 2 3 2]\n",
      "action : 2\n",
      "new state: [3 3 2 2 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -3.0\n",
      "final state: [3 3 2 2 0 3]\n",
      "Episode : 31\n",
      "state : [3 3 2 2 0 3]\n",
      "action : 0\n",
      "new state: [3 3 2 2 3 3]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [3 3 2 2 3 3]\n",
      "action : 0\n",
      "new state: [3 3 2 2 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 3 2 2 3 0]\n",
      "action : 1\n",
      "new state: [4 2 2 2 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [4 2 2 2 3 0]\n",
      "action : 1\n",
      "new state: [5 1 2 2 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [5 1 2 2 2 1]\n",
      "action : 0\n",
      "new state: [5 1 2 2 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "final state: [5 1 2 2 0 1]\n",
      "Episode : 32\n",
      "state : [5 1 2 2 0 1]\n",
      "action : 2\n",
      "new state: [5 1 2 2 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 1 2 2 1 3]\n",
      "action : 0\n",
      "new state: [4 1 2 3 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [4 1 2 3 2 3]\n",
      "action : 2\n",
      "new state: [4 1 2 3 2 0]\n",
      "reward: -0.0\n",
      "epReward so far: -1.25\n",
      "state : [4 1 2 3 2 0]\n",
      "action : 3\n",
      "new state: [5 1 2 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [5 1 2 2 0 2]\n",
      "action : 1\n",
      "new state: [5 0 3 2 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.25\n",
      "final state: [5 0 3 2 3 2]\n",
      "Episode : 33\n",
      "state : [5 0 3 2 3 2]\n",
      "action : 2\n",
      "new state: [5 0 3 2 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 0 3 2 2 3]\n",
      "action : 2\n",
      "new state: [5 0 2 3 1 2]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [5 0 2 3 1 2]\n",
      "action : 3\n",
      "new state: [5 0 3 2 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.75\n",
      "state : [5 0 3 2 3 2]\n",
      "action : 0\n",
      "new state: [4 0 4 2 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [4 0 4 2 0 1]\n",
      "action : 0\n",
      "new state: [4 0 4 2 1 1]\n",
      "reward: -0.0\n",
      "epReward so far: -1.25\n",
      "final state: [4 0 4 2 1 1]\n",
      "Episode : 34\n",
      "state : [4 0 4 2 1 1]\n",
      "action : 3\n",
      "new state: [4 1 4 1 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 1 4 1 0 1]\n",
      "action : 2\n",
      "new state: [4 1 4 1 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [4 1 4 1 0 0]\n",
      "action : 3\n",
      "new state: [5 1 4 0 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [5 1 4 0 3 1]\n",
      "action : 2\n",
      "new state: [5 1 4 0 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "state : [5 1 4 0 0 2]\n",
      "action : 3\n",
      "new state: [5 1 4 0 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10003.0\n",
      "final state: [5 1 4 0 3 2]\n",
      "Episode : 35\n",
      "state : [5 1 4 0 3 2]\n",
      "action : 0\n",
      "new state: [5 1 4 0 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 1 4 0 3 1]\n",
      "action : 0\n",
      "new state: [5 1 4 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 1 4 0 1 1]\n",
      "action : 0\n",
      "new state: [4 2 4 0 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [4 2 4 0 2 0]\n",
      "action : 0\n",
      "new state: [4 2 4 0 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.75\n",
      "state : [4 2 4 0 0 2]\n",
      "action : 3\n",
      "new state: [4 2 4 0 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10002.75\n",
      "final state: [4 2 4 0 3 1]\n",
      "Episode : 36\n",
      "state : [4 2 4 0 3 1]\n",
      "action : 3\n",
      "new state: [4 2 4 0 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [4 2 4 0 1 1]\n",
      "Episode : 37\n",
      "state : [4 2 4 0 1 1]\n",
      "action : 1\n",
      "new state: [4 2 4 0 0 2]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [4 2 4 0 0 2]\n",
      "action : 0\n",
      "new state: [4 2 4 0 3 3]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [4 2 4 0 3 3]\n",
      "action : 0\n",
      "new state: [3 2 4 1 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 2 4 1 1 3]\n",
      "action : 3\n",
      "new state: [3 2 4 1 1 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [3 2 4 1 1 2]\n",
      "action : 3\n",
      "new state: [3 2 4 1 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "final state: [3 2 4 1 2 3]\n",
      "Episode : 38\n",
      "state : [3 2 4 1 2 3]\n",
      "action : 2\n",
      "new state: [3 2 3 2 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [3 2 3 2 2 0]\n",
      "action : 3\n",
      "new state: [4 2 3 1 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.25\n",
      "state : [4 2 3 1 3 0]\n",
      "action : 0\n",
      "new state: [4 2 3 1 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.75\n",
      "state : [4 2 3 1 1 1]\n",
      "action : 0\n",
      "new state: [4 2 3 1 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [4 2 3 1 3 2]\n",
      "action : 1\n",
      "new state: [4 2 3 1 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "final state: [4 2 3 1 2 0]\n",
      "Episode : 39\n",
      "state : [4 2 3 1 2 0]\n",
      "action : 1\n",
      "new state: [5 1 3 1 3 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 1 3 1 3 3]\n",
      "action : 0\n",
      "new state: [4 1 3 2 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [4 1 3 2 2 3]\n",
      "action : 0\n",
      "new state: [4 1 3 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [4 1 3 2 2 0]\n",
      "action : 2\n",
      "new state: [5 1 2 2 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.75\n",
      "state : [5 1 2 2 2 0]\n",
      "action : 1\n",
      "new state: [6 0 2 2 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -2.25\n",
      "final state: [6 0 2 2 0 1]\n",
      "Episode : 40\n",
      "state : [6 0 2 2 0 1]\n",
      "action : 1\n",
      "new state: [6 0 2 2 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 2 2 0 2]\n",
      "Episode : 41\n",
      "state : [6 0 2 2 0 2]\n",
      "action : 1\n",
      "new state: [6 0 2 2 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 2 2 2 2]\n",
      "Episode : 42\n",
      "state : [6 0 2 2 2 2]\n",
      "action : 3\n",
      "new state: [6 0 3 1 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 0 3 1 2 3]\n",
      "action : 3\n",
      "new state: [6 0 3 1 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [6 0 3 1 3 1]\n",
      "action : 0\n",
      "new state: [6 0 3 1 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [6 0 3 1 3 2]\n",
      "action : 2\n",
      "new state: [6 0 3 1 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -2.75\n",
      "state : [6 0 3 1 2 0]\n",
      "action : 3\n",
      "new state: [7 0 3 0 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -3.25\n",
      "final state: [7 0 3 0 2 3]\n",
      "Episode : 43\n",
      "state : [7 0 3 0 2 3]\n",
      "action : 1\n",
      "new state: [7 0 3 0 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 3 0 2 0]\n",
      "Episode : 44\n",
      "state : [7 0 3 0 2 0]\n",
      "action : 2\n",
      "new state: [8 0 2 0 0 1]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [8 0 2 0 0 1]\n",
      "action : 1\n",
      "new state: [8 0 2 0 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -9999.75\n",
      "final state: [8 0 2 0 2 1]\n",
      "Episode : 45\n",
      "state : [8 0 2 0 2 1]\n",
      "action : 3\n",
      "new state: [8 0 2 0 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 0 2 0 2 0]\n",
      "Episode : 46\n",
      "state : [8 0 2 0 2 0]\n",
      "action : 1\n",
      "new state: [8 0 2 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 0 2 0 1 3]\n",
      "Episode : 47\n",
      "state : [8 0 2 0 1 3]\n",
      "action : 2\n",
      "new state: [8 0 1 1 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [8 0 1 1 1 1]\n",
      "action : 0\n",
      "new state: [7 1 1 1 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 1 1 1 0 1]\n",
      "action : 0\n",
      "new state: [6 2 1 1 3 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [6 2 1 1 3 2]\n",
      "action : 1\n",
      "new state: [6 2 1 1 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [6 2 1 1 2 0]\n",
      "action : 1\n",
      "new state: [7 1 1 1 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -2.25\n",
      "final state: [7 1 1 1 3 0]\n",
      "Episode : 48\n",
      "state : [7 1 1 1 3 0]\n",
      "action : 3\n",
      "new state: [8 1 1 0 0 0]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [8 1 1 0 0 0]\n",
      "action : 3\n",
      "new state: [8 1 1 0 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -9999.75\n",
      "final state: [8 1 1 0 0 2]\n",
      "Episode : 49\n",
      "state : [8 1 1 0 0 2]\n",
      "action : 0\n",
      "new state: [7 1 2 0 0 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [7 1 2 0 0 3]\n",
      "action : 1\n",
      "new state: [7 1 2 0 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [7 1 2 0 2 0]\n",
      "action : 2\n",
      "new state: [8 1 1 0 1 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [8 1 1 0 1 3]\n",
      "action : 1\n",
      "new state: [8 0 1 1 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: 0.0\n",
      "state : [8 0 1 1 2 0]\n",
      "action : 1\n",
      "new state: [8 0 1 1 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 0 1 1 2 2]\n",
      "Episode : 50\n",
      "state : [8 0 1 1 2 2]\n",
      "action : 1\n",
      "new state: [8 0 1 1 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 0 1 1 3 1]\n",
      "Episode : 51\n",
      "state : [8 0 1 1 3 1]\n",
      "action : 2\n",
      "new state: [8 1 0 1 0 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [8 1 0 1 0 0]\n",
      "action : 0\n",
      "new state: [8 1 0 1 3 3]\n",
      "reward: 0.0\n",
      "epReward so far: -0.5\n",
      "state : [8 1 0 1 3 3]\n",
      "action : 2\n",
      "new state: [8 1 0 1 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [8 1 0 1 3 0]\n",
      "Episode : 52\n",
      "state : [8 1 0 1 3 0]\n",
      "action : 2\n",
      "new state: [8 1 0 1 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 1 0 1 0 2]\n",
      "Episode : 53\n",
      "state : [8 1 0 1 0 2]\n",
      "action : 0\n",
      "new state: [8 1 0 1 3 1]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [8 1 0 1 3 1]\n",
      "action : 3\n",
      "new state: [8 2 0 0 3 0]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [8 2 0 0 3 0]\n",
      "action : 2\n",
      "new state: [8 2 0 0 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -9999.75\n",
      "final state: [8 2 0 0 3 2]\n",
      "Episode : 54\n",
      "state : [8 2 0 0 3 2]\n",
      "action : 2\n",
      "new state: [8 2 0 0 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 2 0 0 2 2]\n",
      "Episode : 55\n",
      "state : [8 2 0 0 2 2]\n",
      "action : 1\n",
      "new state: [8 1 1 0 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [8 1 1 0 2 2]\n",
      "action : 2\n",
      "new state: [8 1 1 0 2 1]\n",
      "reward: 0.0\n",
      "epReward so far: -0.75\n",
      "state : [8 1 1 0 2 1]\n",
      "action : 2\n",
      "new state: [8 2 0 0 2 2]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "state : [8 2 0 0 2 2]\n",
      "action : 2\n",
      "new state: [8 2 0 0 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [8 2 0 0 3 1]\n",
      "Episode : 56\n",
      "state : [8 2 0 0 3 1]\n",
      "action : 1\n",
      "new state: [8 2 0 0 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [8 2 0 0 1 1]\n",
      "action : 0\n",
      "new state: [8 2 0 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [8 2 0 0 1 1]\n",
      "action : 2\n",
      "new state: [8 2 0 0 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [8 2 0 0 2 1]\n",
      "Episode : 57\n",
      "state : [8 2 0 0 2 1]\n",
      "action : 0\n",
      "new state: [8 2 0 0 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [8 2 0 0 1 2]\n",
      "action : 3\n",
      "new state: [8 2 0 0 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [8 2 0 0 3 2]\n",
      "Episode : 58\n",
      "state : [8 2 0 0 3 2]\n",
      "action : 2\n",
      "new state: [8 2 0 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 2 0 0 1 3]\n",
      "Episode : 59\n",
      "state : [8 2 0 0 1 3]\n",
      "action : 0\n",
      "new state: [7 2 0 1 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 2 0 1 2 1]\n",
      "action : 0\n",
      "new state: [7 2 0 1 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 2 0 1 0 0]\n",
      "action : 2\n",
      "new state: [7 2 0 1 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [7 2 0 1 1 0]\n",
      "Episode : 60\n",
      "state : [7 2 0 1 1 0]\n",
      "action : 0\n",
      "new state: [7 2 0 1 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 2 0 1 2 2]\n",
      "action : 1\n",
      "new state: [7 1 1 1 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 1 1 1 0 0]\n",
      "action : 1\n",
      "new state: [8 0 1 1 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [8 0 1 1 2 3]\n",
      "action : 3\n",
      "new state: [8 0 1 1 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [8 0 1 1 2 0]\n",
      "action : 2\n",
      "new state: [9 0 0 1 3 0]\n",
      "reward: 0.25\n",
      "epReward so far: -2.5\n",
      "final state: [9 0 0 1 3 0]\n",
      "Episode : 61\n",
      "state : [9 0 0 1 3 0]\n",
      "action : 1\n",
      "new state: [9 0 0 1 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 2 1]\n",
      "Episode : 62\n",
      "state : [9 0 0 1 2 1]\n",
      "action : 3\n",
      "new state: [9 0 0 1 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [9 0 0 1 2 3]\n",
      "action : 1\n",
      "new state: [9 0 0 1 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [9 0 0 1 0 2]\n",
      "Episode : 63\n",
      "state : [9 0 0 1 0 2]\n",
      "action : 0\n",
      "new state: [8 0 1 1 3 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [8 0 1 1 3 3]\n",
      "action : 0\n",
      "new state: [8 0 1 1 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [8 0 1 1 3 0]\n",
      "action : 2\n",
      "new state: [9 0 0 1 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [9 0 0 1 0 2]\n",
      "action : 3\n",
      "new state: [9 0 0 1 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [9 0 0 1 0 2]\n",
      "action : 1\n",
      "new state: [9 0 0 1 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.75\n",
      "final state: [9 0 0 1 2 1]\n",
      "Episode : 64\n",
      "state : [9 0 0 1 2 1]\n",
      "action : 3\n",
      "new state: [9 0 0 1 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [9 0 0 1 1 2]\n",
      "action : 2\n",
      "new state: [9 0 0 1 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [9 0 0 1 0 0]\n",
      "Episode : 65\n",
      "state : [9 0 0 1 0 0]\n",
      "action : 2\n",
      "new state: [9 0 0 1 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 1 2]\n",
      "Episode : 66\n",
      "state : [9 0 0 1 1 2]\n",
      "action : 1\n",
      "new state: [9 0 0 1 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 2 2]\n",
      "Episode : 67\n",
      "state : [9 0 0 1 2 2]\n",
      "action : 1\n",
      "new state: [9 0 0 1 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 1 1]\n",
      "Episode : 68\n",
      "state : [9 0 0 1 1 1]\n",
      "action : 1\n",
      "new state: [9 0 0 1 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 2 0]\n",
      "Episode : 69\n",
      "state : [9 0 0 1 2 0]\n",
      "action : 1\n",
      "new state: [9 0 0 1 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 2 3]\n",
      "Episode : 70\n",
      "state : [9 0 0 1 2 3]\n",
      "action : 1\n",
      "new state: [9 0 0 1 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 1 2]\n",
      "Episode : 71\n",
      "state : [9 0 0 1 1 2]\n",
      "action : 1\n",
      "new state: [9 0 0 1 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 3 1]\n",
      "Episode : 72\n",
      "state : [9 0 0 1 3 1]\n",
      "action : 1\n",
      "new state: [9 0 0 1 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 1 1]\n",
      "Episode : 73\n",
      "state : [9 0 0 1 1 1]\n",
      "action : 1\n",
      "new state: [9 0 0 1 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [9 0 0 1 3 3]\n",
      "Episode : 74\n",
      "state : [9 0 0 1 3 3]\n",
      "action : 0\n",
      "new state: [8 0 0 2 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [8 0 0 2 3 0]\n",
      "action : 3\n",
      "new state: [8 0 0 2 3 1]\n",
      "reward: -0.0\n",
      "epReward so far: -0.75\n",
      "state : [8 0 0 2 3 1]\n",
      "action : 3\n",
      "new state: [8 1 0 1 3 2]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "state : [8 1 0 1 3 2]\n",
      "action : 3\n",
      "new state: [8 1 0 1 2 3]\n",
      "reward: -0.0\n",
      "epReward so far: -0.5\n",
      "state : [8 1 0 1 2 3]\n",
      "action : 1\n",
      "new state: [8 1 0 1 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "final state: [8 1 0 1 1 3]\n",
      "Episode : 75\n",
      "state : [8 1 0 1 1 3]\n",
      "action : 1\n",
      "new state: [8 0 0 2 2 1]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [8 0 0 2 2 1]\n",
      "action : 3\n",
      "new state: [8 1 0 1 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.25\n",
      "state : [8 1 0 1 2 2]\n",
      "action : 0\n",
      "new state: [7 1 1 1 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.0\n",
      "state : [7 1 1 1 2 0]\n",
      "action : 3\n",
      "new state: [7 1 1 1 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [7 1 1 1 1 3]\n",
      "action : 1\n",
      "new state: [7 0 1 2 0 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.5\n",
      "final state: [7 0 1 2 0 0]\n",
      "Episode : 76\n",
      "state : [7 0 1 2 0 0]\n",
      "action : 1\n",
      "new state: [7 0 1 2 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 1 2 1 2]\n",
      "Episode : 77\n",
      "state : [7 0 1 2 1 2]\n",
      "action : 0\n",
      "new state: [7 0 1 2 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 1 2 0 2]\n",
      "action : 1\n",
      "new state: [7 0 1 2 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 0 1 2 0 2]\n",
      "Episode : 78\n",
      "state : [7 0 1 2 0 2]\n",
      "action : 1\n",
      "new state: [7 0 1 2 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 1 2 0 1]\n",
      "Episode : 79\n",
      "state : [7 0 1 2 0 1]\n",
      "action : 2\n",
      "new state: [7 0 1 2 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 1 2 1 2]\n",
      "action : 2\n",
      "new state: [7 0 1 2 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [7 0 1 2 1 0]\n",
      "action : 0\n",
      "new state: [7 0 1 2 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [7 0 1 2 2 2]\n",
      "action : 1\n",
      "new state: [7 0 1 2 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10002.25\n",
      "final state: [7 0 1 2 1 3]\n",
      "Episode : 80\n",
      "state : [7 0 1 2 1 3]\n",
      "action : 3\n",
      "new state: [7 0 1 2 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 1 2 0 0]\n",
      "action : 0\n",
      "new state: [7 0 1 2 0 1]\n",
      "reward: 0.0\n",
      "epReward so far: -0.75\n",
      "state : [7 0 1 2 0 1]\n",
      "action : 3\n",
      "new state: [7 0 1 2 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [7 0 1 2 3 2]\n",
      "action : 3\n",
      "new state: [7 0 2 1 3 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [7 0 2 1 3 2]\n",
      "action : 1\n",
      "new state: [7 0 2 1 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [7 0 2 1 0 1]\n",
      "Episode : 81\n",
      "state : [7 0 2 1 0 1]\n",
      "action : 3\n",
      "new state: [7 1 2 0 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 1 2 0 3 2]\n",
      "action : 0\n",
      "new state: [6 1 3 0 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [6 1 3 0 2 0]\n",
      "action : 1\n",
      "new state: [7 0 3 0 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "state : [7 0 3 0 1 0]\n",
      "action : 3\n",
      "new state: [7 0 3 0 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.5\n",
      "final state: [7 0 3 0 3 0]\n",
      "Episode : 82\n",
      "state : [7 0 3 0 3 0]\n",
      "action : 1\n",
      "new state: [7 0 3 0 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 3 0 3 1]\n",
      "Episode : 83\n",
      "state : [7 0 3 0 3 1]\n",
      "action : 2\n",
      "new state: [7 0 3 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 3 0 1 1]\n",
      "action : 2\n",
      "new state: [7 0 3 0 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [7 0 3 0 2 1]\n",
      "action : 2\n",
      "new state: [7 0 3 0 0 1]\n",
      "reward: -0.0\n",
      "epReward so far: -1.5\n",
      "state : [7 0 3 0 0 1]\n",
      "action : 0\n",
      "new state: [6 1 3 0 3 1]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [6 1 3 0 3 1]\n",
      "action : 3\n",
      "new state: [6 1 3 0 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [6 1 3 0 1 2]\n",
      "Episode : 84\n",
      "state : [6 1 3 0 1 2]\n",
      "action : 3\n",
      "new state: [6 1 3 0 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 1 3 0 2 0]\n",
      "Episode : 85\n",
      "state : [6 1 3 0 2 0]\n",
      "action : 0\n",
      "new state: [6 1 3 0 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 1 3 0 3 3]\n",
      "action : 0\n",
      "new state: [6 1 3 0 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [6 1 3 0 3 0]\n",
      "action : 2\n",
      "new state: [6 1 3 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [6 1 3 0 1 1]\n",
      "action : 2\n",
      "new state: [6 2 2 0 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "state : [6 2 2 0 2 0]\n",
      "action : 3\n",
      "new state: [6 2 2 0 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10003.0\n",
      "final state: [6 2 2 0 3 0]\n",
      "Episode : 86\n",
      "state : [6 2 2 0 3 0]\n",
      "action : 0\n",
      "new state: [6 2 2 0 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 2 2 0 1 0]\n",
      "action : 3\n",
      "new state: [6 2 2 0 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [6 2 2 0 0 1]\n",
      "Episode : 87\n",
      "state : [6 2 2 0 0 1]\n",
      "action : 2\n",
      "new state: [6 3 1 0 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [6 3 1 0 1 3]\n",
      "action : 1\n",
      "new state: [6 2 1 1 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [6 2 1 1 2 0]\n",
      "action : 3\n",
      "new state: [7 2 1 0 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.75\n",
      "state : [7 2 1 0 0 1]\n",
      "action : 3\n",
      "new state: [7 2 1 0 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 2 1 0 1 0]\n",
      "Episode : 88\n",
      "state : [7 2 1 0 1 0]\n",
      "action : 1\n",
      "new state: [7 2 1 0 2 1]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [7 2 1 0 2 1]\n",
      "action : 0\n",
      "new state: [6 3 1 0 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [6 3 1 0 0 1]\n",
      "action : 2\n",
      "new state: [6 4 0 0 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [6 4 0 0 1 3]\n",
      "action : 3\n",
      "new state: [6 4 0 0 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.0\n",
      "final state: [6 4 0 0 3 3]\n",
      "Episode : 89\n",
      "state : [6 4 0 0 3 3]\n",
      "action : 0\n",
      "new state: [6 4 0 0 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 4 0 0 3 3]\n",
      "action : 0\n",
      "new state: [6 4 0 0 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [6 4 0 0 1 2]\n",
      "action : 2\n",
      "new state: [6 4 0 0 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.5\n",
      "final state: [6 4 0 0 3 1]\n",
      "Episode : 90\n",
      "state : [6 4 0 0 3 1]\n",
      "action : 2\n",
      "new state: [6 4 0 0 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 4 0 0 3 0]\n",
      "Episode : 91\n",
      "state : [6 4 0 0 3 0]\n",
      "action : 1\n",
      "new state: [7 3 0 0 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 3 0 0 0 2]\n",
      "action : 1\n",
      "new state: [7 3 0 0 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 3 0 0 1 0]\n",
      "action : 2\n",
      "new state: [7 3 0 0 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [7 3 0 0 1 0]\n",
      "Episode : 92\n",
      "state : [7 3 0 0 1 0]\n",
      "action : 0\n",
      "new state: [7 3 0 0 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 3 0 0 1 0]\n",
      "action : 0\n",
      "new state: [7 3 0 0 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [7 3 0 0 0 2]\n",
      "action : 3\n",
      "new state: [7 3 0 0 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.0\n",
      "final state: [7 3 0 0 2 2]\n",
      "Episode : 93\n",
      "state : [7 3 0 0 2 2]\n",
      "action : 1\n",
      "new state: [7 3 0 0 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 3 0 0 0 1]\n",
      "action : 2\n",
      "new state: [7 3 0 0 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 3 0 0 0 0]\n",
      "Episode : 94\n",
      "state : [7 3 0 0 0 0]\n",
      "action : 3\n",
      "new state: [7 3 0 0 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 3 0 0 2 1]\n",
      "Episode : 95\n",
      "state : [7 3 0 0 2 1]\n",
      "action : 3\n",
      "new state: [7 3 0 0 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 3 0 0 3 2]\n",
      "Episode : 96\n",
      "state : [7 3 0 0 3 2]\n",
      "action : 2\n",
      "new state: [7 3 0 0 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 3 0 0 1 2]\n",
      "Episode : 97\n",
      "state : [7 3 0 0 1 2]\n",
      "action : 2\n",
      "new state: [7 3 0 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 3 0 0 1 3]\n",
      "Episode : 98\n",
      "state : [7 3 0 0 1 3]\n",
      "action : 0\n",
      "new state: [7 3 0 0 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 3 0 0 3 3]\n",
      "action : 3\n",
      "new state: [7 3 0 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 3 0 0 1 3]\n",
      "Episode : 99\n",
      "state : [7 3 0 0 1 3]\n",
      "action : 3\n",
      "new state: [7 3 0 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 3 0 0 1 3]\n",
      "Episode : 0\n",
      "state : [7 3 0 0 1 3]\n",
      "action : 1\n",
      "new state: [7 2 0 1 3 2]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [7 2 0 1 3 2]\n",
      "action : 0\n",
      "new state: [7 2 0 1 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [7 2 0 1 3 1]\n",
      "action : 1\n",
      "new state: [7 2 0 1 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 2 0 1 3 0]\n",
      "action : 2\n",
      "new state: [7 2 0 1 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [7 2 0 1 0 2]\n",
      "Episode : 1\n",
      "state : [7 2 0 1 0 2]\n",
      "action : 2\n",
      "new state: [7 2 0 1 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 2 0 1 2 0]\n",
      "Episode : 2\n",
      "state : [7 2 0 1 2 0]\n",
      "action : 3\n",
      "new state: [8 2 0 0 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [8 2 0 0 2 3]\n",
      "action : 3\n",
      "new state: [8 2 0 0 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [8 2 0 0 0 2]\n",
      "Episode : 3\n",
      "state : [8 2 0 0 0 2]\n",
      "action : 3\n",
      "new state: [8 2 0 0 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [8 2 0 0 0 3]\n",
      "Episode : 4\n",
      "state : [8 2 0 0 0 3]\n",
      "action : 1\n",
      "new state: [8 1 0 1 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [8 1 0 1 0 3]\n",
      "action : 1\n",
      "new state: [8 1 0 1 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [8 1 0 1 1 2]\n",
      "action : 0\n",
      "new state: [8 1 0 1 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [8 1 0 1 3 1]\n",
      "action : 1\n",
      "new state: [8 1 0 1 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [8 1 0 1 3 0]\n",
      "action : 2\n",
      "new state: [8 1 0 1 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10002.75\n",
      "final state: [8 1 0 1 3 1]\n",
      "Episode : 5\n",
      "state : [8 1 0 1 3 1]\n",
      "action : 0\n",
      "new state: [7 2 0 1 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 2 0 1 2 2]\n",
      "action : 3\n",
      "new state: [7 2 1 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 2 1 0 1 1]\n",
      "action : 3\n",
      "new state: [7 2 1 0 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [7 2 1 0 0 0]\n",
      "Episode : 6\n",
      "state : [7 2 1 0 0 0]\n",
      "action : 0\n",
      "new state: [7 2 1 0 2 2]\n",
      "reward: 0.0\n",
      "epReward so far: 0.0\n",
      "state : [7 2 1 0 2 2]\n",
      "action : 0\n",
      "new state: [7 2 1 0 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 2 1 0 2 3]\n",
      "action : 2\n",
      "new state: [7 2 0 1 1 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "state : [7 2 0 1 1 3]\n",
      "action : 0\n",
      "new state: [7 2 0 1 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [7 2 0 1 1 0]\n",
      "action : 1\n",
      "new state: [8 1 0 1 3 3]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "final state: [8 1 0 1 3 3]\n",
      "Episode : 7\n",
      "state : [8 1 0 1 3 3]\n",
      "action : 1\n",
      "new state: [8 1 0 1 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [8 1 0 1 0 0]\n",
      "action : 2\n",
      "new state: [8 1 0 1 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [8 1 0 1 0 2]\n",
      "Episode : 8\n",
      "state : [8 1 0 1 0 2]\n",
      "action : 3\n",
      "new state: [8 1 0 1 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [8 1 0 1 0 2]\n",
      "action : 1\n",
      "new state: [8 0 1 1 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [8 0 1 1 2 1]\n",
      "action : 1\n",
      "new state: [8 0 1 1 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [8 0 1 1 0 1]\n",
      "Episode : 9\n",
      "state : [8 0 1 1 0 1]\n",
      "action : 3\n",
      "new state: [8 0 1 1 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [8 0 1 1 3 2]\n",
      "action : 3\n",
      "new state: [8 0 2 0 2 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "state : [8 0 2 0 2 3]\n",
      "action : 0\n",
      "new state: [8 0 2 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [8 0 2 0 1 1]\n",
      "action : 0\n",
      "new state: [7 1 2 0 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [7 1 2 0 0 0]\n",
      "action : 1\n",
      "new state: [7 1 2 0 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "final state: [7 1 2 0 1 0]\n",
      "Episode : 10\n",
      "state : [7 1 2 0 1 0]\n",
      "action : 3\n",
      "new state: [7 1 2 0 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 1 2 0 0 2]\n",
      "Episode : 11\n",
      "state : [7 1 2 0 0 2]\n",
      "action : 0\n",
      "new state: [6 1 3 0 2 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [6 1 3 0 2 3]\n",
      "action : 1\n",
      "new state: [6 0 3 1 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.25\n",
      "state : [6 0 3 1 2 0]\n",
      "action : 2\n",
      "new state: [7 0 2 1 3 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.0\n",
      "state : [7 0 2 1 3 3]\n",
      "action : 1\n",
      "new state: [7 0 2 1 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 2 1 2 1]\n",
      "Episode : 12\n",
      "state : [7 0 2 1 2 1]\n",
      "action : 3\n",
      "new state: [7 1 2 0 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 1 2 0 1 3]\n",
      "action : 2\n",
      "new state: [7 1 1 1 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [7 1 1 1 2 2]\n",
      "action : 1\n",
      "new state: [7 0 2 1 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [7 0 2 1 1 1]\n",
      "action : 2\n",
      "new state: [7 0 2 1 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "state : [7 0 2 1 2 3]\n",
      "action : 2\n",
      "new state: [7 0 1 2 1 1]\n",
      "reward: 0.25\n",
      "epReward so far: -2.25\n",
      "final state: [7 0 1 2 1 1]\n",
      "Episode : 13\n",
      "state : [7 0 1 2 1 1]\n",
      "action : 3\n",
      "new state: [7 0 1 2 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 1 2 3 1]\n",
      "action : 2\n",
      "new state: [7 0 1 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [7 0 1 2 2 0]\n",
      "action : 2\n",
      "new state: [8 0 0 2 0 1]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [8 0 0 2 0 1]\n",
      "action : 0\n",
      "new state: [8 0 0 2 3 3]\n",
      "reward: -0.0\n",
      "epReward so far: -1.25\n",
      "state : [8 0 0 2 3 3]\n",
      "action : 2\n",
      "new state: [8 0 0 2 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [8 0 0 2 3 3]\n",
      "Episode : 14\n",
      "state : [8 0 0 2 3 3]\n",
      "action : 0\n",
      "new state: [7 0 0 3 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 0 3 0 2]\n",
      "action : 3\n",
      "new state: [7 0 0 3 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [7 0 0 3 0 2]\n",
      "action : 0\n",
      "new state: [6 0 1 3 2 1]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [6 0 1 3 2 1]\n",
      "action : 2\n",
      "new state: [6 1 0 3 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [6 1 0 3 2 0]\n",
      "action : 1\n",
      "new state: [7 0 0 3 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "final state: [7 0 0 3 3 1]\n",
      "Episode : 15\n",
      "state : [7 0 0 3 3 1]\n",
      "action : 1\n",
      "new state: [7 0 0 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 0 3 0 2]\n",
      "Episode : 16\n",
      "state : [7 0 0 3 0 2]\n",
      "action : 2\n",
      "new state: [7 0 0 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 0 3 1 3]\n",
      "Episode : 17\n",
      "state : [7 0 0 3 1 3]\n",
      "action : 2\n",
      "new state: [7 0 0 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 0 3 0 1]\n",
      "Episode : 18\n",
      "state : [7 0 0 3 0 1]\n",
      "action : 1\n",
      "new state: [7 0 0 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 0 3 2 3]\n",
      "Episode : 19\n",
      "state : [7 0 0 3 2 3]\n",
      "action : 2\n",
      "new state: [7 0 0 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 0 3 0 1]\n",
      "Episode : 20\n",
      "state : [7 0 0 3 0 1]\n",
      "action : 3\n",
      "new state: [7 1 0 2 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 1 0 2 1 3]\n",
      "action : 2\n",
      "new state: [7 1 0 2 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [7 1 0 2 2 2]\n",
      "Episode : 21\n",
      "state : [7 1 0 2 2 2]\n",
      "action : 1\n",
      "new state: [7 1 0 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 1 0 2 1 1]\n",
      "action : 2\n",
      "new state: [7 1 0 2 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 1 0 2 2 1]\n",
      "Episode : 22\n",
      "state : [7 1 0 2 2 1]\n",
      "action : 1\n",
      "new state: [7 1 0 2 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 1 0 2 1 3]\n",
      "action : 2\n",
      "new state: [7 1 0 2 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 1 0 2 1 0]\n",
      "Episode : 23\n",
      "state : [7 1 0 2 1 0]\n",
      "action : 0\n",
      "new state: [7 1 0 2 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 1 0 2 2 1]\n",
      "action : 1\n",
      "new state: [7 1 0 2 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [7 1 0 2 0 1]\n",
      "action : 2\n",
      "new state: [7 1 0 2 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.5\n",
      "final state: [7 1 0 2 0 1]\n",
      "Episode : 24\n",
      "state : [7 1 0 2 0 1]\n",
      "action : 1\n",
      "new state: [7 1 0 2 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 1 0 2 2 1]\n",
      "action : 2\n",
      "new state: [7 1 0 2 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [7 1 0 2 0 3]\n",
      "Episode : 25\n",
      "state : [7 1 0 2 0 3]\n",
      "action : 1\n",
      "new state: [7 0 0 3 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [7 0 0 3 3 1]\n",
      "action : 0\n",
      "new state: [6 1 0 3 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [6 1 0 3 0 2]\n",
      "action : 0\n",
      "new state: [5 1 1 3 1 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.75\n",
      "state : [5 1 1 3 1 3]\n",
      "action : 1\n",
      "new state: [5 0 1 4 2 2]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "state : [5 0 1 4 2 2]\n",
      "action : 3\n",
      "new state: [5 0 2 3 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "final state: [5 0 2 3 3 3]\n",
      "Episode : 26\n",
      "state : [5 0 2 3 3 3]\n",
      "action : 1\n",
      "new state: [5 0 2 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [5 0 2 3 2 2]\n",
      "Episode : 27\n",
      "state : [5 0 2 3 2 2]\n",
      "action : 3\n",
      "new state: [5 0 2 3 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 0 2 3 2 3]\n",
      "action : 3\n",
      "new state: [5 0 2 3 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 0 2 3 3 2]\n",
      "action : 3\n",
      "new state: [5 0 3 2 3 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [5 0 3 2 3 0]\n",
      "action : 2\n",
      "new state: [6 0 2 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [6 0 2 2 0 2]\n",
      "action : 0\n",
      "new state: [5 0 3 2 0 1]\n",
      "reward: 0.25\n",
      "epReward so far: -1.5\n",
      "final state: [5 0 3 2 0 1]\n",
      "Episode : 28\n",
      "state : [5 0 3 2 0 1]\n",
      "action : 0\n",
      "new state: [4 1 3 2 0 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [4 1 3 2 0 3]\n",
      "action : 2\n",
      "new state: [4 1 3 2 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [4 1 3 2 3 3]\n",
      "action : 1\n",
      "new state: [4 1 3 2 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [4 1 3 2 2 3]\n",
      "action : 0\n",
      "new state: [4 1 3 2 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [4 1 3 2 0 1]\n",
      "action : 3\n",
      "new state: [4 1 3 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "final state: [4 1 3 2 2 0]\n",
      "Episode : 29\n",
      "state : [4 1 3 2 2 0]\n",
      "action : 0\n",
      "new state: [4 1 3 2 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 1 3 2 0 1]\n",
      "action : 3\n",
      "new state: [4 1 3 2 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [4 1 3 2 0 3]\n",
      "action : 2\n",
      "new state: [4 1 3 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [4 1 3 2 1 1]\n",
      "action : 2\n",
      "new state: [4 2 2 2 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "state : [4 2 2 2 2 1]\n",
      "action : 1\n",
      "new state: [4 2 2 2 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -3.5\n",
      "final state: [4 2 2 2 2 3]\n",
      "Episode : 30\n",
      "state : [4 2 2 2 2 3]\n",
      "action : 0\n",
      "new state: [3 2 2 3 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [3 2 2 3 2 1]\n",
      "action : 1\n",
      "new state: [3 2 2 3 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [3 2 2 3 1 3]\n",
      "action : 0\n",
      "new state: [3 2 2 3 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [3 2 2 3 3 3]\n",
      "action : 1\n",
      "new state: [3 1 2 4 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [3 1 2 4 0 1]\n",
      "action : 2\n",
      "new state: [3 2 1 4 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -3.25\n",
      "final state: [3 2 1 4 3 0]\n",
      "Episode : 31\n",
      "state : [3 2 1 4 3 0]\n",
      "action : 2\n",
      "new state: [4 2 0 4 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 2 0 4 2 3]\n",
      "action : 2\n",
      "new state: [4 2 0 4 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [4 2 0 4 1 1]\n",
      "Episode : 32\n",
      "state : [4 2 0 4 1 1]\n",
      "action : 3\n",
      "new state: [4 3 0 3 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 3 0 3 0 3]\n",
      "action : 2\n",
      "new state: [4 3 0 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [4 3 0 3 3 1]\n",
      "Episode : 33\n",
      "state : [4 3 0 3 3 1]\n",
      "action : 1\n",
      "new state: [4 3 0 3 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 3 0 3 0 2]\n",
      "action : 0\n",
      "new state: [4 3 0 3 2 3]\n",
      "reward: -0.0\n",
      "epReward so far: -0.5\n",
      "state : [4 3 0 3 2 3]\n",
      "action : 3\n",
      "new state: [4 3 0 3 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [4 3 0 3 1 3]\n",
      "action : 0\n",
      "new state: [3 3 0 4 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "state : [3 3 0 4 3 0]\n",
      "action : 3\n",
      "new state: [4 3 0 3 0 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "final state: [4 3 0 3 0 0]\n",
      "Episode : 34\n",
      "state : [4 3 0 3 0 0]\n",
      "action : 1\n",
      "new state: [5 2 0 3 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 2 0 3 2 2]\n",
      "action : 3\n",
      "new state: [5 2 0 3 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 2 0 3 3 2]\n",
      "action : 3\n",
      "new state: [5 2 1 2 3 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [5 2 1 2 3 0]\n",
      "action : 2\n",
      "new state: [6 2 0 2 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [6 2 0 2 2 2]\n",
      "action : 1\n",
      "new state: [6 2 0 2 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "final state: [6 2 0 2 0 1]\n",
      "Episode : 35\n",
      "state : [6 2 0 2 0 1]\n",
      "action : 1\n",
      "new state: [6 2 0 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 2 0 2 1 1]\n",
      "action : 3\n",
      "new state: [6 2 0 2 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [6 2 0 2 2 1]\n",
      "action : 0\n",
      "new state: [6 2 0 2 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [6 2 0 2 3 3]\n",
      "action : 1\n",
      "new state: [6 2 0 2 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "state : [6 2 0 2 3 2]\n",
      "action : 0\n",
      "new state: [5 2 1 2 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -3.5\n",
      "final state: [5 2 1 2 3 1]\n",
      "Episode : 36\n",
      "state : [5 2 1 2 3 1]\n",
      "action : 3\n",
      "new state: [5 3 1 1 3 0]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [5 3 1 1 3 0]\n",
      "action : 1\n",
      "new state: [6 2 1 1 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.25\n",
      "state : [6 2 1 1 2 2]\n",
      "action : 3\n",
      "new state: [6 2 1 1 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.0\n",
      "state : [6 2 1 1 0 2]\n",
      "action : 0\n",
      "new state: [5 2 2 1 3 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.75\n",
      "state : [5 2 2 1 3 3]\n",
      "action : 2\n",
      "new state: [5 2 2 1 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "final state: [5 2 2 1 1 2]\n",
      "Episode : 37\n",
      "state : [5 2 2 1 1 2]\n",
      "action : 3\n",
      "new state: [5 2 3 0 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 2 3 0 2 0]\n",
      "action : 2\n",
      "new state: [5 2 3 0 2 0]\n",
      "reward: -0.0\n",
      "epReward so far: -0.5\n",
      "state : [5 2 3 0 2 0]\n",
      "action : 0\n",
      "new state: [5 2 3 0 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [5 2 3 0 2 0]\n",
      "action : 1\n",
      "new state: [5 2 3 0 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [5 2 3 0 0 3]\n",
      "action : 2\n",
      "new state: [5 2 2 1 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -2.5\n",
      "final state: [5 2 2 1 1 1]\n",
      "Episode : 38\n",
      "state : [5 2 2 1 1 1]\n",
      "action : 1\n",
      "new state: [5 2 2 1 1 3]\n",
      "reward: 0.0\n",
      "epReward so far: 0.0\n",
      "state : [5 2 2 1 1 3]\n",
      "action : 0\n",
      "new state: [5 2 2 1 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 2 2 1 1 2]\n",
      "action : 3\n",
      "new state: [5 2 3 0 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [5 2 3 0 3 1]\n",
      "action : 2\n",
      "new state: [5 3 2 0 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [5 3 2 0 1 0]\n",
      "action : 1\n",
      "new state: [6 2 2 0 1 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.5\n",
      "final state: [6 2 2 0 1 0]\n",
      "Episode : 39\n",
      "state : [6 2 2 0 1 0]\n",
      "action : 2\n",
      "new state: [6 2 2 0 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 2 2 0 1 2]\n",
      "action : 2\n",
      "new state: [6 2 2 0 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [6 2 2 0 2 3]\n",
      "action : 3\n",
      "new state: [6 2 2 0 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [6 2 2 0 0 3]\n",
      "Episode : 40\n",
      "state : [6 2 2 0 0 3]\n",
      "action : 0\n",
      "new state: [6 2 2 0 0 1]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [6 2 2 0 0 1]\n",
      "action : 3\n",
      "new state: [6 2 2 0 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 2 2 0 0 0]\n",
      "Episode : 41\n",
      "state : [6 2 2 0 0 0]\n",
      "action : 0\n",
      "new state: [6 2 2 0 0 3]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [6 2 2 0 0 3]\n",
      "action : 2\n",
      "new state: [6 2 2 0 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 2 2 0 0 0]\n",
      "action : 0\n",
      "new state: [6 2 2 0 2 3]\n",
      "reward: -0.0\n",
      "epReward so far: -0.75\n",
      "state : [6 2 2 0 2 3]\n",
      "action : 2\n",
      "new state: [6 2 2 0 0 2]\n",
      "reward: -0.0\n",
      "epReward so far: -0.75\n",
      "state : [6 2 2 0 0 2]\n",
      "action : 2\n",
      "new state: [6 2 2 0 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "final state: [6 2 2 0 0 1]\n",
      "Episode : 42\n",
      "state : [6 2 2 0 0 1]\n",
      "action : 3\n",
      "new state: [6 2 2 0 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 2 2 0 2 3]\n",
      "Episode : 43\n",
      "state : [6 2 2 0 2 3]\n",
      "action : 0\n",
      "new state: [6 2 2 0 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 2 2 0 2 3]\n",
      "action : 3\n",
      "new state: [6 2 2 0 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [6 2 2 0 1 2]\n",
      "Episode : 44\n",
      "state : [6 2 2 0 1 2]\n",
      "action : 1\n",
      "new state: [6 1 3 0 0 2]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [6 1 3 0 0 2]\n",
      "action : 0\n",
      "new state: [5 1 4 0 0 2]\n",
      "reward: 0.25\n",
      "epReward so far: 0.5\n",
      "state : [5 1 4 0 0 2]\n",
      "action : 1\n",
      "new state: [5 0 5 0 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: 0.0\n",
      "state : [5 0 5 0 1 0]\n",
      "action : 2\n",
      "new state: [6 0 4 0 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [6 0 4 0 3 0]\n",
      "action : 3\n",
      "new state: [6 0 4 0 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [6 0 4 0 2 2]\n",
      "Episode : 45\n",
      "state : [6 0 4 0 2 2]\n",
      "action : 1\n",
      "new state: [6 0 4 0 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 4 0 2 0]\n",
      "Episode : 46\n",
      "state : [6 0 4 0 2 0]\n",
      "action : 0\n",
      "new state: [6 0 4 0 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 0 4 0 1 1]\n",
      "action : 1\n",
      "new state: [6 0 4 0 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [6 0 4 0 1 0]\n",
      "Episode : 47\n",
      "state : [6 0 4 0 1 0]\n",
      "action : 2\n",
      "new state: [6 0 4 0 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 0 4 0 1 2]\n",
      "action : 1\n",
      "new state: [6 0 4 0 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [6 0 4 0 2 3]\n",
      "Episode : 48\n",
      "state : [6 0 4 0 2 3]\n",
      "action : 3\n",
      "new state: [6 0 4 0 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 4 0 1 1]\n",
      "Episode : 49\n",
      "state : [6 0 4 0 1 1]\n",
      "action : 0\n",
      "new state: [6 0 4 0 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 0 4 0 3 2]\n",
      "action : 3\n",
      "new state: [6 0 4 0 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [6 0 4 0 3 0]\n",
      "Episode : 50\n",
      "state : [6 0 4 0 3 0]\n",
      "action : 1\n",
      "new state: [6 0 4 0 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 4 0 1 1]\n",
      "Episode : 51\n",
      "state : [6 0 4 0 1 1]\n",
      "action : 0\n",
      "new state: [5 1 4 0 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 1 4 0 3 3]\n",
      "action : 2\n",
      "new state: [5 1 3 1 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 1 3 1 1 1]\n",
      "action : 2\n",
      "new state: [5 1 3 1 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [5 1 3 1 3 2]\n",
      "action : 3\n",
      "new state: [5 1 4 0 0 0]\n",
      "reward: 0.25\n",
      "epReward so far: -2.0\n",
      "state : [5 1 4 0 0 0]\n",
      "action : 3\n",
      "new state: [5 1 4 0 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10002.0\n",
      "final state: [5 1 4 0 0 2]\n",
      "Episode : 52\n",
      "state : [5 1 4 0 0 2]\n",
      "action : 2\n",
      "new state: [5 1 4 0 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 1 4 0 2 0]\n",
      "action : 1\n",
      "new state: [6 0 4 0 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [6 0 4 0 3 1]\n",
      "action : 2\n",
      "new state: [6 1 3 0 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "state : [6 1 3 0 1 3]\n",
      "action : 0\n",
      "new state: [5 1 3 1 1 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.0\n",
      "state : [5 1 3 1 1 2]\n",
      "action : 1\n",
      "new state: [5 0 4 1 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.75\n",
      "final state: [5 0 4 1 2 0]\n",
      "Episode : 53\n",
      "state : [5 0 4 1 2 0]\n",
      "action : 0\n",
      "new state: [5 0 4 1 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 0 4 1 1 0]\n",
      "action : 3\n",
      "new state: [6 0 4 0 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [6 0 4 0 1 1]\n",
      "action : 1\n",
      "new state: [6 0 4 0 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.0\n",
      "final state: [6 0 4 0 2 2]\n",
      "Episode : 54\n",
      "state : [6 0 4 0 2 2]\n",
      "action : 1\n",
      "new state: [6 0 4 0 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 4 0 3 1]\n",
      "Episode : 55\n",
      "state : [6 0 4 0 3 1]\n",
      "action : 3\n",
      "new state: [6 0 4 0 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 4 0 2 0]\n",
      "Episode : 56\n",
      "state : [6 0 4 0 2 0]\n",
      "action : 2\n",
      "new state: [7 0 3 0 1 2]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [7 0 3 0 1 2]\n",
      "action : 1\n",
      "new state: [7 0 3 0 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -9999.75\n",
      "final state: [7 0 3 0 2 1]\n",
      "Episode : 57\n",
      "state : [7 0 3 0 2 1]\n",
      "action : 1\n",
      "new state: [7 0 3 0 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 3 0 2 2]\n",
      "Episode : 58\n",
      "state : [7 0 3 0 2 2]\n",
      "action : 2\n",
      "new state: [7 0 3 0 3 0]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [7 0 3 0 3 0]\n",
      "action : 3\n",
      "new state: [7 0 3 0 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 3 0 0 3]\n",
      "Episode : 59\n",
      "state : [7 0 3 0 0 3]\n",
      "action : 3\n",
      "new state: [7 0 3 0 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 3 0 3 3]\n",
      "Episode : 60\n",
      "state : [7 0 3 0 3 3]\n",
      "action : 0\n",
      "new state: [6 0 3 1 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [6 0 3 1 1 0]\n",
      "action : 2\n",
      "new state: [7 0 2 1 1 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [7 0 2 1 1 1]\n",
      "action : 1\n",
      "new state: [7 0 2 1 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [7 0 2 1 0 3]\n",
      "Episode : 61\n",
      "state : [7 0 2 1 0 3]\n",
      "action : 0\n",
      "new state: [6 0 2 2 3 1]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [6 0 2 2 3 1]\n",
      "action : 2\n",
      "new state: [6 0 2 2 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [6 0 2 2 0 3]\n",
      "action : 0\n",
      "new state: [5 0 2 3 3 2]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [5 0 2 3 3 2]\n",
      "action : 2\n",
      "new state: [5 0 2 3 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.75\n",
      "state : [5 0 2 3 3 1]\n",
      "action : 3\n",
      "new state: [5 1 2 2 3 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.5\n",
      "final state: [5 1 2 2 3 3]\n",
      "Episode : 62\n",
      "state : [5 1 2 2 3 3]\n",
      "action : 1\n",
      "new state: [5 1 2 2 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 1 2 2 3 0]\n",
      "action : 3\n",
      "new state: [5 1 2 2 1 3]\n",
      "reward: -0.0\n",
      "epReward so far: -0.75\n",
      "state : [5 1 2 2 1 3]\n",
      "action : 3\n",
      "new state: [5 1 2 2 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 1 2 2 1 2]\n",
      "action : 0\n",
      "new state: [5 1 2 2 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [5 1 2 2 0 3]\n",
      "action : 2\n",
      "new state: [5 1 2 2 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "final state: [5 1 2 2 3 1]\n",
      "Episode : 63\n",
      "state : [5 1 2 2 3 1]\n",
      "action : 0\n",
      "new state: [4 2 2 2 2 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 2 2 2 2 1]\n",
      "action : 2\n",
      "new state: [4 3 1 2 2 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [4 3 1 2 2 3]\n",
      "action : 0\n",
      "new state: [4 3 1 2 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.0\n",
      "state : [4 3 1 2 3 1]\n",
      "action : 3\n",
      "new state: [4 4 1 1 0 3]\n",
      "reward: 0.25\n",
      "epReward so far: -0.75\n",
      "state : [4 4 1 1 0 3]\n",
      "action : 3\n",
      "new state: [4 4 1 1 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "final state: [4 4 1 1 0 3]\n",
      "Episode : 64\n",
      "state : [4 4 1 1 0 3]\n",
      "action : 0\n",
      "new state: [3 4 1 2 3 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [3 4 1 2 3 3]\n",
      "action : 0\n",
      "new state: [2 4 1 3 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [2 4 1 3 3 2]\n",
      "action : 2\n",
      "new state: [2 4 1 3 3 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [2 4 1 3 3 3]\n",
      "action : 1\n",
      "new state: [2 3 1 4 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [2 3 1 4 2 0]\n",
      "action : 0\n",
      "new state: [2 3 1 4 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "final state: [2 3 1 4 0 2]\n",
      "Episode : 65\n",
      "state : [2 3 1 4 0 2]\n",
      "action : 1\n",
      "new state: [2 2 2 4 1 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [2 2 2 4 1 2]\n",
      "action : 1\n",
      "new state: [2 2 2 4 1 3]\n",
      "reward: -0.0\n",
      "epReward so far: -0.5\n",
      "state : [2 2 2 4 1 3]\n",
      "action : 1\n",
      "new state: [2 2 2 4 3 0]\n",
      "reward: -0.0\n",
      "epReward so far: -0.5\n",
      "state : [2 2 2 4 3 0]\n",
      "action : 1\n",
      "new state: [3 1 2 4 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [3 1 2 4 3 2]\n",
      "action : 2\n",
      "new state: [3 1 2 4 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "final state: [3 1 2 4 1 0]\n",
      "Episode : 66\n",
      "state : [3 1 2 4 1 0]\n",
      "action : 3\n",
      "new state: [3 1 2 4 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 1 2 4 0 0]\n",
      "action : 2\n",
      "new state: [3 1 2 4 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [3 1 2 4 1 2]\n",
      "action : 1\n",
      "new state: [3 0 3 4 2 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [3 0 3 4 2 0]\n",
      "action : 2\n",
      "new state: [4 0 2 4 1 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [4 0 2 4 1 2]\n",
      "action : 3\n",
      "new state: [4 0 2 4 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "final state: [4 0 2 4 2 0]\n",
      "Episode : 67\n",
      "state : [4 0 2 4 2 0]\n",
      "action : 0\n",
      "new state: [4 0 2 4 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 0 2 4 3 0]\n",
      "action : 1\n",
      "new state: [4 0 2 4 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [4 0 2 4 1 3]\n",
      "Episode : 68\n",
      "state : [4 0 2 4 1 3]\n",
      "action : 3\n",
      "new state: [4 0 2 4 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 0 2 4 0 3]\n",
      "action : 3\n",
      "new state: [4 0 2 4 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "state : [4 0 2 4 1 3]\n",
      "action : 0\n",
      "new state: [4 0 2 4 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [4 0 2 4 3 2]\n",
      "action : 3\n",
      "new state: [4 0 3 3 1 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.5\n",
      "state : [4 0 3 3 1 2]\n",
      "action : 3\n",
      "new state: [4 0 4 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.0\n",
      "final state: [4 0 4 2 0 2]\n",
      "Episode : 69\n",
      "state : [4 0 4 2 0 2]\n",
      "action : 1\n",
      "new state: [4 0 4 2 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [4 0 4 2 1 2]\n",
      "Episode : 70\n",
      "state : [4 0 4 2 1 2]\n",
      "action : 3\n",
      "new state: [4 0 5 1 3 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 0 5 1 3 3]\n",
      "action : 2\n",
      "new state: [4 0 5 1 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [4 0 5 1 2 2]\n",
      "action : 2\n",
      "new state: [4 0 5 1 1 3]\n",
      "reward: -0.0\n",
      "epReward so far: -1.25\n",
      "state : [4 0 5 1 1 3]\n",
      "action : 0\n",
      "new state: [3 0 5 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [3 0 5 2 0 2]\n",
      "action : 3\n",
      "new state: [3 0 5 2 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "final state: [3 0 5 2 0 0]\n",
      "Episode : 71\n",
      "state : [3 0 5 2 0 0]\n",
      "action : 3\n",
      "new state: [3 0 5 2 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 0 5 2 3 1]\n",
      "action : 0\n",
      "new state: [3 0 5 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [3 0 5 2 2 0]\n",
      "action : 2\n",
      "new state: [4 0 4 2 2 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [4 0 4 2 2 2]\n",
      "action : 0\n",
      "new state: [3 0 5 2 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [3 0 5 2 3 1]\n",
      "action : 3\n",
      "new state: [3 1 5 1 3 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.75\n",
      "final state: [3 1 5 1 3 2]\n",
      "Episode : 72\n",
      "state : [3 1 5 1 3 2]\n",
      "action : 3\n",
      "new state: [3 1 5 1 1 2]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [3 1 5 1 1 2]\n",
      "action : 0\n",
      "new state: [2 1 6 1 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [2 1 6 1 3 1]\n",
      "action : 3\n",
      "new state: [2 2 6 0 1 2]\n",
      "reward: 0.25\n",
      "epReward so far: -0.25\n",
      "state : [2 2 6 0 1 2]\n",
      "action : 1\n",
      "new state: [2 1 7 0 1 0]\n",
      "reward: 0.25\n",
      "epReward so far: 0.0\n",
      "state : [2 1 7 0 1 0]\n",
      "action : 0\n",
      "new state: [2 1 7 0 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "final state: [2 1 7 0 3 2]\n",
      "Episode : 73\n",
      "state : [2 1 7 0 3 2]\n",
      "action : 2\n",
      "new state: [2 1 7 0 2 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [2 1 7 0 2 3]\n",
      "action : 1\n",
      "new state: [2 1 7 0 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [2 1 7 0 3 0]\n",
      "action : 3\n",
      "new state: [2 1 7 0 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [2 1 7 0 3 3]\n",
      "Episode : 74\n",
      "state : [2 1 7 0 3 3]\n",
      "action : 3\n",
      "new state: [2 1 7 0 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [2 1 7 0 2 3]\n",
      "Episode : 75\n",
      "state : [2 1 7 0 2 3]\n",
      "action : 0\n",
      "new state: [2 1 7 0 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [2 1 7 0 0 0]\n",
      "action : 2\n",
      "new state: [3 1 6 0 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [3 1 6 0 2 1]\n",
      "action : 3\n",
      "new state: [3 1 6 0 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.5\n",
      "final state: [3 1 6 0 3 0]\n",
      "Episode : 76\n",
      "state : [3 1 6 0 3 0]\n",
      "action : 0\n",
      "new state: [3 1 6 0 1 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 1 6 0 1 2]\n",
      "action : 0\n",
      "new state: [3 1 6 0 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [3 1 6 0 2 0]\n",
      "action : 1\n",
      "new state: [3 1 6 0 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [3 1 6 0 0 3]\n",
      "action : 2\n",
      "new state: [3 1 6 0 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "state : [3 1 6 0 2 2]\n",
      "action : 0\n",
      "new state: [3 1 6 0 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -3.75\n",
      "final state: [3 1 6 0 1 0]\n",
      "Episode : 77\n",
      "state : [3 1 6 0 1 0]\n",
      "action : 0\n",
      "new state: [3 1 6 0 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [3 1 6 0 2 0]\n",
      "action : 3\n",
      "new state: [3 1 6 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [3 1 6 0 1 3]\n",
      "Episode : 78\n",
      "state : [3 1 6 0 1 3]\n",
      "action : 2\n",
      "new state: [3 1 5 1 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [3 1 5 1 2 0]\n",
      "action : 3\n",
      "new state: [3 1 5 1 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [3 1 5 1 0 0]\n",
      "action : 2\n",
      "new state: [3 1 5 1 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [3 1 5 1 1 1]\n",
      "action : 1\n",
      "new state: [3 1 5 1 2 0]\n",
      "reward: 0.0\n",
      "epReward so far: -2.0\n",
      "state : [3 1 5 1 2 0]\n",
      "action : 1\n",
      "new state: [4 0 5 1 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.5\n",
      "final state: [4 0 5 1 0 2]\n",
      "Episode : 79\n",
      "state : [4 0 5 1 0 2]\n",
      "action : 1\n",
      "new state: [4 0 5 1 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [4 0 5 1 3 3]\n",
      "Episode : 80\n",
      "state : [4 0 5 1 3 3]\n",
      "action : 3\n",
      "new state: [4 0 5 1 2 0]\n",
      "reward: 0.0\n",
      "epReward so far: 0.0\n",
      "state : [4 0 5 1 2 0]\n",
      "action : 2\n",
      "new state: [5 0 4 1 0 3]\n",
      "reward: 0.25\n",
      "epReward so far: 0.25\n",
      "state : [5 0 4 1 0 3]\n",
      "action : 2\n",
      "new state: [5 0 4 1 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.5\n",
      "state : [5 0 4 1 0 2]\n",
      "action : 0\n",
      "new state: [5 0 4 1 2 0]\n",
      "reward: -0.0\n",
      "epReward so far: -0.5\n",
      "state : [5 0 4 1 2 0]\n",
      "action : 3\n",
      "new state: [6 0 4 0 3 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.0\n",
      "final state: [6 0 4 0 3 1]\n",
      "Episode : 81\n",
      "state : [6 0 4 0 3 1]\n",
      "action : 1\n",
      "new state: [6 0 4 0 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [6 0 4 0 1 3]\n",
      "Episode : 82\n",
      "state : [6 0 4 0 1 3]\n",
      "action : 0\n",
      "new state: [5 0 4 1 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 0 4 1 0 3]\n",
      "action : 1\n",
      "new state: [5 0 4 1 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [5 0 4 1 2 2]\n",
      "Episode : 83\n",
      "state : [5 0 4 1 2 2]\n",
      "action : 2\n",
      "new state: [5 0 4 1 0 1]\n",
      "reward: 0.0\n",
      "epReward so far: 0.0\n",
      "state : [5 0 4 1 0 1]\n",
      "action : 3\n",
      "new state: [5 0 4 1 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 0 4 1 0 0]\n",
      "action : 2\n",
      "new state: [5 0 4 1 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 0 4 1 3 2]\n",
      "action : 0\n",
      "new state: [4 0 5 1 0 3]\n",
      "reward: -0.5\n",
      "epReward so far: -2.0\n",
      "state : [4 0 5 1 0 3]\n",
      "action : 1\n",
      "new state: [4 0 5 1 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10002.0\n",
      "final state: [4 0 5 1 0 2]\n",
      "Episode : 84\n",
      "state : [4 0 5 1 0 2]\n",
      "action : 2\n",
      "new state: [4 0 5 1 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 0 5 1 1 0]\n",
      "action : 1\n",
      "new state: [4 0 5 1 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [4 0 5 1 1 3]\n",
      "Episode : 85\n",
      "state : [4 0 5 1 1 3]\n",
      "action : 2\n",
      "new state: [4 0 4 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 0 4 2 0 2]\n",
      "action : 1\n",
      "new state: [4 0 4 2 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.5\n",
      "final state: [4 0 4 2 3 0]\n",
      "Episode : 86\n",
      "state : [4 0 4 2 3 0]\n",
      "action : 1\n",
      "new state: [4 0 4 2 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [4 0 4 2 3 3]\n",
      "Episode : 87\n",
      "state : [4 0 4 2 3 3]\n",
      "action : 3\n",
      "new state: [4 0 4 2 0 0]\n",
      "reward: 0.0\n",
      "epReward so far: 0.0\n",
      "state : [4 0 4 2 0 0]\n",
      "action : 0\n",
      "new state: [4 0 4 2 0 0]\n",
      "reward: 0.0\n",
      "epReward so far: 0.0\n",
      "state : [4 0 4 2 0 0]\n",
      "action : 2\n",
      "new state: [4 0 4 2 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 0 4 2 2 2]\n",
      "action : 2\n",
      "new state: [4 0 4 2 0 2]\n",
      "reward: 0.0\n",
      "epReward so far: -0.75\n",
      "state : [4 0 4 2 0 2]\n",
      "action : 2\n",
      "new state: [4 0 4 2 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "final state: [4 0 4 2 2 3]\n",
      "Episode : 88\n",
      "state : [4 0 4 2 2 3]\n",
      "action : 3\n",
      "new state: [4 0 4 2 3 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [4 0 4 2 3 0]\n",
      "action : 0\n",
      "new state: [4 0 4 2 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [4 0 4 2 3 3]\n",
      "action : 2\n",
      "new state: [4 0 4 2 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [4 0 4 2 2 3]\n",
      "action : 2\n",
      "new state: [4 0 3 3 3 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.75\n",
      "state : [4 0 3 3 3 0]\n",
      "action : 2\n",
      "new state: [5 0 2 3 1 0]\n",
      "reward: -0.5\n",
      "epReward so far: -2.25\n",
      "final state: [5 0 2 3 1 0]\n",
      "Episode : 89\n",
      "state : [5 0 2 3 1 0]\n",
      "action : 3\n",
      "new state: [6 0 2 2 2 0]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [6 0 2 2 2 0]\n",
      "action : 3\n",
      "new state: [6 0 2 2 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [6 0 2 2 0 2]\n",
      "action : 0\n",
      "new state: [5 0 3 2 2 2]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [5 0 3 2 2 2]\n",
      "action : 0\n",
      "new state: [5 0 3 2 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "state : [5 0 3 2 0 3]\n",
      "action : 3\n",
      "new state: [5 0 3 2 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -2.25\n",
      "final state: [5 0 3 2 0 2]\n",
      "Episode : 90\n",
      "state : [5 0 3 2 0 2]\n",
      "action : 1\n",
      "new state: [5 0 3 2 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [5 0 3 2 2 0]\n",
      "Episode : 91\n",
      "state : [5 0 3 2 2 0]\n",
      "action : 0\n",
      "new state: [5 0 3 2 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [5 0 3 2 1 3]\n",
      "action : 2\n",
      "new state: [5 0 3 2 2 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [5 0 3 2 2 3]\n",
      "action : 2\n",
      "new state: [5 0 2 3 1 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [5 0 2 3 1 0]\n",
      "action : 0\n",
      "new state: [5 0 2 3 3 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.5\n",
      "state : [5 0 2 3 3 3]\n",
      "action : 0\n",
      "new state: [5 0 2 3 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "final state: [5 0 2 3 3 1]\n",
      "Episode : 92\n",
      "state : [5 0 2 3 3 1]\n",
      "action : 2\n",
      "new state: [5 0 2 3 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 0 2 3 2 2]\n",
      "action : 0\n",
      "new state: [5 0 2 3 3 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 0 2 3 3 1]\n",
      "action : 0\n",
      "new state: [5 0 2 3 0 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [5 0 2 3 0 3]\n",
      "action : 2\n",
      "new state: [5 0 1 4 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -2.75\n",
      "state : [5 0 1 4 0 1]\n",
      "action : 0\n",
      "new state: [4 1 1 4 1 1]\n",
      "reward: 0.25\n",
      "epReward so far: -2.5\n",
      "final state: [4 1 1 4 1 1]\n",
      "Episode : 93\n",
      "state : [4 1 1 4 1 1]\n",
      "action : 3\n",
      "new state: [4 2 1 3 3 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 2 1 3 3 0]\n",
      "action : 1\n",
      "new state: [5 1 1 3 0 0]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [5 1 1 3 0 0]\n",
      "action : 1\n",
      "new state: [5 1 1 3 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "state : [5 1 1 3 0 2]\n",
      "action : 3\n",
      "new state: [5 1 1 3 3 3]\n",
      "reward: -0.75\n",
      "epReward so far: -2.75\n",
      "state : [5 1 1 3 3 3]\n",
      "action : 3\n",
      "new state: [5 1 1 3 2 1]\n",
      "reward: -0.0\n",
      "epReward so far: -2.75\n",
      "final state: [5 1 1 3 2 1]\n",
      "Episode : 94\n",
      "state : [5 1 1 3 2 1]\n",
      "action : 0\n",
      "new state: [5 1 1 3 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 1 1 3 2 2]\n",
      "action : 2\n",
      "new state: [5 1 1 3 1 3]\n",
      "reward: 0.0\n",
      "epReward so far: -0.75\n",
      "state : [5 1 1 3 1 3]\n",
      "action : 3\n",
      "new state: [5 1 1 3 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [5 1 1 3 0 1]\n",
      "action : 1\n",
      "new state: [5 1 1 3 0 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [5 1 1 3 0 2]\n",
      "action : 2\n",
      "new state: [5 1 1 3 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "final state: [5 1 1 3 1 0]\n",
      "Episode : 95\n",
      "state : [5 1 1 3 1 0]\n",
      "action : 3\n",
      "new state: [6 1 1 2 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [6 1 1 2 2 2]\n",
      "action : 1\n",
      "new state: [6 0 2 2 2 2]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [6 0 2 2 2 2]\n",
      "action : 1\n",
      "new state: [6 0 2 2 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.25\n",
      "final state: [6 0 2 2 0 0]\n",
      "Episode : 96\n",
      "state : [6 0 2 2 0 0]\n",
      "action : 3\n",
      "new state: [7 0 2 1 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [7 0 2 1 1 0]\n",
      "action : 1\n",
      "new state: [7 0 2 1 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.75\n",
      "final state: [7 0 2 1 1 2]\n",
      "Episode : 97\n",
      "state : [7 0 2 1 1 2]\n",
      "action : 1\n",
      "new state: [7 0 2 1 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 2 1 0 2]\n",
      "Episode : 98\n",
      "state : [7 0 2 1 0 2]\n",
      "action : 1\n",
      "new state: [7 0 2 1 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [7 0 2 1 3 2]\n",
      "Episode : 99\n",
      "state : [7 0 2 1 3 2]\n",
      "action : 0\n",
      "new state: [6 0 3 1 3 2]\n",
      "reward: -0.5\n",
      "epReward so far: -0.5\n",
      "state : [6 0 3 1 3 2]\n",
      "action : 2\n",
      "new state: [6 0 3 1 1 3]\n",
      "reward: -0.75\n",
      "epReward so far: -1.25\n",
      "state : [6 0 3 1 1 3]\n",
      "action : 2\n",
      "new state: [6 0 2 2 2 2]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [6 0 2 2 2 2]\n",
      "action : 0\n",
      "new state: [5 0 3 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -2.5\n",
      "state : [5 0 3 2 1 1]\n",
      "action : 2\n",
      "new state: [5 1 2 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -3.25\n",
      "final state: [5 1 2 2 2 0]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.00000000e+04  9.72070000e+04\n",
      "  -6.48690493e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00 -1.00000000e+04  3.02600000e+03\n",
      "  -6.86946946e+00]\n",
      " [ 2.00000000e+00  0.00000000e+00 -1.00000000e+04  3.02600000e+03\n",
      "  -6.35278676e+00]\n",
      " [ 3.00000000e+00  0.00000000e+00 -1.00015000e+04  7.70300000e+03\n",
      "  -5.75778707e+00]\n",
      " [ 4.00000000e+00  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.01972685e+00]\n",
      " [ 5.00000000e+00  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.76953899e+00]\n",
      " [ 6.00000000e+00  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.08814846e+00]\n",
      " [ 7.00000000e+00  0.00000000e+00 -3.00000000e+00  1.26570000e+04\n",
      "  -5.35021035e+00]\n",
      " [ 8.00000000e+00  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.35662659e+00]\n",
      " [ 9.00000000e+00  0.00000000e+00 -1.00007500e+04  5.18600000e+03\n",
      "  -5.98991698e+00]\n",
      " [ 1.00000000e+01  0.00000000e+00 -3.25000000e+00  1.69400000e+04\n",
      "  -4.58349704e+00]\n",
      " [ 1.10000000e+01  0.00000000e+00 -2.75000000e+00  1.36350000e+04\n",
      "  -4.53947547e+00]\n",
      " [ 1.20000000e+01  0.00000000e+00 -2.50000000e-01  1.31850000e+04\n",
      "  -5.21916182e+00]\n",
      " [ 1.30000000e+01  0.00000000e+00 -2.25000000e+00  1.31860000e+04\n",
      "  -5.37992787e+00]\n",
      " [ 1.40000000e+01  0.00000000e+00 -2.75000000e+00  1.47450000e+04\n",
      "  -4.94932606e+00]\n",
      " [ 1.50000000e+01  0.00000000e+00 -2.50000000e+00  1.54030000e+04\n",
      "  -4.78644897e+00]\n",
      " [ 1.60000000e+01  0.00000000e+00 -2.75000000e+00  1.59890000e+04\n",
      "  -4.98902048e+00]\n",
      " [ 1.70000000e+01  0.00000000e+00 -1.00007500e+04  7.87300000e+03\n",
      "  -6.06442056e+00]\n",
      " [ 1.80000000e+01  0.00000000e+00 -1.00000000e+04  2.11300000e+03\n",
      "  -6.57640949e+00]\n",
      " [ 1.90000000e+01  0.00000000e+00 -3.00000000e+00  9.60800000e+03\n",
      "  -4.42534815e+00]\n",
      " [ 2.00000000e+01  0.00000000e+00 -3.25000000e+00  5.60200000e+03\n",
      "  -4.98905548e+00]\n",
      " [ 2.10000000e+01  0.00000000e+00 -2.75000000e+00  1.08670000e+04\n",
      "  -4.78393705e+00]\n",
      " [ 2.20000000e+01  0.00000000e+00 -3.50000000e+00  3.66000000e+03\n",
      "  -4.89821610e+00]\n",
      " [ 2.30000000e+01  0.00000000e+00 -2.50000000e+00  1.41700000e+04\n",
      "  -4.79086006e+00]\n",
      " [ 2.40000000e+01  0.00000000e+00 -3.00000000e+00  5.76900000e+03\n",
      "  -5.02620637e+00]\n",
      " [ 2.50000000e+01  0.00000000e+00 -1.00010000e+04  1.45680000e+04\n",
      "  -4.65257824e+00]\n",
      " [ 2.60000000e+01  0.00000000e+00 -1.00005000e+04  5.18300000e+03\n",
      "  -5.90672964e+00]\n",
      " [ 2.70000000e+01  0.00000000e+00 -2.50000000e+00  3.44200000e+03\n",
      "  -4.78971245e+00]\n",
      " [ 2.80000000e+01  0.00000000e+00 -2.00000000e+00  1.35780000e+04\n",
      "  -4.79364850e+00]\n",
      " [ 2.90000000e+01  0.00000000e+00 -3.25000000e+00  3.44400000e+03\n",
      "  -5.05854346e+00]\n",
      " [ 3.00000000e+01  0.00000000e+00 -3.00000000e+00  5.76800000e+03\n",
      "  -4.65382899e+00]\n",
      " [ 3.10000000e+01  0.00000000e+00 -2.50000000e+00  2.13770000e+04\n",
      "  -4.90449998e+00]\n",
      " [ 3.20000000e+01  0.00000000e+00 -2.25000000e+00  1.26600000e+04\n",
      "  -4.77666532e+00]\n",
      " [ 3.30000000e+01  0.00000000e+00 -1.25000000e+00  4.30500000e+03\n",
      "  -4.43005987e+00]\n",
      " [ 3.40000000e+01  0.00000000e+00 -1.00030000e+04  1.74750000e+04\n",
      "  -3.24409494e+00]\n",
      " [ 3.50000000e+01  0.00000000e+00 -1.00027500e+04  2.80400000e+03\n",
      "  -4.67196446e+00]\n",
      " [ 3.60000000e+01  0.00000000e+00 -1.00000000e+04  2.11300000e+03\n",
      "  -5.59133132e+00]\n",
      " [ 3.70000000e+01  0.00000000e+00 -2.00000000e+00  4.30300000e+03\n",
      "  -4.78584896e+00]\n",
      " [ 3.80000000e+01  0.00000000e+00 -2.25000000e+00  1.80580000e+04\n",
      "  -4.87446636e+00]\n",
      " [ 3.90000000e+01  0.00000000e+00 -2.25000000e+00  5.34000000e+03\n",
      "  -1.75876804e+00]\n",
      " [ 4.00000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.30794240e+00]\n",
      " [ 4.10000000e+01  0.00000000e+00 -1.00000000e+04  3.90500000e+03\n",
      "  -6.87429983e+00]\n",
      " [ 4.20000000e+01  0.00000000e+00 -3.25000000e+00  7.39600000e+03\n",
      "  -5.33248875e+00]\n",
      " [ 4.30000000e+01  0.00000000e+00 -1.00000000e+04  2.46500000e+03\n",
      "  -5.99775566e+00]\n",
      " [ 4.40000000e+01  0.00000000e+00 -9.99975000e+03  5.91000000e+03\n",
      "  -6.14093033e+00]\n",
      " [ 4.50000000e+01  0.00000000e+00 -1.00000000e+04  2.99300000e+03\n",
      "  -6.94647639e+00]\n",
      " [ 4.60000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.85330887e+00]\n",
      " [ 4.70000000e+01  0.00000000e+00 -2.25000000e+00  6.81000000e+03\n",
      "  -5.38236254e+00]\n",
      " [ 4.80000000e+01  0.00000000e+00 -9.99975000e+03  3.66200000e+03\n",
      "  -6.29948345e+00]\n",
      " [ 4.90000000e+01  0.00000000e+00 -1.00000000e+04  9.29400000e+03\n",
      "  -5.45116649e+00]\n",
      " [ 5.00000000e+01  0.00000000e+00 -1.00000000e+04  5.29700000e+03\n",
      "  -6.98874512e+00]\n",
      " [ 5.10000000e+01  0.00000000e+00 -1.00005000e+04  7.23400000e+03\n",
      "  -6.01167161e+00]\n",
      " [ 5.20000000e+01  0.00000000e+00 -1.00000000e+04  1.19920000e+04\n",
      "  -6.52470546e+00]\n",
      " [ 5.30000000e+01  0.00000000e+00 -9.99975000e+03  9.12000000e+03\n",
      "  -6.22125916e+00]\n",
      " [ 5.40000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.36052845e+00]\n",
      " [ 5.50000000e+01  0.00000000e+00 -1.00005000e+04  1.10820000e+04\n",
      "  -5.85200318e+00]\n",
      " [ 5.60000000e+01  0.00000000e+00 -1.00012500e+04  7.67900000e+03\n",
      "  -6.16196960e+00]\n",
      " [ 5.70000000e+01  0.00000000e+00 -1.00007500e+04  5.20100000e+03\n",
      "  -5.59510962e+00]\n",
      " [ 5.80000000e+01  0.00000000e+00 -1.00000000e+04  5.06500000e+03\n",
      "  -6.76518800e+00]\n",
      " [ 5.90000000e+01  0.00000000e+00 -1.00012500e+04  4.48600000e+03\n",
      "  -5.65186805e+00]\n",
      " [ 6.00000000e+01  0.00000000e+00 -2.50000000e+00  6.46600000e+03\n",
      "  -4.77785472e+00]\n",
      " [ 6.10000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.27608254e+00]\n",
      " [ 6.20000000e+01  0.00000000e+00 -1.00007500e+04  5.18600000e+03\n",
      "  -6.62732447e+00]\n",
      " [ 6.30000000e+01  0.00000000e+00 -1.00017500e+04  9.36100000e+03\n",
      "  -5.13520590e+00]\n",
      " [ 6.40000000e+01  0.00000000e+00 -1.00007500e+04  5.18600000e+03\n",
      "  -6.64311857e+00]\n",
      " [ 6.50000000e+01  0.00000000e+00 -1.00000000e+04  6.05700000e+03\n",
      "  -5.08111950e+00]\n",
      " [ 6.60000000e+01  0.00000000e+00 -1.00000000e+04  2.06500000e+03\n",
      "  -5.69502425e+00]\n",
      " [ 6.70000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.50093306e+00]\n",
      " [ 6.80000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.45729598e+00]\n",
      " [ 6.90000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.60841222e+00]\n",
      " [ 7.00000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.20530644e+00]\n",
      " [ 7.10000000e+01  0.00000000e+00 -1.00000000e+04  6.67300000e+03\n",
      "  -6.75674739e+00]\n",
      " [ 7.20000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.29381288e+00]\n",
      " [ 7.30000000e+01  0.00000000e+00 -1.00000000e+04  2.81700000e+03\n",
      "  -6.12893172e+00]\n",
      " [ 7.40000000e+01  0.00000000e+00 -1.25000000e+00  8.93000000e+03\n",
      "  -3.87703541e+00]\n",
      " [ 7.50000000e+01  0.00000000e+00 -1.50000000e+00  1.26580000e+04\n",
      "  -4.77536427e+00]\n",
      " [ 7.60000000e+01  0.00000000e+00 -1.00000000e+04  2.77000000e+03\n",
      "  -6.68187482e-01]\n",
      " [ 7.70000000e+01  0.00000000e+00 -1.00007500e+04  3.70500000e+03\n",
      "  -6.21850285e+00]\n",
      " [ 7.80000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.30510048e+00]\n",
      " [ 7.90000000e+01  0.00000000e+00 -1.00022500e+04  3.79800000e+03\n",
      "  -5.30879188e+00]\n",
      " [ 8.00000000e+01  0.00000000e+00 -1.00012500e+04  7.45800000e+03\n",
      "  -5.03580551e+00]\n",
      " [ 8.10000000e+01  0.00000000e+00 -1.00015000e+04  8.57600000e+03\n",
      "  -5.80977198e+00]\n",
      " [ 8.20000000e+01  0.00000000e+00 -1.00000000e+04  4.77700000e+03\n",
      "  -6.85806162e+00]\n",
      " [ 8.30000000e+01  0.00000000e+00 -1.00012500e+04  9.39400000e+03\n",
      "  -4.98685295e+00]\n",
      " [ 8.40000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.91452635e+00]\n",
      " [ 8.50000000e+01  0.00000000e+00 -1.00030000e+04  7.84300000e+03\n",
      "  -5.21139437e+00]\n",
      " [ 8.60000000e+01  0.00000000e+00 -1.00007500e+04  8.49700000e+03\n",
      "  -6.10846206e+00]\n",
      " [ 8.70000000e+01  0.00000000e+00 -1.00007500e+04  8.22700000e+03\n",
      "  -5.34180820e+00]\n",
      " [ 8.80000000e+01  0.00000000e+00 -1.00010000e+04  8.60700000e+03\n",
      "  -5.49925131e+00]\n",
      " [ 8.90000000e+01  0.00000000e+00 -1.00015000e+04  8.30200000e+03\n",
      "  -5.63965179e+00]\n",
      " [ 9.00000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.34158638e+00]\n",
      " [ 9.10000000e+01  0.00000000e+00 -1.00012500e+04  8.91000000e+03\n",
      "  -5.56490195e+00]\n",
      " [ 9.20000000e+01  0.00000000e+00 -1.00010000e+04  9.01900000e+03\n",
      "  -5.84440047e+00]\n",
      " [ 9.30000000e+01  0.00000000e+00 -1.00007500e+04  9.15300000e+03\n",
      "  -5.74213191e+00]\n",
      " [ 9.40000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.75326842e+00]\n",
      " [ 9.50000000e+01  0.00000000e+00 -1.00000000e+04  4.03300000e+03\n",
      "  -6.71047900e+00]\n",
      " [ 9.60000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.36805577e+00]\n",
      " [ 9.70000000e+01  0.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.28926344e+00]\n",
      " [ 9.80000000e+01  0.00000000e+00 -1.00007500e+04  5.66500000e+03\n",
      "  -6.17060209e+00]\n",
      " [ 9.90000000e+01  0.00000000e+00 -1.00000000e+04  4.03300000e+03\n",
      "  -6.26492029e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00 -1.00012500e+04  1.25000000e+04\n",
      "  -5.16605731e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00 -1.00000000e+04  2.73700000e+03\n",
      "  -5.75341795e+00]\n",
      " [ 2.00000000e+00  1.00000000e+00 -1.00005000e+04  3.50200000e+03\n",
      "  -6.24715254e+00]\n",
      " [ 3.00000000e+00  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.37146164e+00]\n",
      " [ 4.00000000e+00  1.00000000e+00 -1.00027500e+04  1.58190000e+04\n",
      "  -5.46791805e+00]\n",
      " [ 5.00000000e+00  1.00000000e+00 -1.00012500e+04  3.83800000e+03\n",
      "  -6.02145069e+00]\n",
      " [ 6.00000000e+00  1.00000000e+00 -1.00000000e+00  1.65190000e+04\n",
      "  -5.35302683e+00]\n",
      " [ 7.00000000e+00  1.00000000e+00 -1.00007500e+04  6.29700000e+03\n",
      "  -6.53664248e+00]\n",
      " [ 8.00000000e+00  1.00000000e+00 -1.00012500e+04  7.10300000e+03\n",
      "  -6.28877021e+00]\n",
      " [ 9.00000000e+00  1.00000000e+00 -2.75000000e+00  1.54040000e+04\n",
      "  -2.64391952e+00]\n",
      " [ 1.00000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.55575633e+00]\n",
      " [ 1.10000000e+01  1.00000000e+00 -1.00000000e+04  3.23200000e+03\n",
      "  -5.61245409e+00]\n",
      " [ 1.20000000e+01  1.00000000e+00 -2.25000000e+00  6.00900000e+03\n",
      "  -5.25216901e+00]\n",
      " [ 1.30000000e+01  1.00000000e+00 -1.00012500e+04  1.80990000e+04\n",
      "  -5.58954321e+00]\n",
      " [ 1.40000000e+01  1.00000000e+00 -1.50000000e+00  6.82500000e+03\n",
      "  -5.70650510e+00]\n",
      " [ 1.50000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.54082731e+00]\n",
      " [ 1.60000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.41722379e+00]\n",
      " [ 1.70000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.33864736e+00]\n",
      " [ 1.80000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.37108264e+00]\n",
      " [ 1.90000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.53858465e+00]\n",
      " [ 2.00000000e+01  1.00000000e+00 -1.00005000e+04  6.52600000e+03\n",
      "  -6.45653651e+00]\n",
      " [ 2.10000000e+01  1.00000000e+00 -1.00007500e+04  5.43300000e+03\n",
      "  -6.42529565e+00]\n",
      " [ 2.20000000e+01  1.00000000e+00 -1.00007500e+04  3.31300000e+03\n",
      "  -6.75163543e+00]\n",
      " [ 2.30000000e+01  1.00000000e+00 -1.00015000e+04  4.47000000e+03\n",
      "  -6.09864760e+00]\n",
      " [ 2.40000000e+01  1.00000000e+00 -1.00005000e+04  2.44600000e+03\n",
      "  -6.73967381e+00]\n",
      " [ 2.50000000e+01  1.00000000e+00 -1.25000000e+00  2.08240000e+04\n",
      "  -5.75876898e+00]\n",
      " [ 2.60000000e+01  1.00000000e+00 -1.00000000e+04  3.23300000e+03\n",
      "  -6.68611585e+00]\n",
      " [ 2.70000000e+01  1.00000000e+00 -1.50000000e+00  4.30900000e+04\n",
      "  -5.45511896e+00]\n",
      " [ 2.80000000e+01  1.00000000e+00 -2.75000000e+00  1.37390000e+04\n",
      "  -5.54499436e+00]\n",
      " [ 2.90000000e+01  1.00000000e+00 -3.50000000e+00  1.37710000e+04\n",
      "  -5.66871431e+00]\n",
      " [ 3.00000000e+01  1.00000000e+00 -3.25000000e+00  8.69900000e+03\n",
      "  -5.45238953e+00]\n",
      " [ 3.10000000e+01  1.00000000e+00 -1.00005000e+04  8.74200000e+03\n",
      "  -6.39015865e+00]\n",
      " [ 3.20000000e+01  1.00000000e+00 -1.00007500e+04  5.59300000e+03\n",
      "  -6.25543800e+00]\n",
      " [ 3.30000000e+01  1.00000000e+00 -1.25000000e+00  8.30200000e+03\n",
      "  -5.15401498e+00]\n",
      " [ 3.40000000e+01  1.00000000e+00 -2.50000000e+00  1.52510000e+04\n",
      "  -5.64422384e+00]\n",
      " [ 3.50000000e+01  1.00000000e+00 -3.50000000e+00  8.54700000e+03\n",
      "  -5.22619118e+00]\n",
      " [ 3.60000000e+01  1.00000000e+00 -1.50000000e+00  8.40900000e+03\n",
      "  -4.85904332e+00]\n",
      " [ 3.70000000e+01  1.00000000e+00 -2.50000000e+00  5.59300000e+03\n",
      "  -1.07883586e+00]\n",
      " [ 3.80000000e+01  1.00000000e+00 -1.50000000e+00  6.55100000e+03\n",
      "  -4.82582631e+00]\n",
      " [ 3.90000000e+01  1.00000000e+00 -1.00012500e+04  6.53500000e+03\n",
      "  -5.73023712e+00]\n",
      " [ 4.00000000e+01  1.00000000e+00 -1.00000000e+04  5.35700000e+03\n",
      "  -6.45851234e+00]\n",
      " [ 4.10000000e+01  1.00000000e+00 -1.25000000e+00  9.08900000e+03\n",
      "  -5.04069514e+00]\n",
      " [ 4.20000000e+01  1.00000000e+00 -1.00000000e+04  5.54500000e+03\n",
      "  -6.74980150e+00]\n",
      " [ 4.30000000e+01  1.00000000e+00 -1.00007500e+04  5.08100000e+03\n",
      "  -5.94951404e+00]\n",
      " [ 4.40000000e+01  1.00000000e+00 -1.00005000e+04  9.83500000e+03\n",
      "  -5.14268713e+00]\n",
      " [ 4.50000000e+01  1.00000000e+00 -1.00000000e+04  4.73700000e+03\n",
      "  -6.61213068e+00]\n",
      " [ 4.60000000e+01  1.00000000e+00 -1.00007500e+04  7.83300000e+03\n",
      "  -6.35141896e+00]\n",
      " [ 4.70000000e+01  1.00000000e+00 -1.00007500e+04  3.43300000e+03\n",
      "  -6.57709442e+00]\n",
      " [ 4.80000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.41722379e+00]\n",
      " [ 4.90000000e+01  1.00000000e+00 -1.00007500e+04  8.41700000e+03\n",
      "  -6.46891158e+00]\n",
      " [ 5.00000000e+01  1.00000000e+00 -1.00000000e+04  3.87300000e+03\n",
      "  -6.50698307e+00]\n",
      " [ 5.10000000e+01  1.00000000e+00 -1.00020000e+04  1.06340000e+04\n",
      "  -5.50586049e+00]\n",
      " [ 5.20000000e+01  1.00000000e+00 -1.75000000e+00  9.40600000e+03\n",
      "  -5.25030389e+00]\n",
      " [ 5.30000000e+01  1.00000000e+00 -1.00010000e+04  1.01870000e+04\n",
      "  -6.18508011e+00]\n",
      " [ 5.40000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.53903278e+00]\n",
      " [ 5.50000000e+01  1.00000000e+00 -1.00000000e+04  3.87300000e+03\n",
      "  -6.77224197e+00]\n",
      " [ 5.60000000e+01  1.00000000e+00 -9.99975000e+03  7.83000000e+03\n",
      "  -6.50077434e+00]\n",
      " [ 5.70000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.51643044e+00]\n",
      " [ 5.80000000e+01  1.00000000e+00 -1.00000000e+04  3.85300000e+03\n",
      "  -6.43907670e+00]\n",
      " [ 5.90000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.50510134e+00]\n",
      " [ 6.00000000e+01  1.00000000e+00 -1.00012500e+04  8.86300000e+03\n",
      "  -6.14603748e+00]\n",
      " [ 6.10000000e+01  1.00000000e+00 -5.00000000e-01  1.43920000e+04\n",
      "  -5.66018723e+00]\n",
      " [ 6.20000000e+01  1.00000000e+00 -3.00000000e+00  1.52200000e+04\n",
      "  -5.56067782e+00]\n",
      " [ 6.30000000e+01  1.00000000e+00 -1.25000000e+00  1.29290000e+04\n",
      "  -5.71081762e+00]\n",
      " [ 6.40000000e+01  1.00000000e+00 -2.50000000e+00  1.46330000e+04\n",
      "  -5.03859666e+00]\n",
      " [ 6.50000000e+01  1.00000000e+00 -1.75000000e+00  5.19900000e+03\n",
      "  -5.25431136e+00]\n",
      " [ 6.60000000e+01  1.00000000e+00 -1.75000000e+00  1.61070000e+04\n",
      "  -2.67063672e+00]\n",
      " [ 6.70000000e+01  1.00000000e+00 -1.00007500e+04  5.45700000e+03\n",
      "  -6.64385077e+00]\n",
      " [ 6.80000000e+01  1.00000000e+00 -2.00000000e+00  6.18300000e+03\n",
      "  -5.60374425e+00]\n",
      " [ 6.90000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.52038215e+00]\n",
      " [ 7.00000000e+01  1.00000000e+00 -2.50000000e+00  1.71460000e+04\n",
      "  -5.67926703e+00]\n",
      " [ 7.10000000e+01  1.00000000e+00 -1.75000000e+00  7.36300000e+03\n",
      "  -5.63349916e+00]\n",
      " [ 7.20000000e+01  1.00000000e+00 -7.50000000e-01  1.17980000e+04\n",
      "  -5.69907384e+00]\n",
      " [ 7.30000000e+01  1.00000000e+00 -1.00012500e+04  1.50060000e+04\n",
      "  -6.19473303e+00]\n",
      " [ 7.40000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -6.99992423e+00]\n",
      " [ 7.50000000e+01  1.00000000e+00 -1.00015000e+04  7.95000000e+03\n",
      "  -6.03470640e+00]\n",
      " [ 7.60000000e+01  1.00000000e+00 -3.75000000e+00  1.39650000e+04\n",
      "  -5.56359553e+00]\n",
      " [ 7.70000000e+01  1.00000000e+00 -1.00007500e+04  6.36900000e+03\n",
      "  -6.25110121e+00]\n",
      " [ 7.80000000e+01  1.00000000e+00 -2.50000000e+00  2.11670000e+04\n",
      "  -5.50533249e+00]\n",
      " [ 7.90000000e+01  1.00000000e+00 -1.00000000e+04  4.73700000e+03\n",
      "  -6.74148924e+00]\n",
      " [ 8.00000000e+01  1.00000000e+00 -1.00000000e+00  6.70800000e+03\n",
      "  -5.50903435e+00]\n",
      " [ 8.10000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.54442605e+00]\n",
      " [ 8.20000000e+01  1.00000000e+00 -1.00005000e+04  5.35100000e+03\n",
      "  -6.73545057e+00]\n",
      " [ 8.30000000e+01  1.00000000e+00 -1.00020000e+04  4.16440000e+04\n",
      "  -5.39635974e+00]\n",
      " [ 8.40000000e+01  1.00000000e+00 -1.00005000e+04  5.18300000e+03\n",
      "  -6.85896947e+00]\n",
      " [ 8.50000000e+01  1.00000000e+00 -1.00005000e+04  5.27900000e+03\n",
      "  -6.83985273e+00]\n",
      " [ 8.60000000e+01  1.00000000e+00 -1.00000000e+04  2.69000000e+03\n",
      "  -7.53724147e+00]\n",
      " [ 8.70000000e+01  1.00000000e+00 -1.50000000e+00  1.38040000e+04\n",
      "  -5.79454065e+00]\n",
      " [ 8.80000000e+01  1.00000000e+00 -2.25000000e+00  1.26590000e+04\n",
      "  -5.74458754e+00]\n",
      " [ 8.90000000e+01  1.00000000e+00 -2.25000000e+00  1.26590000e+04\n",
      "  -5.80754781e+00]\n",
      " [ 9.00000000e+01  1.00000000e+00 -1.00000000e+04  3.94500000e+03\n",
      "  -7.03450214e+00]\n",
      " [ 9.10000000e+01  1.00000000e+00 -2.25000000e+00  7.03300000e+03\n",
      "  -5.37523073e+00]\n",
      " [ 9.20000000e+01  1.00000000e+00 -2.50000000e+00  1.03150000e+04\n",
      "  -5.44474237e+00]\n",
      " [ 9.30000000e+01  1.00000000e+00 -2.75000000e+00  9.37200000e+03\n",
      "  -2.25419446e+00]\n",
      " [ 9.40000000e+01  1.00000000e+00 -2.50000000e+00  9.98600000e+03\n",
      "  -5.57064550e+00]\n",
      " [ 9.50000000e+01  1.00000000e+00 -1.00012500e+04  1.10460000e+04\n",
      "  -5.78806106e+00]\n",
      " [ 9.60000000e+01  1.00000000e+00 -1.00007500e+04  7.58500000e+03\n",
      "  -6.31386090e+00]\n",
      " [ 9.70000000e+01  1.00000000e+00 -1.00000000e+04  9.87300000e+03\n",
      "  -6.64001270e+00]\n",
      " [ 9.80000000e+01  1.00000000e+00 -1.00000000e+04  3.36100000e+03\n",
      "  -6.65619547e+00]\n",
      " [ 9.90000000e+01  1.00000000e+00 -3.25000000e+00  1.14190000e+04\n",
      "  -5.50662365e+00]]\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "max_weight_fixed\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [5 1 2 2 2 0]\n",
      "action : 0\n",
      "new state: [5 1 2 2 0 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [5 1 2 2 0 0]\n",
      "action : 0\n",
      "new state: [5 1 2 2 3 1]\n",
      "reward: 0.0\n",
      "epReward so far: -0.75\n",
      "state : [5 1 2 2 3 1]\n",
      "action : 0\n",
      "new state: [5 1 2 2 0 1]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [5 1 2 2 0 1]\n",
      "action : 0\n",
      "new state: [4 2 2 2 1 0]\n",
      "reward: 0.25\n",
      "epReward so far: -1.25\n",
      "state : [4 2 2 2 1 0]\n",
      "action : 0\n",
      "new state: [4 2 2 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.0\n",
      "final state: [4 2 2 2 2 0]\n",
      "Episode : 1\n",
      "state : [4 2 2 2 2 0]\n",
      "action : 0\n",
      "new state: [4 2 2 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 2 2 2 2 0]\n",
      "action : 0\n",
      "new state: [4 2 2 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.5\n",
      "state : [4 2 2 2 2 0]\n",
      "action : 0\n",
      "new state: [4 2 2 2 2 0]\n",
      "reward: -0.75\n",
      "epReward so far: -2.25\n",
      "state : [4 2 2 2 2 0]\n",
      "action : 0\n",
      "new state: [4 2 2 2 1 1]\n",
      "reward: -0.75\n",
      "epReward so far: -3.0\n",
      "state : [4 2 2 2 1 1]\n",
      "action : 0\n",
      "new state: [4 2 2 2 0 2]\n",
      "reward: -0.75\n",
      "epReward so far: -3.75\n",
      "final state: [4 2 2 2 0 2]\n",
      "Episode : 2\n",
      "state : [4 2 2 2 0 2]\n",
      "action : 0\n",
      "new state: [4 2 2 2 1 3]\n",
      "reward: -0.0\n",
      "epReward so far: 0.0\n",
      "state : [4 2 2 2 1 3]\n",
      "action : 0\n",
      "new state: [4 2 2 2 2 1]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [4 2 2 2 2 1]\n",
      "action : 0\n",
      "new state: [3 3 2 2 0 1]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [3 3 2 2 0 1]\n",
      "action : 0\n",
      "new state: [2 4 2 2 1 3]\n",
      "reward: 0.25\n",
      "epReward so far: -1.0\n",
      "state : [2 4 2 2 1 3]\n",
      "action : 0\n",
      "new state: [2 4 2 2 1 0]\n",
      "reward: -0.75\n",
      "epReward so far: -1.75\n",
      "final state: [2 4 2 2 1 0]\n",
      "Episode : 3\n",
      "state : [2 4 2 2 1 0]\n",
      "action : 0\n",
      "new state: [2 4 2 2 3 2]\n",
      "reward: -0.75\n",
      "epReward so far: -0.75\n",
      "state : [2 4 2 2 3 2]\n",
      "action : 0\n",
      "new state: [1 4 3 2 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.25\n",
      "state : [1 4 3 2 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -0.5\n",
      "epReward so far: -1.75\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10001.75\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/davejung/Developer/ORSuite/or_suite/agents/rideshare/max_weight_fixed.py:36: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  weighted_value = state[:-2] / self.alpha\n",
      "/Users/davejung/Developer/ORSuite/or_suite/agents/rideshare/max_weight_fixed.py:36: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weighted_value = state[:-2] / self.alpha\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 0\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 78\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 79\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 80\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 81\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 82\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 83\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 84\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 85\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 86\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 87\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 88\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 89\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 90\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 91\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 92\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 93\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 94\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 95\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 96\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 97\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 98\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 99\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "Episode : 0\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 1\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 2\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 3\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 4\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 5\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 6\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 7\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 8\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 9\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 10\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 11\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 12\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 13\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 14\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 15\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 16\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 17\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 18\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 19\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 20\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 21\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 22\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 23\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 24\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 25\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 26\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 27\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 28\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 29\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 0]\n",
      "Episode : 30\n",
      "state : [0 4 3 3 1 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 3]\n",
      "Episode : 31\n",
      "state : [0 4 3 3 2 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 32\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 33\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 34\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 35\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 36\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 37\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 38\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 39\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 40\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 41\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 42\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 43\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 44\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 1]\n",
      "Episode : 45\n",
      "state : [0 4 3 3 2 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 46\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 47\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 48\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 49\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 50\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 51\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 2]\n",
      "Episode : 52\n",
      "state : [0 4 3 3 3 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 53\n",
      "state : [0 4 3 3 0 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 54\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 55\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 3]\n",
      "Episode : 56\n",
      "state : [0 4 3 3 3 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 57\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 58\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 59\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 0]\n",
      "Episode : 60\n",
      "state : [0 4 3 3 2 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 61\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 62\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 1]\n",
      "Episode : 63\n",
      "state : [0 4 3 3 1 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 0]\n",
      "Episode : 64\n",
      "state : [0 4 3 3 3 0]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 65\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 2]\n",
      "Episode : 66\n",
      "state : [0 4 3 3 1 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 67\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 2 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 2 2]\n",
      "Episode : 68\n",
      "state : [0 4 3 3 2 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 69\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 1 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 1 3]\n",
      "Episode : 70\n",
      "state : [0 4 3 3 1 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 71\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 72\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 73\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 2]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 2]\n",
      "Episode : 74\n",
      "state : [0 4 3 3 0 2]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 3]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 3]\n",
      "Episode : 75\n",
      "state : [0 4 3 3 0 3]\n",
      "action : 0\n",
      "new state: [0 4 3 3 3 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 3 1]\n",
      "Episode : 76\n",
      "state : [0 4 3 3 3 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 1]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 1]\n",
      "Episode : 77\n",
      "state : [0 4 3 3 0 1]\n",
      "action : 0\n",
      "new state: [0 4 3 3 0 0]\n",
      "reward: -10000.0\n",
      "epReward so far: -10000.0\n",
      "final state: [0 4 3 3 0 0]\n",
      "Episode : 78"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l5/43sgrxps7lbcv1k2xnpw4g5h0000gn/T/ipykernel_9633/284948338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dirPath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/rideshare'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max_weight_fixed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_algo_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrideshare_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SB PPO'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_sb_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/ORSuite/or_suite/utils.py\u001b[0m in \u001b[0;36mrun_single_algo_tune\u001b[0;34m(env, agent, param_list, settings)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         dt = pd.DataFrame(exp.data, columns=[\n\u001b[1;32m     37\u001b[0m                           'episode', 'iteration', 'epReward', 'memory', 'time'])\n",
      "\u001b[0;32m~/Developer/ORSuite/or_suite/experiment/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loops over the episodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeBug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Episode : %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# Reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 )\n\u001b[1;32m    540\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ORSuite/lib/python3.8/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'rideshare'+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'rideshare'+'_'+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization Demo\n",
    "\n",
    "The following demo includes a command-line interface with a visualization to demonstrate how the Ambulance Routing code works with 2 ambulances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following commands need to be used in the terminal to install the necessary packages:\n",
    "* `apt-get install -y xvfb python-opengl`\n",
    "* `pip install gym pyvirtualdisplay`\n",
    "* `pip install scikit-learn-extra`\n",
    "* `pip install stable_baselines3`\n",
    "* `pip install pyglet==1.5.16`\n",
    "\n",
    "The first two are needed for the simulation but the rest should already be installed from the code demo above."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation\n",
    "\n",
    "Run the cell below to run the simulation. In this simulation, you are trying to minimize the distance traveled by two ambulances to respond to incoming calls. The parameters in the problem are set up so the distance traveled to respond to a call is three times as costly as the distance traveled between calls. The reward is the negative cost, because reward is something that you want to maximize. Your goal therefore is to keep the reward as close to zero as possible.\n",
    "\n",
    "These are some questions you could ask yourself when choosing actions:\n",
    "\n",
    "* Should I focus more on minimizing distance traveled between calls, or distance traveled to respond to a call?\n",
    "\n",
    "* Do calls seem to arrive more in a certain part of the range $0$ to $1$? Can I take advantage of that?\n",
    "\n",
    "* Am I able to improve your performance over multiple rounds? (once you've finished you can re-run the cell to try again!)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(500, 800))\n",
    "display.start()\n",
    "\n",
    "import or_suite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "a = 5\n",
    "b = 2\n",
    "CONFIG = {'epLen': 5,\n",
    "    'arrival_dist': lambda x : np.random.beta(a,b), \n",
    "    'alpha': 0.25, \n",
    "    'starting_state': np.array([0.0, 0.0]), \n",
    "    'num_ambulance': 2,\n",
    "    'norm': 1\n",
    "}\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "epLen = CONFIG['epLen']\n",
    "state = CONFIG['starting_state']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "agent = or_suite.agents.ambulance.command_line_metric.commandLineAgent(epLen)\n",
    "env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "env.reset()\n",
    "\n",
    "\n",
    "done = False\n",
    "your_rewards = []\n",
    "heuristic_agent_rewards = []\n",
    "your_total_reward = 0\n",
    "heuristic_agent_total_reward = 0\n",
    "\n",
    "median_est = (a - 1/3)/(a + b - 2/3)\n",
    "heuristic_agent_states = [state]\n",
    "\n",
    "x_axis = ['Your Reward So Far', 'RL Algorithm Reward So Far']\n",
    "\n",
    "\n",
    "def display_animation(screen, time_to_display):\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    if time_to_display is not None:\n",
    "        ipythondisplay.display(plt.gcf())\n",
    "        time.sleep(time_to_display)\n",
    "\n",
    "def plot_rewards():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    y_axis = [your_total_reward, heuristic_agent_total_reward]\n",
    "    ax.bar(x_axis, y_axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = agent.greedy(state, 0)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    your_rewards.append(reward)\n",
    "    your_total_reward += reward\n",
    "\n",
    "    # by comparing the final state with the action the user chose, we can figure out where the most recent arrival was\n",
    "    previous_arrival_ind = np.argmax(np.abs(action - state))\n",
    "    previous_arrival = state[previous_arrival_ind]\n",
    "\n",
    "    # the heuristic agent always chooses to put all the ambulances at the median estimate\n",
    "    heuristic_agent_action = np.full(num_ambulance, median_est)\n",
    "\n",
    "    # the state will have one ambulance where the call arrived, and all other ambulances at the median estimate\n",
    "    # doesn't matter which ambulance responds to the call because they're all at the same place\n",
    "    heuristic_agent_state = np.concatenate([np.full(num_ambulance - 1, median_est), [previous_arrival]])\n",
    "    heuristic_agent_states.append(heuristic_agent_state)\n",
    "\n",
    "    heuristic_agent_reward = -1 * (alpha * np.sum(np.abs(heuristic_agent_states[-2] - heuristic_agent_action)) + (1 - alpha) * np.sum(np.abs(heuristic_agent_action - heuristic_agent_state)))\n",
    "    heuristic_agent_rewards.append(heuristic_agent_reward)\n",
    "    heuristic_agent_total_reward += heuristic_agent_reward\n",
    "\n",
    "    screen1, screen2, screen3 = env.render(mode='rgb_array')\n",
    "\n",
    "    # display each step of the environment for 2 seconds\n",
    "    display_animation(screen1, 2)\n",
    "    display_animation(screen2, 2)\n",
    "    display_animation(screen3, None)\n",
    "\n",
    "    # plot your reward vs the agent's reward\n",
    "    plot_rewards()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"\\nThe most recent call arrival was at \" + str(previous_arrival) + \", and ambulance \" + str(previous_arrival_ind+1) + \" responded to the call.\\n\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "\n",
    "if np.sum(your_rewards) >= np.sum(heuristic_agent_rewards):\n",
    "    print(\"CONGRATS! You beat the RL algorithm.\")\n",
    "else:\n",
    "    print(\"You did not get a better reward than the RL algorithm.\")\n",
    "\n",
    "print(\"\\nYour total reward over all iterations was \", round(sum(your_rewards),3))\n",
    "print(\"The RL algorithm's total reward over all iterations was \", round(sum(heuristic_agent_rewards),3), \"\\n\")\n",
    "\n",
    "plot_rewards()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c142dd05be15695d7d0f22ccf2092ca7b90c6a6af78118fc1f80db7c62802c3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ORSuite': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}