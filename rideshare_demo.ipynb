{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OR Suite \n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making, including inventory control, resource allocation, ridesharing systems, and ambulance routing. In these models, an agent interacts with a system that has stochastic transitions and rewards, and aims to control the system by maximizing their cumulative rewards across the trajectory. Reinforcement learning has been shown in practice to be an effective technique for learning complex control policies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ridesharing Code Demo\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook, we walk through the Ambulance Routing problem with a 1-dimensional reinforcement learning environment in the space $X = [0, 1]$. Each ambulance in the problem can be located anywhere in $X$, so the state space is $S = X^k$, where $k$ is the number of ambulances. For this example there will be only one ambulance, so $k = 1$.\n",
    "\n",
    "The default distribution for call arrivals is $Beta(5, 2)$ over $[0,1]$, however any probability distribution defined over the interval $[0,1]$ is valid. The probability distribution can also change with each timestep.\n",
    "\n",
    "For example, in a problem with two ambulances, imagine the ambulances are initially located at $0.4$ and $0.6$, and the distance function being used is the $\\ell_1$ norm. The agent could choose to move the ambulances to $0.342$ and $0.887$. If a call arrived at $0.115$, ambulance 1, which was at $0.342$, would respond to that call, and the state at the end of the iteration would be ambulance 1 at $0.115$ and ambulance 2 at $0.887$. The agent could then choose new locations to move the ambulances to, and the cycle would repeat."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Package Installation\n",
    "First we import the necessary packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import gym"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "CONFIG =  or_suite.envs.env_configs.rideshare_graph_default_config\n",
    "\n",
    "epLen = CONFIG['epLen']\n",
    "nEps = 100\n",
    "numIters = 2\n",
    "\n",
    "epsilon = (nEps * epLen)**(-1 / 4)\n",
    "action_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "state_net = np.arange(start=0, stop=1, step=epsilon)\n",
    "\n",
    "scaling_list = [0.1]\n",
    "\n",
    "def beta(step):\n",
    "    return np.random.beta(5,2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation. This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/rideshare/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5,\n",
    "                    'render': False,\n",
    "                    'pickle': False\n",
    "                    }\n",
    "\n",
    "starting_state = CONFIG['starting_state']\n",
    "num_cars = CONFIG['num_cars']\n",
    "\n",
    "rideshare_env = gym.make('Rideshare-v0', config=CONFIG)\n",
    "mon_env = Monitor(rideshare_env)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `Random` policy, and some `RL discretization based` algorithms. \n",
    "\n",
    "The `Stable` agent only moves ambulances when responding to an incoming call and not in between calls. This means the policy $\\pi$ chosen by the agent for any given state $X$ will be $\\pi_h(X) = X$\n",
    "\n",
    "The `Median` agent takes a list of all past call arrivals sorted by arrival location, and partitions it into $k$ quantiles where $k$ is the number of ambulances. The algorithm then selects the middle data point in each quantile as the locations to station the ambulances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "agents = { # 'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "'max_weight_fixed' : or_suite.agents.rideshare.max_weight_fixed.maxWeightFixedAgent()\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Run Simulations\n",
    "\n",
    "Run the different heuristics in the environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "path_list_line = []\n",
    "algo_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_radar= []\n",
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/rideshare'+str(agent)+'_'+str(num_cars)\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    elif agent == 'AdaQL' or agent == 'Unif QL' or agent == 'AdaMB' or agent == 'Unif MB':\n",
    "        or_suite.utils.run_single_algo_tune(rideshare_env, agents[agent], scaling_list, DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(rideshare_env, agents[agent], DEFAULT_SETTINGS)\n",
    "\n",
    "    path_list_line.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_line.append(str(agent))\n",
    "    path_list_radar.append('../data/ambulance_metric_'+str(agent)+'_'+str(num_cars))\n",
    "    algo_list_radar.append(str(agent))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6: Generate Figures\n",
    "\n",
    "Create a chart to compare the different heuristic functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "fig_path = '../figures/'\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_line_plot'+'.pdf'\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40)+1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y)), 'RTV': lambda traj : or_suite.utils.response_time_variance(traj, lambda x, y : np.abs(x-y))}\n",
    "fig_name = 'ambulance_metric'+'_'+str(num_ambulance)+'_'+str(alpha)+'_'+str(arrival_dist.__name__)+'_radar_plot'+'.pdf'\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar,\n",
    "fig_path, fig_name,\n",
    "additional_metric\n",
    ")\n",
    "\n",
    "# TODO: Import figures and display\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Algorithm    Reward      Time   Space       MRT       RTV\n",
      "0    Random -1.420085  7.052635 -4726.0 -0.335064 -0.050939\n",
      "1    Stable -1.001835  7.732670 -3804.0 -0.291050 -0.065029\n",
      "2    Median -0.658575  6.494975 -4544.5 -0.135620 -0.011065\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization Demo\n",
    "\n",
    "The following demo includes a command-line interface with a visualization to demonstrate how the Ambulance Routing code works with 2 ambulances."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following commands need to be used in the terminal to install the necessary packages:\n",
    "* `apt-get install -y xvfb python-opengl`\n",
    "* `pip install gym pyvirtualdisplay`\n",
    "* `pip install scikit-learn-extra`\n",
    "* `pip install stable_baselines3`\n",
    "* `pip install pyglet==1.5.16`\n",
    "\n",
    "The first two are needed for the simulation but the rest should already be installed from the code demo above."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation\n",
    "\n",
    "Run the cell below to run the simulation. In this simulation, you are trying to minimize the distance traveled by two ambulances to respond to incoming calls. The parameters in the problem are set up so the distance traveled to respond to a call is three times as costly as the distance traveled between calls. The reward is the negative cost, because reward is something that you want to maximize. Your goal therefore is to keep the reward as close to zero as possible.\n",
    "\n",
    "These are some questions you could ask yourself when choosing actions:\n",
    "\n",
    "* Should I focus more on minimizing distance traveled between calls, or distance traveled to respond to a call?\n",
    "\n",
    "* Do calls seem to arrive more in a certain part of the range $0$ to $1$? Can I take advantage of that?\n",
    "\n",
    "* Am I able to improve your performance over multiple rounds? (once you've finished you can re-run the cell to try again!)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(500, 800))\n",
    "display.start()\n",
    "\n",
    "import or_suite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "a = 5\n",
    "b = 2\n",
    "CONFIG = {'epLen': 5,\n",
    "    'arrival_dist': lambda x : np.random.beta(a,b), \n",
    "    'alpha': 0.25, \n",
    "    'starting_state': np.array([0.0, 0.0]), \n",
    "    'num_ambulance': 2,\n",
    "    'norm': 1\n",
    "}\n",
    "\n",
    "alpha = CONFIG['alpha']\n",
    "epLen = CONFIG['epLen']\n",
    "state = CONFIG['starting_state']\n",
    "num_ambulance = CONFIG['num_ambulance']\n",
    "\n",
    "agent = or_suite.agents.ambulance.command_line_metric.commandLineAgent(epLen)\n",
    "env = gym.make('Ambulance-v0', config=CONFIG)\n",
    "env.reset()\n",
    "\n",
    "\n",
    "done = False\n",
    "your_rewards = []\n",
    "heuristic_agent_rewards = []\n",
    "your_total_reward = 0\n",
    "heuristic_agent_total_reward = 0\n",
    "\n",
    "median_est = (a - 1/3)/(a + b - 2/3)\n",
    "heuristic_agent_states = [state]\n",
    "\n",
    "x_axis = ['Your Reward So Far', 'RL Algorithm Reward So Far']\n",
    "\n",
    "\n",
    "def display_animation(screen, time_to_display):\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    if time_to_display is not None:\n",
    "        ipythondisplay.display(plt.gcf())\n",
    "        time.sleep(time_to_display)\n",
    "\n",
    "def plot_rewards():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    y_axis = [your_total_reward, heuristic_agent_total_reward]\n",
    "    ax.bar(x_axis, y_axis)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = agent.greedy(state, 0)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    your_rewards.append(reward)\n",
    "    your_total_reward += reward\n",
    "\n",
    "    # by comparing the final state with the action the user chose, we can figure out where the most recent arrival was\n",
    "    previous_arrival_ind = np.argmax(np.abs(action - state))\n",
    "    previous_arrival = state[previous_arrival_ind]\n",
    "\n",
    "    # the heuristic agent always chooses to put all the ambulances at the median estimate\n",
    "    heuristic_agent_action = np.full(num_ambulance, median_est)\n",
    "\n",
    "    # the state will have one ambulance where the call arrived, and all other ambulances at the median estimate\n",
    "    # doesn't matter which ambulance responds to the call because they're all at the same place\n",
    "    heuristic_agent_state = np.concatenate([np.full(num_ambulance - 1, median_est), [previous_arrival]])\n",
    "    heuristic_agent_states.append(heuristic_agent_state)\n",
    "\n",
    "    heuristic_agent_reward = -1 * (alpha * np.sum(np.abs(heuristic_agent_states[-2] - heuristic_agent_action)) + (1 - alpha) * np.sum(np.abs(heuristic_agent_action - heuristic_agent_state)))\n",
    "    heuristic_agent_rewards.append(heuristic_agent_reward)\n",
    "    heuristic_agent_total_reward += heuristic_agent_reward\n",
    "\n",
    "    screen1, screen2, screen3 = env.render(mode='rgb_array')\n",
    "\n",
    "    # display each step of the environment for 2 seconds\n",
    "    display_animation(screen1, 2)\n",
    "    display_animation(screen2, 2)\n",
    "    display_animation(screen3, None)\n",
    "\n",
    "    # plot your reward vs the agent's reward\n",
    "    plot_rewards()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(\"\\nThe most recent call arrival was at \" + str(previous_arrival) + \", and ambulance \" + str(previous_arrival_ind+1) + \" responded to the call.\\n\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "ipythondisplay.clear_output(wait=True)\n",
    "env.close()\n",
    "\n",
    "if np.sum(your_rewards) >= np.sum(heuristic_agent_rewards):\n",
    "    print(\"CONGRATS! You beat the RL algorithm.\")\n",
    "else:\n",
    "    print(\"You did not get a better reward than the RL algorithm.\")\n",
    "\n",
    "print(\"\\nYour total reward over all iterations was \", round(sum(your_rewards),3))\n",
    "print(\"The RL algorithm's total reward over all iterations was \", round(sum(heuristic_agent_rewards),3), \"\\n\")\n",
    "\n",
    "plot_rewards()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 518.4x320.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sean/anaconda3/envs/ORSuite/lib/python3.8/site-packages/IPython/core/pylabtools.py:132: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 518.4x320.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "The most recent call arrival was at 0.8320872, and ambulance 2 responded to the call.\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6f9f52849e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m   \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0myour_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ORSuite/or_suite/agents/ambulance/command_line_metric.py\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(self, state, timestep, epsilon)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Where do you want to position ambulance \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mambulance\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"? (choose a number between 0 and 1)\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mnew_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0mnew_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ORSuite/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             )\n\u001b[0;32m--> 848\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ORSuite/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ORSuite': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "4c142dd05be15695d7d0f22ccf2092ca7b90c6a6af78118fc1f80db7c62802c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}